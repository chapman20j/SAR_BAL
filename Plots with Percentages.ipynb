{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6af5fb27",
      "metadata": {
        "id": "6af5fb27"
      },
      "source": [
        "# Plotting for experiments 1 and 2\n",
        "\n",
        "## TODO: Get this to work properly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d10968dd",
      "metadata": {
        "id": "d10968dd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import graphlearning as gl\n",
        "import graphlearning.active_learning as al\n",
        "\n",
        "import batch_active_learning as bal\n",
        "import utils\n",
        "\n",
        "from matplotlib.ticker import AutoLocator\n",
        "\n",
        "import pickle5 as pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e7d5ef3",
      "metadata": {
        "id": "0e7d5ef3"
      },
      "outputs": [],
      "source": [
        "#Non-default Parameters\n",
        "acq_fun_list = ['uc']\n",
        "save_path = \"Experiment Results/Experiment 1/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c0a0c14",
      "metadata": {
        "id": "0c0a0c14"
      },
      "outputs": [],
      "source": [
        "def tick_function(X, n):\n",
        "    V = X / n\n",
        "    return [\"%d%%\" % np.round(100*z) for z in V]\n",
        "    \n",
        "def experiment1_plotter(x_dict, y_dict, dataset, include_sota=False, fine_tuned=False):\n",
        "    fig = plt.figure()\n",
        "    fig.set_size_inches(12.5, 8.5)\n",
        "    ax1 = fig.add_subplot()\n",
        "    ax2 = ax1.twiny()\n",
        "\n",
        "    dataset_size = utils.SAR_DATASET_SIZE_DICT[dataset]\n",
        "\n",
        "    ax1.set_xlabel('Number of Labeled Points')\n",
        "    ax1.set_ylabel('Accuracy (%)')\n",
        "    \n",
        "    marker_types = [\"^\", \"o\", \"d\", \"p\", \"*\"]\n",
        "    for i in range(len(bal.AL_METHODS)):\n",
        "        this_key = bal.AL_METHODS[i]\n",
        "        ax1.plot(x_dict[this_key], y_dict[this_key], label=bal.AL_METHOD_NAMES[i], linewidth=3, markevery=3, markersize=15)\n",
        "\n",
        "    ax1.tick_params(axis='x')\n",
        "\n",
        "    # Add SoTA\n",
        "    if dataset != 'mstar' and include_sota:\n",
        "        if dataset == 'open_sar_ship':\n",
        "            sota_val = 78.15\n",
        "        elif dataset == 'fusar':\n",
        "            sota_val = 86.69\n",
        "        ax1.plot(x_dict['local_max'], sota_val *\n",
        "                 np.ones_like(x_dict['local_max']), label='SoTA', linestyle='--')\n",
        "\n",
        "    fontsize = 30\n",
        "    #ax1.legend(fontsize=fontsize)\n",
        "    ax1.set_xlabel(r\"Number of labeled points\", fontsize=fontsize)\n",
        "    ax1.set_ylabel(\"Accuracy (%)\", fontsize=fontsize)\n",
        "    ax1.set_ylim((None, 100))\n",
        "    if fine_tuned:\n",
        "        ax1.set_xlim((dataset_size*0.05, None))\n",
        "    else:\n",
        "        ax1.set_xlim((0, None))\n",
        "    \n",
        "    ax1.autoscale(enable=True, axis='x', tight=False)\n",
        "\n",
        "    \n",
        "    \n",
        "    if fine_tuned:\n",
        "        if dataset == 'mstar':\n",
        "            new_tick_locations = np.linspace(0.05, 0.15, 5) * dataset_size\n",
        "        elif dataset == 'open_sar_ship':\n",
        "            new_tick_locations = np.linspace(0.05, 0.3, 5) * dataset_size\n",
        "        else:\n",
        "            new_tick_locations = np.linspace(0.05, 0.63, 6) * dataset_size\n",
        "    else:\n",
        "        if dataset == 'mstar':\n",
        "            new_tick_locations = np.linspace(0, 0.15, 5) * dataset_size\n",
        "        elif dataset == 'open_sar_ship':\n",
        "            new_tick_locations = np.linspace(0, 0.3, 5) * dataset_size\n",
        "        else:\n",
        "            new_tick_locations = np.linspace(0, 0.63, 6) * dataset_size\n",
        "\n",
        "    \n",
        "    ax2.set_xlim(ax1.get_xlim())\n",
        "    ax2.set_xticks(new_tick_locations)\n",
        "    ax2.set_xticklabels(tick_function(new_tick_locations, dataset_size), fontsize=fontsize)\n",
        "    ax2.set_xlabel(r\"Percentage of Training Data\", fontsize=fontsize)\n",
        "    \n",
        "    ax1.tick_params(axis='both', labelsize=fontsize)\n",
        "    ax2.tick_params(axis='both', labelsize=fontsize)\n",
        "\n",
        "    return\n",
        "\n",
        "def get_data(dataset, file):\n",
        "    return pd.read_pickle(save_path + 'Pickles/' + dataset + \"_\" + file + '.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b5bb9ab",
      "metadata": {
        "id": "7b5bb9ab"
      },
      "outputs": [],
      "source": [
        "dataset = 'fusar'\n",
        "df = get_data(dataset, 'full_acc_dict')\n",
        "df = df.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c435830",
      "metadata": {
        "id": "6c435830"
      },
      "outputs": [],
      "source": [
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de9218a8",
      "metadata": {
        "id": "de9218a8"
      },
      "outputs": [],
      "source": [
        "y_dict = {'local_max': [n for n in df['local_max'] if not np.isnan(n)],\n",
        "          'random': [n for n in df['random'] if not np.isnan(n)],\n",
        "          'topn_max': [n for n in df['topn_max'] if not np.isnan(n)],\n",
        "          'acq_sample': [n for n in df['acq_sample'] if not np.isnan(n)],\n",
        "          'global_max': [n for n in df['global_max'] if not np.isnan(n)]}\n",
        "x_dict = {'local_max': [n*15 for n in range(len(y_dict['local_max']))],\n",
        "          'random': [n*15 for n in range(len(y_dict['random']))],\n",
        "          'topn_max': [n*15 for n in range(len(y_dict['topn_max']))],\n",
        "          'acq_sample': [n*15 for n in range(len(y_dict['acq_sample']))],\n",
        "          'global_max': [n for n in range(len(y_dict['global_max']))]}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(x_dict['local_max']))\n",
        "print(len(y_dict['local_max']))"
      ],
      "metadata": {
        "id": "h6p6E8dlgmuA"
      },
      "id": "h6p6E8dlgmuA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experiment1_plotter(x_dict, y_dict, dataset, include_sota=True)"
      ],
      "metadata": {
        "id": "9mpi5RhIgo3_"
      },
      "id": "9mpi5RhIgo3_",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}