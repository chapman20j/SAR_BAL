{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f577bbed",
   "metadata": {},
   "source": [
    "# MSTAR Testing\n",
    "\n",
    "encode_pretrained returns data and labels\n",
    "encode_dataset returns just data\n",
    "\n",
    "\n",
    "This is taking a while. I am going through this step by step and fixing it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b77febf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphlearning.active_learning as al\n",
    "import graphlearning as gl\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as torch_models\n",
    "import timeit\n",
    "import torch\n",
    "import random\n",
    "\n",
    "import utils\n",
    "import batch_active_learning as bal\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49c61b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/Users/jameschapman/Documents/GitHub/SAR_BAL/utils.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(bal)\n",
    "reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2581356",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pick one of 'mstar', 'open_sar', 'fusar'\n",
    "dataset_chosen = 'mstar'\n",
    "\n",
    "#This uses a CNNVAE to get embeddings\n",
    "# **I think this actually uses the fully trained and not a CNNVAE\n",
    "#Currently we always use the VAE for MSTAR since the knn_data is already stored for this\n",
    "\n",
    "use_fully_trained_features = False\n",
    "just_transfer              = True\n",
    "transfer_and_train         = False\n",
    "\n",
    "assert(use_fully_trained_features + just_transfer + transfer_and_train == 1)\n",
    "\n",
    "#If you specify this, then it will use a specific trained NN for embeddings\n",
    "#If none, it will pick the ones deemed optimal from prior testing\n",
    "#  I recommend using None\n",
    "transfer_encoding = None\n",
    "\n",
    "#Determines the number of points in the coreset\n",
    "#Larger values correspond to smaller coresets\n",
    "density_radius_param = .5\n",
    "\n",
    "knn_num = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0012688e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237\n",
      "101\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 80\u001b[0m\n\u001b[1;32m     78\u001b[0m     X \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mencode_dataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmstar\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./models/SAR10_CNNVAE.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m just_transfer:\n\u001b[0;32m---> 80\u001b[0m     X, labels \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmstar\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mResNet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     82\u001b[0m     X \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mencode_transfer_learning(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmstar\u001b[39m\u001b[38;5;124m'\u001b[39m, model_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShuffleNet\u001b[39m\u001b[38;5;124m'\u001b[39m, transfer_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, data_info\u001b[38;5;241m=\u001b[39mdata_info)\n",
      "File \u001b[0;32m~/Documents/GitHub/SAR_BAL/utils.py:192\u001b[0m, in \u001b[0;36mencode_pretrained\u001b[0;34m(dataset, model_type, batch_size, cuda, normalized, balanced, transformed)\u001b[0m\n\u001b[1;32m    189\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_cuda \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m#Load data\u001b[39;00m\n\u001b[0;32m--> 192\u001b[0m data, labels \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_torch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcatenate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(data)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m#Data augmentation\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m#Rotation produces negative effects so there's none of it\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/SAR_BAL/utils.py:69\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(dataset, return_torch, shuffle_train_set, concatenate)\u001b[0m\n\u001b[1;32m     67\u001b[0m hdr, fields, mag, phase \u001b[38;5;241m=\u001b[39m load_MSTAR(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/MSTAR\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     68\u001b[0m data \u001b[38;5;241m=\u001b[39m polar_transform(mag, phase)\n\u001b[0;32m---> 69\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m()\n\u001b[1;32m     70\u001b[0m labels, target_names \u001b[38;5;241m=\u001b[39m targets_to_labels(hdr)\n\u001b[1;32m     71\u001b[0m data_train \u001b[38;5;241m=\u001b[39m data[:\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'float'"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "with torch.no_grad():\n",
    "  torch.cuda.empty_cache()\n",
    "\n",
    "if dataset_chosen == 'open_sar':\n",
    "  #Load labels\n",
    "  data, labels = utils.load_dataset('open_sar_ship', return_torch = False, concatenate = True)\n",
    "elif dataset_chosen == 'fusar':\n",
    "  #Load labels\n",
    "  data, labels = utils.load_dataset('fusar', return_torch = False, concatenate = True)\n",
    "elif dataset_chosen == 'mstar':\n",
    "  hdr, fields, mag, phase = utils.load_MSTAR('data/MSTAR/')\n",
    "  data = utils.polar_transform(mag, phase)\n",
    "  labels, target_names = utils.targets_to_labels(hdr)\n",
    "else:\n",
    "  assert False, \"Chosen dataset could not be loaded. Check for typos\"\n",
    "\n",
    "#Mimic that we know a percentage of data, and don't know for the rest\n",
    "#Do transfer learning merely using these\n",
    "percent_known_data = 0.05\n",
    "known_data_ind = gl.trainsets.generate(labels, rate=percent_known_data).tolist()\n",
    "known_data = data[known_data_ind]\n",
    "known_labels = labels[known_data_ind]\n",
    "\n",
    "# print(len(known_data))\n",
    "\n",
    "#Generate the initial set\n",
    "initial = gl.trainsets.generate(labels, rate=1).tolist()\n",
    "\n",
    "#Percent of known data to use as training data for transfer learning\n",
    "training_percent = 0.7\n",
    "transfer_train_ind = random.sample(range(len(known_data)), round(len(known_data)*training_percent))\n",
    "transfer_testing_ind = np.array([ind for ind in range(len(known_data)) if ind not in transfer_train_ind]).astype(int)\n",
    "\n",
    "#Convert to torch for use\n",
    "known_data = torch.from_numpy(known_data)\n",
    "known_labels = torch.from_numpy(known_labels)\n",
    "\n",
    "\n",
    "#print(len(transfer_testing_ind))\n",
    "training_data = known_data[transfer_train_ind]\n",
    "training_label = known_labels[transfer_train_ind]\n",
    "testing_data = known_data[transfer_testing_ind]\n",
    "testing_label = known_labels[transfer_testing_ind]\n",
    "\n",
    "print(len(training_data))\n",
    "print(len(testing_data))\n",
    "\n",
    "data_info=[training_data, training_label, testing_data, testing_label]\n",
    "for item in data_info:\n",
    "  item = item.float()\n",
    "\n",
    "        \n",
    "if dataset_chosen == 'open_sar':\n",
    "    #Load encoded dataset\n",
    "    if use_fully_trained_features:\n",
    "        X = utils.encode_dataset('open_sar_ship','./models/open_sar_ship_CNN.pt')\n",
    "    elif just_transfer:\n",
    "        X, labels = utils.encode_pretrained('open_sar_ship', 'AlexNet', transformed=True)\n",
    "    else:\n",
    "        X = utils.encode_transfer_learning('open_sar_ship', model_type='AlexNet', transfer_batch_size=64, epochs=30, data_info=data_info)\n",
    "    #Load labels\n",
    "    _, labels = utils.load_dataset('open_sar_ship', return_torch = False, concatenate = True)\n",
    "    knn_data = gl.weightmatrix.knnsearch(X, knn_num, method='annoy', similarity='angular')\n",
    "elif dataset_chosen == 'fusar':\n",
    "    #Load encoded dataset\n",
    "    if use_fully_trained_features:\n",
    "        X = utils.encode_dataset('fusar','./models/fusar_CNN.pt')\n",
    "    elif just_transfer:\n",
    "        X, labels = utils.encode_pretrained('fusar', 'ShuffleNet', normalized=True, transformed=True)\n",
    "    else:\n",
    "        X = utils.encode_transfer_learning('fusar', model_type='ShuffleNet', transfer_batch_size=64, epochs=30, data_info=data_info)\n",
    "    #Load labels\n",
    "    _, labels = utils.load_dataset('fusar', return_torch = False, concatenate = True)\n",
    "    knn_data = gl.weightmatrix.knnsearch(X, knn_num, method='annoy', similarity='angular')\n",
    "elif dataset_chosen == 'mstar':\n",
    "    if use_fully_trained_features:\n",
    "        X = utils.encode_dataset('mstar', './models/SAR10_CNNVAE.pt')\n",
    "    elif just_transfer:\n",
    "        X, labels = utils.encode_pretrained('mstar', 'ResNet', transformed=False)\n",
    "    else:\n",
    "        X = utils.encode_transfer_learning('mstar', model_type = 'ShuffleNet', transfer_batch_size=64, epochs=30, data_info=data_info)\n",
    "    # X = utils.encode_transfer_learning(path, data_info=data_info, transformed=False)\n",
    "    knn_data = gl.weightmatrix.knnsearch(X, knn_num, method='annoy', similarity='angular')\n",
    "else:\n",
    "    assert False, \"Chosen dataset could not be loaded. Check for typos\"\n",
    "\n",
    "print(\"Constructing Graph Learning Objects\")\n",
    "W = gl.weightmatrix.knn(X, knn_num, kernel = 'gaussian', knn_data=knn_data)\n",
    "G = gl.graph(W)\n",
    "end = timeit.default_timer()\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "print(\"Complete\")\n",
    "print(f\"Time taken = {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941dca6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the percent radius because it should be more robust across datasets\n",
    "coreset = bal.coreset_dijkstras(G, rad = .2, DEBUGGING=False, data = X, initial=initial, \n",
    "                                density_info = (True, density_radius_param, 1), knn_data=knn_data)\n",
    "print(\"Coreset Size = {}\\t Percent of data = {}%\".format(len(coreset), round(100 * len(coreset) / len(X), 2)))\n",
    "print(\"Coreset = \", coreset)\n",
    "print(labels[coreset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9290f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#acq_fun_list = ['uc', 'vopt', 'mc', 'mcvopt']\n",
    "##TODO: Use the above one for actual testing\n",
    "acq_fun_list = ['uc']\n",
    "max_new_samples = 700\n",
    "# max_new_samples = 3060\n",
    "# max_new_samples = 2000\n",
    "batchsize=15\n",
    "\n",
    "L_time = []\n",
    "L_num_labels = []\n",
    "L_acc = []\n",
    "L_names = []\n",
    "for acq_fun in acq_fun_list:\n",
    "\n",
    "  num_iter = int(max_new_samples/batchsize)\n",
    "\n",
    "  al_mtd = 'local_max'\n",
    "  print(acq_fun, al_mtd)\n",
    "  start = timeit.default_timer() \n",
    "  _, list_num_labels, list_acc = bal.coreset_run_experiment(X, labels, W, coreset, num_iter=num_iter, method='Laplace',\n",
    "                           display=False, use_prior=False, al_mtd=al_mtd, debug=False,\n",
    "                           acq_fun=acq_fun, knn_data=knn_data, mtd_para=None,\n",
    "                           savefig=False, savefig_folder='../BAL_figures', batchsize=batchsize,\n",
    "                           dist_metric='angular', q=1, thresholding=0, randseed=0)\n",
    "  stop = timeit.default_timer()\n",
    "  L_time.append(stop - start)\n",
    "  L_num_labels.append(list_num_labels)\n",
    "  L_acc.append(list_acc)\n",
    "  L_names.append(al_mtd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc48bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "fig = plt.figure()\n",
    "plt.plot(L_num_labels[i], L_acc[i])\n",
    "#plt.set_ylim([None, 100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0a897e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
