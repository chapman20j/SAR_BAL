{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f577bbed"
      },
      "source": [
        "# MSTAR Testing\n",
        "\n",
        "encode_pretrained returns data and labels\n",
        "encode_dataset returns just data\n",
        "\n",
        "\n",
        "This is taking a while. I am going through this step by step and fixing it. \n",
        "\n",
        "\n",
        "## Clean this up"
      ],
      "id": "f577bbed"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8LcaEjtvGZW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccffb6dd-7e6e-48d1-cb09-cf9da0aa020a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 69 kB 2.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 647 kB 9.6 MB/s \n",
            "\u001b[?25h  Building wheel for graphlearning (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for annoy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q graphlearning annoy"
      ],
      "id": "X8LcaEjtvGZW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTvnQseivIvb",
        "outputId": "7e8ccf9e-6071-4377-c68f-856dd28fdafc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "WTvnQseivIvb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_EpGSz3vKPB",
        "outputId": "7aa018f4-1373-43c0-e2c0-20db046f61b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/"
      ],
      "id": "j_EpGSz3vKPB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2b77febf"
      },
      "outputs": [],
      "source": [
        "import graphlearning.active_learning as al\n",
        "import graphlearning as gl\n",
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.models as torch_models\n",
        "import timeit\n",
        "import torch\n",
        "import random\n",
        "from torch import optim  # For optimizers like SGD, Adam, etc.\n",
        "from torch import nn  # All neural network modules\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import utils\n",
        "import batch_active_learning as bal\n",
        "import models\n",
        "from importlib import reload"
      ],
      "id": "2b77febf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49c61b4c",
        "outputId": "fa977d81-65a9-45ae-c5de-a05497502ff1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'utils' from '/content/drive/MyDrive/utils.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "reload(bal)\n",
        "reload(utils)"
      ],
      "id": "49c61b4c"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNNVAE"
      ],
      "metadata": {
        "id": "J5zkzrxiw_bS"
      },
      "id": "J5zkzrxiw_bS"
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN Variational Autoencoder - SarShip 128*128\n",
        "class CVAE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CVAE, self).__init__()\n",
        " \n",
        "        kernel_size = 3 # (3, 3) kernel\n",
        "        num_classes = 10\n",
        "        init_channels = 8 # initial number of filters\n",
        "        image_channels = 1\n",
        "        latent_dim = 32 # latent dimension for sampling\n",
        "\n",
        "        # encoder\n",
        "        self.enc1 = nn.Conv2d(image_channels, init_channels, kernel_size, padding=1)\n",
        "        self.enc2 = nn.Conv2d(init_channels, 2*init_channels, kernel_size, padding=1)\n",
        "        self.enc3 = nn.Conv2d(2*init_channels, 4*init_channels, kernel_size, padding=1)\n",
        "        self.enc4 = nn.Conv2d(4*init_channels, 64, kernel_size, padding=1)\n",
        "\n",
        "        # fully connected layers for learning representations\n",
        "        self.fc1 = nn.Linear(64*16*16, 128)     #Change to 16*16 since that is the dimensions. Note input is flattened\n",
        "        self.fc_mu = nn.Linear(128, latent_dim)\n",
        "        self.fc_log_var = nn.Linear(128, latent_dim)\n",
        "        self.fc2 = nn.Linear(latent_dim, 64)\n",
        "\n",
        "        # decoder \n",
        "        self.dec1 = nn.ConvTranspose2d(64, 8*init_channels, kernel_size, output_padding=1, dilation=3)\n",
        "        self.dec2 = nn.ConvTranspose2d(8*init_channels, 4*init_channels, kernel_size, stride=2, padding=1, output_padding=1)\n",
        "        self.dec3 = nn.ConvTranspose2d(4*init_channels, 2*init_channels, kernel_size, stride=2, padding=1, output_padding=1) #doubling conv transpose\n",
        "        self.dec4 = nn.ConvTranspose2d(2*init_channels, image_channels, kernel_size, stride=2, padding=1, output_padding=1)\n",
        "        self.dec5 = nn.ConvTranspose2d(image_channels, image_channels, kernel_size, stride=2, padding=1, output_padding=1)\n",
        "\n",
        "        #Dropout\n",
        "        self.dropout1 = nn.Dropout(0.5)\n",
        "\n",
        "    def reparameterize(self, mu, log_var):\n",
        "        \"\"\"\n",
        "        :param mu: mean from the encoder's latent space\n",
        "        :param log_var: log variance from the encoder's latent space\n",
        "        \"\"\"\n",
        "        std = torch.exp(0.5*log_var) # standard deviation\n",
        "        eps = torch.randn_like(std) # `randn_like` as we need the same size\n",
        "        sample = mu + (eps * std) # sampling\n",
        "        return sample\n",
        "\n",
        "    def encode(self, x):\n",
        "        x = F.relu(self.enc1(x)) #76  128\n",
        "        x = F.max_pool2d(x, 2) #38    64\n",
        "        x = F.leaky_relu(self.enc2(x)) #38  64\n",
        "        x = F.max_pool2d(x, 2) #19    32\n",
        "        x = F.leaky_relu(self.enc3(x)) #19  32\n",
        "        x = F.leaky_relu(self.enc4(x)) #10  32\n",
        "        x = F.max_pool2d(x, 2) #      16\n",
        "        x = self.dropout1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        return x\n",
        "\n",
        "    def decode(self, x):\n",
        "        x = x.view(-1, 64, 1, 1)\n",
        "        x = F.leaky_relu(self.dec1(x)) #8\n",
        "        x = F.leaky_relu(self.dec2(x)) #16\n",
        "        x = self.dropout1(x)\n",
        "        x = F.leaky_relu(self.dec3(x))  #32\n",
        "        x = F.leaky_relu(self.dec4(x))  #64\n",
        "        x = torch.sigmoid(self.dec5(x))  #128\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward(self, x): #76\n",
        "\n",
        "        #encode\n",
        "        x = self.encode(x)\n",
        "        hidden = self.fc1(x) #(64*10*10, 128)\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        # get `mu` and `log_var`\n",
        "        mu = self.fc_mu(hidden)\n",
        "        log_var = self.fc_log_var(hidden)\n",
        "\n",
        "        # get the latent vector through reparameterization\n",
        "        z = self.reparameterize(mu, log_var) #(64, 16)\n",
        "        z = self.fc2(z) #(64, 64)\n",
        "\n",
        "        #decode\n",
        "        reconstruction = self.decode(z)\n",
        "        \n",
        "        return reconstruction, mu, log_var\n",
        "        \n",
        "        \n",
        "class CVAE2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CVAE2, self).__init__()\n",
        " \n",
        "        kernel_size = 3 # (3, 3) kernel\n",
        "        num_classes = 10\n",
        "        init_channels = 8 # initial number of filters\n",
        "        image_channels = 1\n",
        "        latent_dim = 32 # latent dimension for sampling\n",
        "\n",
        "        # encoder\n",
        "        self.enc1 = nn.Conv2d(image_channels, init_channels, kernel_size, padding=1)\n",
        "        self.enc2 = nn.Conv2d(init_channels, 2*init_channels, kernel_size, padding=1)\n",
        "        #self.enc3 = nn.Conv2d(2*init_channels, 4*init_channels, kernel_size, padding=1)\n",
        "        #self.enc4 = nn.Conv2d(4*init_channels, 64, kernel_size, padding=1)\n",
        "\n",
        "        # fully connected layers for learning representations\n",
        "        self.fc1 = nn.Linear(16*32*32, 128)     #Change to 16*16 since that is the dimensions. Note input is flattened\n",
        "        self.fc_mu = nn.Linear(128, latent_dim)\n",
        "        self.fc_log_var = nn.Linear(128, latent_dim)\n",
        "        self.fc2 = nn.Linear(latent_dim, 64)\n",
        "\n",
        "        # decoder \n",
        "        self.dec1 = nn.ConvTranspose2d(64, 2*init_channels, kernel_size, output_padding=1, dilation=3)\n",
        "        self.dec2 = nn.ConvTranspose2d(2*init_channels, 1*init_channels, kernel_size=5, stride=4, padding=1, output_padding=1) #quadruple conv transpose\n",
        "        self.dec3 = nn.ConvTranspose2d(1*init_channels, image_channels, kernel_size=5, stride=4, padding=1, output_padding=1) #doubling conv transpose\n",
        "        #self.dec4 = nn.ConvTranspose2d(2*init_channels, image_channels, kernel_size, stride=2, padding=1, output_padding=1)\n",
        "        #self.dec5 = nn.ConvTranspose2d(image_channels, image_channels, kernel_size, stride=2, padding=1, output_padding=1)\n",
        "\n",
        "        #Dropout\n",
        "        self.dropout1 = nn.Dropout(0.5)\n",
        "\n",
        "    def reparameterize(self, mu, log_var):\n",
        "        \"\"\"\n",
        "        :param mu: mean from the encoder's latent space\n",
        "        :param log_var: log variance from the encoder's latent space\n",
        "        \"\"\"\n",
        "        std = torch.exp(0.5*log_var) # standard deviation\n",
        "        eps = torch.randn_like(std) # `randn_like` as we need the same size\n",
        "        sample = mu + (eps * std) # sampling\n",
        "        return sample\n",
        "\n",
        "    def encode(self, x):\n",
        "        x = F.relu(self.enc1(x)) #76  128\n",
        "        x = F.max_pool2d(x, 2) #38    64\n",
        "        x = F.relu(self.enc2(x)) #38  64\n",
        "        x = F.max_pool2d(x, 2) #19    32\n",
        "        #x = F.leaky_relu(self.enc3(x)) #19  32\n",
        "        #x = F.leaky_relu(self.enc4(x)) #10  32\n",
        "        #x = F.max_pool2d(x, 2) #      16\n",
        "        x = self.dropout1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        return x\n",
        "\n",
        "    def decode(self, x):\n",
        "        x = x.view(-1, 64, 1, 1)\n",
        "        x = F.relu(self.dec1(x)) #8\n",
        "        x = F.relu(self.dec2(x)) #16\n",
        "        x = self.dropout1(x)\n",
        "        x = torch.sigmoid(self.dec3(x))  #32\n",
        "        #x = F.relu(self.dec4(x))  #64\n",
        "        #x = torch.sigmoid(self.dec5(x))  #128\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward(self, x): #76\n",
        "\n",
        "        #encode\n",
        "        x = self.encode(x)\n",
        "        hidden = self.fc1(x) #(64*10*10, 128)\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        # get `mu` and `log_var`\n",
        "        mu = self.fc_mu(hidden)\n",
        "        log_var = self.fc_log_var(hidden)\n",
        "\n",
        "        # get the latent vector through reparameterization\n",
        "        z = self.reparameterize(mu, log_var) #(64, 16)\n",
        "        z = self.fc2(z) #(64, 64)\n",
        "\n",
        "        #decode\n",
        "        reconstruction = self.decode(z)\n",
        "        \n",
        "        return reconstruction, mu, log_var\n",
        "        \n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        w = (32,64) #Number of channels in 1st and 2nd layers\n",
        "        self.conv1 = nn.Conv2d(1, w[0], 3, 1)       #change first parameter to be a 1 since only one image channel for grayscale\n",
        "        self.conv2 = nn.Conv2d(w[0], w[1], 3, 1)\n",
        "        self.dropout1 = nn.Dropout(0.25)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "\n",
        "        f = 512  #Number of hidden nodes in fully connected layers\n",
        "        #self.fc1 = nn.Linear(w[1]*10*10, f)\n",
        "        self.fc1 = nn.Linear(64*15*15, f)\n",
        "        self.fc2 = nn.Linear(f, 10)\n",
        "        self.bn1 = nn.BatchNorm1d(f)\n",
        "\n",
        "    def forward(self, x): #88  #128\n",
        "        x = self.conv1(x) #86  #126\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2) #43  #63  #124\n",
        "        x = self.conv2(x) #41  #66  @122\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 4)  #10  #15  @120\n",
        "        x = self.dropout1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.bn1(x)   #batch normalization\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output\n",
        "\n",
        "    #This is useful for extracting features from convolutional part of NN\n",
        "    def encode(self, x):\n",
        "        x = self.conv1(x) #86\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2) #43\n",
        "        x = self.conv2(x) #41\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 4)  #10\n",
        "        x = self.dropout1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        return x"
      ],
      "metadata": {
        "id": "VMJkDNAlxA5S"
      },
      "id": "VMJkDNAlxA5S",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Active Learning"
      ],
      "metadata": {
        "id": "FEPyIbxlxB19"
      },
      "id": "FEPyIbxlxB19"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2581356"
      },
      "outputs": [],
      "source": [
        "#Pick one of 'mstar', 'open_sar', 'fusar'\n",
        "dataset_chosen = 'fusar'\n",
        "\n",
        "#This uses a CNNVAE to get embeddings\n",
        "# **I think this actually uses the fully trained and not a CNNVAE\n",
        "#Currently we always use the VAE for MSTAR since the knn_data is already stored for this\n",
        "\n",
        "use_fully_trained_features = False\n",
        "just_transfer              = False\n",
        "transfer_and_train         = True\n",
        "\n",
        "assert(use_fully_trained_features + just_transfer + transfer_and_train == 1)\n",
        "\n",
        "#If you specify this, then it will use a specific trained NN for embeddings\n",
        "#If none, it will pick the ones deemed optimal from prior testing\n",
        "#  I recommend using None\n",
        "transfer_encoding = None\n",
        "\n",
        "#Determines the number of points in the coreset\n",
        "#Larger values correspond to smaller coresets\n",
        "density_radius_param = .5\n",
        "\n",
        "knn_num = 17"
      ],
      "id": "a2581356"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0012688e",
        "scrolled": false,
        "outputId": "75916870-96af-4c50-f042-4c864774fb4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "169\n",
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.6106 Acc: 0.0651\n",
            "val Loss: 1.6143 Acc: 0.0278\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.6095 Acc: 0.0710\n",
            "val Loss: 1.6132 Acc: 0.0278\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.6062 Acc: 0.0947\n",
            "val Loss: 1.6107 Acc: 0.0278\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.6029 Acc: 0.1420\n",
            "val Loss: 1.6068 Acc: 0.0278\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.5989 Acc: 0.2781\n",
            "val Loss: 1.6034 Acc: 0.0556\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.5939 Acc: 0.3905\n",
            "val Loss: 1.5977 Acc: 0.1806\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.5905 Acc: 0.4497\n",
            "val Loss: 1.5915 Acc: 0.3889\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.5868 Acc: 0.4556\n",
            "val Loss: 1.5951 Acc: 0.3056\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 1.5855 Acc: 0.4497\n",
            "val Loss: 1.5927 Acc: 0.2917\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 1.5853 Acc: 0.4320\n",
            "val Loss: 1.5933 Acc: 0.2778\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 1.5845 Acc: 0.4556\n",
            "val Loss: 1.5940 Acc: 0.3750\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 1.5834 Acc: 0.4497\n",
            "val Loss: 1.5924 Acc: 0.3889\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 1.5847 Acc: 0.4438\n",
            "val Loss: 1.5925 Acc: 0.3889\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 1.5824 Acc: 0.4615\n",
            "val Loss: 1.5894 Acc: 0.3750\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 1.5825 Acc: 0.4379\n",
            "val Loss: 1.5887 Acc: 0.4167\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 1.5820 Acc: 0.4497\n",
            "val Loss: 1.5892 Acc: 0.3889\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 1.5832 Acc: 0.4497\n",
            "val Loss: 1.5896 Acc: 0.4028\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 1.5827 Acc: 0.4379\n",
            "val Loss: 1.5906 Acc: 0.4306\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 1.5831 Acc: 0.4438\n",
            "val Loss: 1.5887 Acc: 0.4306\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 1.5823 Acc: 0.4438\n",
            "val Loss: 1.5899 Acc: 0.4306\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 1.5816 Acc: 0.4438\n",
            "val Loss: 1.5874 Acc: 0.4167\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 1.5821 Acc: 0.4497\n",
            "val Loss: 1.5891 Acc: 0.4167\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 1.5827 Acc: 0.4379\n",
            "val Loss: 1.5878 Acc: 0.4444\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 1.5832 Acc: 0.4438\n",
            "val Loss: 1.5882 Acc: 0.4306\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 1.5835 Acc: 0.4320\n",
            "val Loss: 1.5872 Acc: 0.4444\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 1.5831 Acc: 0.4497\n",
            "val Loss: 1.5868 Acc: 0.4167\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 1.5822 Acc: 0.4497\n",
            "val Loss: 1.5873 Acc: 0.4028\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 1.5832 Acc: 0.4615\n",
            "val Loss: 1.5861 Acc: 0.4167\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 1.5820 Acc: 0.4379\n",
            "val Loss: 1.5858 Acc: 0.4306\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 1.5826 Acc: 0.4556\n",
            "val Loss: 1.5864 Acc: 0.4306\n",
            "\n",
            "Training complete in 1m 28s\n",
            "Best val Acc: 0.444444\n",
            "Constructing Graph Learning Objects\n",
            "(4856, 1024)\n",
            "Complete\n",
            "Time taken = 106.93502773\n"
          ]
        }
      ],
      "source": [
        "start = timeit.default_timer()\n",
        "with torch.no_grad():\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "if dataset_chosen == 'open_sar':\n",
        "  #Load labels\n",
        "  data, labels = utils.load_dataset('open_sar_ship', return_torch = False, concatenate = True)\n",
        "elif dataset_chosen == 'fusar':\n",
        "  #Load labels\n",
        "  data, labels = utils.load_dataset('fusar', return_torch = False, concatenate = True)\n",
        "elif dataset_chosen == 'mstar':\n",
        "  hdr, fields, mag, phase = utils.load_MSTAR('data/MSTAR/')\n",
        "  data = utils.polar_transform(mag, phase)\n",
        "  labels, target_names = utils.targets_to_labels(hdr)\n",
        "else:\n",
        "  assert False, \"Chosen dataset could not be loaded. Check for typos\"\n",
        "\n",
        "knn_data = None\n",
        "\n",
        "#Mimic that we know a percentage of data, and don't know for the rest\n",
        "#Do transfer learning merely using these\n",
        "percent_known_data = 0.05\n",
        "known_data_ind = gl.trainsets.generate(labels, rate=percent_known_data).tolist()\n",
        "known_data = data[known_data_ind]\n",
        "known_labels = labels[known_data_ind]\n",
        "\n",
        "# print(len(known_data))\n",
        "\n",
        "#Generate the initial set\n",
        "initial = gl.trainsets.generate(labels, rate=1).tolist()\n",
        "\n",
        "#Percent of known data to use as training data for transfer learning\n",
        "training_percent = 0.7\n",
        "transfer_train_ind = random.sample(range(len(known_data)), round(len(known_data)*training_percent))\n",
        "transfer_testing_ind = np.array([ind for ind in range(len(known_data)) if ind not in transfer_train_ind]).astype(int)\n",
        "\n",
        "#Convert to torch for use\n",
        "known_data = torch.from_numpy(known_data)\n",
        "known_labels = torch.from_numpy(known_labels)\n",
        "\n",
        "\n",
        "#print(len(transfer_testing_ind))\n",
        "training_data = known_data[transfer_train_ind]\n",
        "training_label = known_labels[transfer_train_ind]\n",
        "testing_data = known_data[transfer_testing_ind]\n",
        "testing_label = known_labels[transfer_testing_ind]\n",
        "\n",
        "print(len(training_data))\n",
        "print(len(testing_data))\n",
        "\n",
        "data_info=[training_data, training_label, testing_data, testing_label]\n",
        "for item in data_info:\n",
        "  item = item.float()\n",
        "\n",
        "        \n",
        "if dataset_chosen == 'open_sar':\n",
        "    #Load encoded dataset\n",
        "    if use_fully_trained_features:\n",
        "        X = utils.encode_dataset('open_sar_ship','/content/drive/MyDrive/OpenSarShip_CNNVAE.pt')\n",
        "    elif just_transfer:\n",
        "        X, labels = utils.encode_pretrained('open_sar_ship', 'AlexNet', transformed=True)\n",
        "    else:\n",
        "        X = utils.encode_transfer_learning('open_sar_ship', model_type='AlexNet', transfer_batch_size=64, epochs=30, data_info=data_info)\n",
        "    #Load labels\n",
        "    _, labels = utils.load_dataset('open_sar_ship', return_torch = False, concatenate = True)\n",
        "    knn_data = gl.weightmatrix.knnsearch(X, knn_num, method='annoy', similarity='angular')\n",
        "elif dataset_chosen == 'fusar':\n",
        "    #Load encoded dataset\n",
        "    if use_fully_trained_features:\n",
        "        X = utils.encode_dataset('fusar','/content/drive/MyDrive/Fusar_CNNVAE.pt')\n",
        "    elif just_transfer:\n",
        "        X, labels = utils.encode_pretrained('fusar', 'ShuffleNet', normalized=True, transformed=True)\n",
        "    else:\n",
        "        X = utils.encode_transfer_learning('fusar', model_type='ShuffleNet', transfer_batch_size=64, epochs=30, data_info=data_info)\n",
        "    #Load labels\n",
        "    _, labels = utils.load_dataset('fusar', return_torch = False, concatenate = True)\n",
        "    knn_data = gl.weightmatrix.knnsearch(X, knn_num, method='annoy', similarity='angular')\n",
        "elif dataset_chosen == 'mstar':\n",
        "    knn_constructed = False\n",
        "    if use_fully_trained_features:\n",
        "        X = utils.encodeMSTAR('/content/drive/MyDrive/SAR10_CNNVAE.pt', cuda=False)\n",
        "        # knn_data = gl.weightmatrix.load_knn_data('sar10', metric='cnnvae') #('knn_data/sar10_cnnvae.npz')\n",
        "        # knn_constructed = True\n",
        "    elif just_transfer:\n",
        "        X, labels = utils.encode_pretrained('mstar', 'ResNet', transformed=False, path = '/content/drive/MyDrive/data/MSTAR')\n",
        "    else:\n",
        "        X = utils.encode_transfer_learning('mstar', model_type = 'ResNet', transfer_batch_size=64, epochs=30, data_info=data_info, transformed=False)\n",
        "    \n",
        "    print(\"Constructing knn_data\")\n",
        "    if not knn_constructed:\n",
        "        knn_data = gl.weightmatrix.knnsearch(X, knn_num, method='annoy', similarity='angular')\n",
        "    \n",
        "    \n",
        "else:\n",
        "    assert False, \"Chosen dataset could not be loaded. Check for typos\"\n",
        "\n",
        "print(\"Constructing Graph Learning Objects\")\n",
        "W = gl.weightmatrix.knn(X, knn_num, kernel = 'gaussian', knn_data=knn_data)\n",
        "G = gl.graph(W)\n",
        "end = timeit.default_timer()\n",
        "\n",
        "print(X.shape)\n",
        "\n",
        "print(\"Complete\")\n",
        "print(f\"Time taken = {end - start}\")"
      ],
      "id": "0012688e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "941dca6c",
        "outputId": "1527119e-e6ca-4889-b92e-2a3480f6bedc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coreset Size = 17\t Percent of data = 0.35%\n",
            "Coreset =  [320, 4817, 1094, 2035, 1001, 3387, 4258, 1793, 185, 696, 2506, 3040, 2435, 4110, 970, 1165, 1112]\n",
            "[0 1 2 3 4 2 3 4 0 4 0 2 4 2 3 4 4]\n"
          ]
        }
      ],
      "source": [
        "#Use the percent radius because it should be more robust across datasets\n",
        "coreset = bal.coreset_dijkstras(G, rad = .2, DEBUGGING=False, data = X, initial=initial, \n",
        "                                density_info = (True, density_radius_param, 1), knn_data=knn_data)\n",
        "print(\"Coreset Size = {}\\t Percent of data = {}%\".format(len(coreset), round(100 * len(coreset) / len(X), 2)))\n",
        "print(\"Coreset = \", coreset)\n",
        "print(labels[coreset])"
      ],
      "id": "941dca6c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a9290f0",
        "outputId": "a6ea61fa-d402-4bff-f393-162eb179fceb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "uc local_max\n",
            "Running half of the iterations takes 8.409820998000214\n",
            "Accuracy for half of the iterations is 80.89711417816812\n",
            "Running all the iterations takes 13.584661629000038\n",
            "Final accuracy is 91.85722253206916\n",
            "91.85722253206916\n"
          ]
        }
      ],
      "source": [
        "# acq_fun_list = ['uc', 'vopt', 'mc', 'mcvopt']\n",
        "\n",
        "acq_fun_list = ['uc']\n",
        "# max_new_samples = 500\n",
        "\n",
        "if dataset_chosen == 'open_sar':\n",
        "  if transfer_and_train:\n",
        "    coreset = coreset + known_data_ind\n",
        "    max_new_samples = 574\n",
        "  else:\n",
        "    max_new_samples = 700\n",
        "\n",
        "if dataset_chosen == 'fusar':\n",
        "  if transfer_and_train:\n",
        "    coreset = coreset + known_data_ind\n",
        "    max_new_samples = 2816\n",
        "  else:\n",
        "    max_new_samples = 3060\n",
        "batchsize=15\n",
        "\n",
        "L_time = []\n",
        "L_num_labels = []\n",
        "L_acc = []\n",
        "L_names = []\n",
        "for acq_fun in acq_fun_list:\n",
        "\n",
        "  num_iter = int(max_new_samples/batchsize)\n",
        "\n",
        "  al_mtd = 'local_max'\n",
        "  print(acq_fun, al_mtd)\n",
        "  list_data_ind, list_num_labels, list_acc, running_time_lm = bal.coreset_run_experiment(X, labels, W, coreset, num_iter=num_iter, method='Laplace',\n",
        "                           display=False, use_prior=False, al_mtd=al_mtd, debug=False,\n",
        "                           acq_fun=acq_fun, knn_data=knn_data, mtd_para=None,\n",
        "                           savefig=False, savefig_folder='../BAL_figures', batchsize=batchsize,\n",
        "                           dist_metric='angular', q=1, thresholding=0, randseed=0)\n",
        "  L_time.append(running_time_lm)\n",
        "  L_num_labels.append(list_num_labels)\n",
        "  L_acc.append(list_acc)\n",
        "  L_names.append(al_mtd)\n",
        "\n",
        "\n",
        "  # al_mtd = 'random'\n",
        "  # print(acq_fun, al_mtd)\n",
        "  # _, list_num_labels, list_acc, running_time_random = bal.coreset_run_experiment(X, labels, W, coreset, num_iter=num_iter, method='Laplace',\n",
        "  #                          display=False, use_prior=False, al_mtd=al_mtd, debug=False,\n",
        "  #                          acq_fun=acq_fun, knn_data=knn_data, mtd_para=None,\n",
        "  #                          savefig=False, savefig_folder='../BAL_figures', batchsize=batchsize,\n",
        "  #                          dist_metric='angular', q=5, thresholding=0, randseed=0)\n",
        "  # L_time.append(running_time_random)\n",
        "  # L_num_labels.append(list_num_labels)\n",
        "  # L_acc.append(list_acc)\n",
        "  # L_names.append(al_mtd)\n",
        "\n",
        "  # al_mtd = 'topn_max'\n",
        "  # print(acq_fun, al_mtd)\n",
        "  # _, list_num_labels, list_acc, running_time_topn = bal.coreset_run_experiment(X, labels, W, coreset, num_iter=num_iter, method='Laplace',\n",
        "  #                          display=False, use_prior=False, al_mtd=al_mtd, debug=False,\n",
        "  #                          acq_fun=acq_fun, knn_data=knn_data, mtd_para=None,\n",
        "  #                          savefig=False, savefig_folder='../BAL_figures', batchsize=batchsize,\n",
        "  #                          dist_metric='angular', q=1, thresholding=0, randseed=0)\n",
        "  # L_time.append(running_time_topn)\n",
        "  # L_num_labels.append(list_num_labels)\n",
        "  # L_acc.append(list_acc)\n",
        "  # L_names.append(al_mtd)\n",
        "\n",
        "\n",
        "\n",
        "  # al_mtd = 'acq_sample'\n",
        "  # print(acq_fun, al_mtd)\n",
        "  # _, list_num_labels, list_acc, running_time_acq = bal.coreset_run_experiment(X, labels, W, coreset, num_iter=num_iter, method='Laplace',\n",
        "  #                          display=False, use_prior=False, al_mtd=al_mtd, debug=False,\n",
        "  #                          acq_fun=acq_fun, knn_data=knn_data, mtd_para=None,\n",
        "  #                          savefig=False, savefig_folder='../BAL_figures', batchsize=batchsize,\n",
        "  #                          dist_metric='angular', q=5, thresholding=0, randseed=0)\n",
        "  # L_time.append(running_time_acq)\n",
        "  # L_num_labels.append(list_num_labels)\n",
        "  # L_acc.append(list_acc)\n",
        "  # L_names.append(al_mtd)\n",
        "\n",
        "\n",
        "  # al_mtd = 'global_max'\n",
        "  # print(acq_fun, al_mtd)\n",
        "  # _, list_num_labels, list_acc, running_time_gm = bal.coreset_run_experiment(X, labels, W, coreset, num_iter=max_new_samples, method='Laplace',\n",
        "  #                          display=False, use_prior=False, al_mtd=al_mtd, debug=False,\n",
        "  #                          acq_fun=acq_fun, knn_data=knn_data, mtd_para=None,\n",
        "  #                          savefig=False, savefig_folder='../BAL_figures', batchsize=batchsize,\n",
        "  #                          dist_metric='angular', q=5, thresholding=0, randseed=0)\n",
        "  # L_time.append(running_time_gm)\n",
        "  # L_num_labels.append(list_num_labels)\n",
        "  # L_acc.append(list_acc)\n",
        "  # L_names.append(al_mtd)\n",
        "\n",
        "  # al_mtd = 'gd_kmeans'\n",
        "  # print(acq_fun, al_mtd)\n",
        "  # _, list_num_labels, list_acc, running_time_acq = bal.coreset_run_experiment(X, labels, W, coreset, num_iter=num_iter, method='Laplace',\n",
        "  #                          display=False, use_prior=False, al_mtd=al_mtd, debug=False,\n",
        "  #                          acq_fun=acq_fun, knn_data=knn_data, mtd_para=None,\n",
        "  #                          savefig=False, savefig_folder='../BAL_figures', batchsize=batchsize,\n",
        "  #                          dist_metric='angular', q=5, thresholding=0, randseed=0)\n",
        "  # L_time.append(running_time_acq)\n",
        "  # L_num_labels.append(list_num_labels)\n",
        "  # L_acc.append(list_acc)\n",
        "  # L_names.append(al_mtd)\n",
        "\n",
        "print(L_acc[0][-1])"
      ],
      "id": "8a9290f0"
    },
    {
      "cell_type": "code",
      "source": [
        "list_data_ind = list(list_data_ind)\n",
        "total_data = known_data_ind + list_data_ind\n",
        "print(len(set(total_data))/len(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FWN-VGj7U_B",
        "outputId": "ef0fcfd9-d2c1-440e-8ba9-88c7ba8dc5dd"
      },
      "id": "0FWN-VGj7U_B",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6307660626029654\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4fbOzG_QXKT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 762
        },
        "outputId": "ec183e3e-73f8-413c-ff43-410284507274"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "74.18341708542714\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-eae2dac11161>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL_num_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL_acc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0macq_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmarker_types\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarkevery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarkersize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;31m# ax1.plot(L_num_labels[i], L_acc[i], label=acq_list[i], linewidth=3, marker=marker_types[i], markevery=3, markersize=15)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 900x612 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "print(L_acc[0][-1])\n",
        "fontsize=25\n",
        "\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.set_size_inches(12.5, 8.5)\n",
        "ax1 = fig.add_subplot()\n",
        "ax2 = ax1.twiny()\n",
        "\n",
        "acq_list = ['uc', 'vopt', 'mc', 'mcvopt']\n",
        "\n",
        "marker_types = [\"^\", \"o\", \"d\", \"p\"]\n",
        "\n",
        "for i in range(len(L_acc)):\n",
        "    ax1.plot(L_num_labels[i], L_acc[i], label=acq_list[i], linewidth=3, marker=marker_types[i], markevery=10, markersize=15)\n",
        "    # ax1.plot(L_num_labels[i], L_acc[i], label=acq_list[i], linewidth=3, marker=marker_types[i], markevery=3, markersize=15)\n",
        "\n",
        "    # ax1.plot(L_num_labels[i], L_acc[i], label=L_names[i], linewidth=3)\n",
        "\n",
        "#SOTA for Fusar\n",
        "ax1.plot(L_num_labels[0], 87.16 * np.ones_like(L_num_labels[0]), label='SoTA', linestyle='--')\n",
        "ax1.plot(L_num_labels[0], 75.36 * np.ones_like(L_num_labels[0]), label='TL', linestyle='--')\n",
        "#SOTA for Opensar\n",
        "# ax1.plot(L_num_labels[0], 77.87 * np.ones_like(L_num_labels[0]), label='SoTA', linestyle='--')\n",
        "# ax1.plot(L_num_labels[0], 76.99 * np.ones_like(L_num_labels[0]), label='TL', linestyle='--')\n",
        "#SOTA for MSTAR\n",
        "# ax1.plot(L_num_labels[0], 98.42 * np.ones_like(L_num_labels[0]), label='SoTA', linestyle='--')\n",
        "ax1.legend(fontsize=fontsize)\n",
        "ax1.set_xlabel(r\"Number of labeled points\", fontsize=fontsize)\n",
        "ax1.set_ylabel(\"Accuracy (%)\", fontsize=fontsize)\n",
        "ax1.set_ylim((None, 100))\n",
        "\n",
        "# title_str = 'Coreset size: ' + str(len(coreset)) + '; GL method: Laplace; Al function: local max' + '\\n'\n",
        "title_str = 'Coreset size: ' + str(len(coreset)) + '; GL method: Laplace; Acquisition function: uc' + '\\n'\n",
        "title_str += 'Fusar: Batch Size: ' + str(batchsize) + '; Total num data: ' + str(X.shape[0])\n",
        "\n",
        "# plt.title(title_str)\n",
        "\n",
        "# new_tick_locations = np.linspace(0, 0.3, 5) * X.shape[0]\n",
        "new_tick_locations = np.linspace(0, 0.63, 6) * X.shape[0]\n",
        "\n",
        "\n",
        "def tick_function(X, n):\n",
        "    V = X / n\n",
        "    return [\"%d%%\" % np.round(100*z) for z in V]\n",
        "\n",
        "ax2.set_xlim(ax1.get_xlim())\n",
        "ax2.set_xticks(new_tick_locations)\n",
        "ax2.set_xticklabels(tick_function(new_tick_locations, X.shape[0]), fontsize=fontsize)\n",
        "ax2.set_xlabel(r\"Percentage of Training Data\", fontsize=fontsize)\n",
        "\n",
        "ax1.tick_params(axis='both', labelsize=fontsize)\n",
        "ax2.tick_params(axis='both', labelsize=fontsize)\n",
        "\n",
        "\n",
        "plt.savefig('Time Efficiency Fusar.eps', bbox_inches='tight')\n",
        "# files.download(\"Time Efficiency Fusar.eps\") \n",
        "plt.show()\n"
      ],
      "id": "E4fbOzG_QXKT"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test for Average Behavior"
      ],
      "metadata": {
        "id": "ae9J6y3pcUTG"
      },
      "id": "ae9J6y3pcUTG"
    },
    {
      "cell_type": "code",
      "source": [
        "#Pick one of 'mstar', 'open_sar', 'fusar'\n",
        "dataset_chosen = 'fusar'\n",
        "\n",
        "#This uses a CNNVAE to get embeddings\n",
        "# **I think this actually uses the fully trained and not a CNNVAE\n",
        "#Currently we always use the VAE for MSTAR since the knn_data is already stored for this\n",
        "\n",
        "use_fully_trained_features = False\n",
        "just_transfer              = False\n",
        "transfer_and_train         = True\n",
        "\n",
        "assert(use_fully_trained_features + just_transfer + transfer_and_train == 1)\n",
        "\n",
        "#If you specify this, then it will use a specific trained NN for embeddings\n",
        "#If none, it will pick the ones deemed optimal from prior testing\n",
        "#  I recommend using None\n",
        "transfer_encoding = None\n",
        "\n",
        "#Determines the number of points in the coreset\n",
        "#Larger values correspond to smaller coresets\n",
        "density_radius_param = .5\n",
        "\n",
        "knn_num = 17"
      ],
      "metadata": {
        "id": "UWLHYaFLdDy9"
      },
      "id": "UWLHYaFLdDy9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_time = 50\n",
        "\n",
        "final_acc_list = []\n",
        "for i in range(experiment_time):\n",
        "  print(\"This is experiment \" + str(i))\n",
        "\n",
        "  start = timeit.default_timer()\n",
        "  with torch.no_grad():\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "  if dataset_chosen == 'open_sar':\n",
        "    #Load labels\n",
        "    data, labels = utils.load_dataset('open_sar_ship', return_torch = False, concatenate = True)\n",
        "  elif dataset_chosen == 'fusar':\n",
        "    #Load labels\n",
        "    data, labels = utils.load_dataset('fusar', return_torch = False, concatenate = True)\n",
        "  elif dataset_chosen == 'mstar':\n",
        "    hdr, fields, mag, phase = utils.load_MSTAR('data/MSTAR/')\n",
        "    data = utils.polar_transform(mag, phase)\n",
        "    labels, target_names = utils.targets_to_labels(hdr)\n",
        "  else:\n",
        "    assert False, \"Chosen dataset could not be loaded. Check for typos\"\n",
        "\n",
        "  knn_data = None\n",
        "\n",
        "  #Mimic that we know a percentage of data, and don't know for the rest\n",
        "  #Do transfer learning merely using these\n",
        "  percent_known_data = 0.05\n",
        "  known_data_ind = gl.trainsets.generate(labels, rate=percent_known_data).tolist()\n",
        "  known_data = data[known_data_ind]\n",
        "  known_labels = labels[known_data_ind]\n",
        "\n",
        "  # print(len(known_data))\n",
        "\n",
        "  #Generate the initial set\n",
        "  initial = gl.trainsets.generate(labels, rate=1).tolist()\n",
        "\n",
        "  #Percent of known data to use as training data for transfer learning\n",
        "  training_percent = 0.7\n",
        "  transfer_train_ind = random.sample(range(len(known_data)), round(len(known_data)*training_percent))\n",
        "  transfer_testing_ind = np.array([ind for ind in range(len(known_data)) if ind not in transfer_train_ind]).astype(int)\n",
        "\n",
        "  #Convert to torch for use\n",
        "  known_data = torch.from_numpy(known_data)\n",
        "  known_labels = torch.from_numpy(known_labels)\n",
        "\n",
        "\n",
        "  #print(len(transfer_testing_ind))\n",
        "  training_data = known_data[transfer_train_ind]\n",
        "  training_label = known_labels[transfer_train_ind]\n",
        "  testing_data = known_data[transfer_testing_ind]\n",
        "  testing_label = known_labels[transfer_testing_ind]\n",
        "\n",
        "  print(len(training_data))\n",
        "  print(len(testing_data))\n",
        "\n",
        "  data_info=[training_data, training_label, testing_data, testing_label]\n",
        "  for item in data_info:\n",
        "    item = item.float()\n",
        "\n",
        "          \n",
        "  if dataset_chosen == 'open_sar':\n",
        "      #Load encoded dataset\n",
        "      if use_fully_trained_features:\n",
        "          X = utils.encode_dataset('open_sar_ship','/content/drive/MyDrive/OpenSarShip_CNNVAE.pt')\n",
        "      elif just_transfer:\n",
        "          X, labels = utils.encode_pretrained('open_sar_ship', 'AlexNet', transformed=True)\n",
        "      else:\n",
        "          X = utils.encode_transfer_learning('open_sar_ship', model_type='AlexNet', transfer_batch_size=64, epochs=30, data_info=data_info, transformed=False)\n",
        "      #Load labels\n",
        "      _, labels = utils.load_dataset('open_sar_ship', return_torch = False, concatenate = True)\n",
        "      knn_data = gl.weightmatrix.knnsearch(X, knn_num, method='annoy', similarity='angular')\n",
        "  elif dataset_chosen == 'fusar':\n",
        "      #Load encoded dataset\n",
        "      if use_fully_trained_features:\n",
        "          X = utils.encode_dataset('fusar','/content/drive/MyDrive/Fusar_CNNVAE.pt')\n",
        "      elif just_transfer:\n",
        "          X, labels = utils.encode_pretrained('fusar', 'ShuffleNet', normalized=True, transformed=True)\n",
        "      else:\n",
        "          X = utils.encode_transfer_learning('fusar', model_type='ShuffleNet', transfer_batch_size=64, epochs=30, data_info=data_info, transformed=False)\n",
        "      #Load labels\n",
        "      _, labels = utils.load_dataset('fusar', return_torch = False, concatenate = True)\n",
        "      knn_data = gl.weightmatrix.knnsearch(X, knn_num, method='annoy', similarity='angular')\n",
        "  elif dataset_chosen == 'mstar':\n",
        "      knn_constructed = False\n",
        "      if use_fully_trained_features:\n",
        "          X = utils.encodeMSTAR('/content/drive/MyDrive/SAR10_CNNVAE.pt', cuda=False)\n",
        "          # knn_data = gl.weightmatrix.load_knn_data('sar10', metric='cnnvae') #('knn_data/sar10_cnnvae.npz')\n",
        "          # knn_constructed = True\n",
        "      elif just_transfer:\n",
        "          X, labels = utils.encode_pretrained('mstar', 'ResNet', transformed=False, path = '/content/drive/MyDrive/data/MSTAR')\n",
        "      else:\n",
        "          X = utils.encode_transfer_learning('mstar', model_type = 'ResNet', transfer_batch_size=64, epochs=30, data_info=data_info, transformed=False)\n",
        "      \n",
        "      print(\"Constructing knn_data\")\n",
        "      if not knn_constructed:\n",
        "          knn_data = gl.weightmatrix.knnsearch(X, knn_num, method='annoy', similarity='angular')\n",
        "      \n",
        "      \n",
        "  else:\n",
        "      assert False, \"Chosen dataset could not be loaded. Check for typos\"\n",
        "\n",
        "  print(\"Constructing Graph Learning Objects\")\n",
        "  W = gl.weightmatrix.knn(X, knn_num, kernel = 'gaussian', knn_data=knn_data)\n",
        "  G = gl.graph(W)\n",
        "  end = timeit.default_timer()\n",
        "\n",
        "  print(X.shape)\n",
        "\n",
        "  print(\"Complete\")\n",
        "  print(f\"Time taken = {end - start}\")\n",
        "\n",
        "\n",
        "\n",
        "  #Use the percent radius because it should be more robust across datasets\n",
        "  coreset = bal.coreset_dijkstras(G, rad = .2, DEBUGGING=False, data = X, initial=initial, \n",
        "                                  density_info = (True, density_radius_param, 1), knn_data=knn_data)\n",
        "  print(\"Coreset Size = {}\\t Percent of data = {}%\".format(len(coreset), round(100 * len(coreset) / len(X), 2)))\n",
        "  print(\"Coreset = \", coreset)\n",
        "  print(labels[coreset])\n",
        "\n",
        "\n",
        "  al_mtd = 'local_max'\n",
        "  acq_fun = 'uc'\n",
        "  if dataset_chosen == 'open_sar':\n",
        "    if transfer_and_train:\n",
        "      coreset = coreset + known_data_ind\n",
        "      max_new_samples = 574\n",
        "    else:\n",
        "      max_new_samples = 700\n",
        "\n",
        "  if dataset_chosen == 'fusar':\n",
        "    if transfer_and_train:\n",
        "      coreset = coreset + known_data_ind\n",
        "      max_new_samples = 2816\n",
        "    else:\n",
        "      max_new_samples = 3060\n",
        "  batchsize=15\n",
        "\n",
        "  num_iter = int(max_new_samples/batchsize)\n",
        "  print(acq_fun, al_mtd)\n",
        "  list_data_ind, list_num_labels, list_acc, running_time_lm = bal.coreset_run_experiment(X, labels, W, coreset, num_iter=num_iter, method='Laplace',\n",
        "                           display=False, use_prior=False, al_mtd=al_mtd, debug=False,\n",
        "                           acq_fun=acq_fun, knn_data=knn_data, mtd_para=None,\n",
        "                           savefig=False, savefig_folder='../BAL_figures', batchsize=batchsize,\n",
        "                           dist_metric='angular', q=1, thresholding=0, randseed=0)\n",
        "  final_acc_list.append(list_acc[-1])\n",
        "  print(list_acc[-1])\n",
        "print(final_acc_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3w3PJ04cXw0",
        "outputId": "3f47e638-21b9-4397-849d-0a750d5b4cb3"
      },
      "id": "G3w3PJ04cXw0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is experiment 0\n",
            "169\n",
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ShuffleNet_V2_X0_5_Weights.IMAGENET1K_V1`. You can also use `weights=ShuffleNet_V2_X0_5_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/utils.py:354: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  outputs = nn.functional.log_softmax(outputs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 1.6151 Acc: 0.1598\n",
            "val Loss: 1.6097 Acc: 0.0278\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.6135 Acc: 0.2071\n",
            "val Loss: 1.6071 Acc: 0.0694\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.6120 Acc: 0.2722\n",
            "val Loss: 1.6059 Acc: 0.0694\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.6073 Acc: 0.3491\n",
            "val Loss: 1.6026 Acc: 0.2083\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.6052 Acc: 0.4201\n",
            "val Loss: 1.5975 Acc: 0.4444\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.6002 Acc: 0.4142\n",
            "val Loss: 1.5949 Acc: 0.4444\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.5955 Acc: 0.4201\n",
            "val Loss: 1.5895 Acc: 0.4722\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.5916 Acc: 0.4201\n",
            "val Loss: 1.5885 Acc: 0.4722\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 1.5908 Acc: 0.4201\n",
            "val Loss: 1.5885 Acc: 0.4722\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 1.5908 Acc: 0.4201\n",
            "val Loss: 1.5899 Acc: 0.4722\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 1.5907 Acc: 0.4201\n",
            "val Loss: 1.5891 Acc: 0.4722\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 1.5904 Acc: 0.4201\n",
            "val Loss: 1.5865 Acc: 0.4722\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 1.5901 Acc: 0.4201\n",
            "val Loss: 1.5868 Acc: 0.4722\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 1.5895 Acc: 0.4201\n",
            "val Loss: 1.5848 Acc: 0.4722\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 1.5877 Acc: 0.4201\n",
            "val Loss: 1.5846 Acc: 0.4583\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 1.5897 Acc: 0.4201\n",
            "val Loss: 1.5832 Acc: 0.4722\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 1.5884 Acc: 0.4201\n",
            "val Loss: 1.5841 Acc: 0.4722\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 1.5877 Acc: 0.4201\n",
            "val Loss: 1.5836 Acc: 0.4722\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 1.5895 Acc: 0.4201\n",
            "val Loss: 1.5849 Acc: 0.4722\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 1.5891 Acc: 0.4201\n",
            "val Loss: 1.5820 Acc: 0.4722\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 1.5881 Acc: 0.4201\n",
            "val Loss: 1.5807 Acc: 0.4722\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 1.5880 Acc: 0.4201\n",
            "val Loss: 1.5828 Acc: 0.4722\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 1.5889 Acc: 0.4201\n",
            "val Loss: 1.5826 Acc: 0.4722\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 1.5871 Acc: 0.4201\n",
            "val Loss: 1.5841 Acc: 0.4722\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 1.5889 Acc: 0.4201\n",
            "val Loss: 1.5814 Acc: 0.4722\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 1.5895 Acc: 0.4201\n",
            "val Loss: 1.5832 Acc: 0.4722\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 1.5884 Acc: 0.4201\n",
            "val Loss: 1.5852 Acc: 0.4722\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 1.5882 Acc: 0.4201\n",
            "val Loss: 1.5834 Acc: 0.4722\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 1.5881 Acc: 0.4201\n",
            "val Loss: 1.5824 Acc: 0.4722\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 1.5878 Acc: 0.4201\n",
            "val Loss: 1.5824 Acc: 0.4722\n",
            "\n",
            "Training complete in 1m 38s\n",
            "Best val Acc: 0.472222\n",
            "Constructing Graph Learning Objects\n",
            "(4856, 1024)\n",
            "Complete\n",
            "Time taken = 112.05753512199954\n",
            "Coreset Size = 19\t Percent of data = 0.39%\n",
            "Coreset =  [2530, 4079, 4214, 4444, 1453, 1622, 1495, 3874, 2119, 3657, 2141, 3421, 2962, 3808, 3586, 3372, 3019, 2235, 1055]\n",
            "[0 1 2 3 4 4 0 2 4 0 4 2 4 0 4 2 4 2 0]\n",
            "uc local_max\n",
            "Running half of the iterations takes 8.21365525299916\n",
            "Accuracy for half of the iterations is 75.64344005021971\n",
            "Running all the iterations takes 13.307258912001998\n",
            "Final accuracy is 88.38637632607482\n",
            "88.38637632607482\n",
            "This is experiment 1\n",
            "169\n",
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.6056 Acc: 0.3964\n",
            "val Loss: 1.6025 Acc: 0.4028\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.6038 Acc: 0.4024\n",
            "val Loss: 1.6009 Acc: 0.4306\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.6010 Acc: 0.4260\n",
            "val Loss: 1.5964 Acc: 0.4444\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.5994 Acc: 0.4320\n",
            "val Loss: 1.5933 Acc: 0.4444\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.5949 Acc: 0.4320\n",
            "val Loss: 1.5872 Acc: 0.4444\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.5905 Acc: 0.4320\n",
            "val Loss: 1.5852 Acc: 0.4444\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.5873 Acc: 0.4320\n",
            "val Loss: 1.5796 Acc: 0.4444\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.5832 Acc: 0.4320\n",
            "val Loss: 1.5810 Acc: 0.4444\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 1.5834 Acc: 0.4260\n",
            "val Loss: 1.5811 Acc: 0.4444\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 1.5829 Acc: 0.4320\n",
            "val Loss: 1.5816 Acc: 0.4306\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 1.5819 Acc: 0.4320\n",
            "val Loss: 1.5808 Acc: 0.4444\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 1.5822 Acc: 0.4320\n",
            "val Loss: 1.5795 Acc: 0.4444\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 1.5801 Acc: 0.4320\n",
            "val Loss: 1.5798 Acc: 0.4444\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 1.5803 Acc: 0.4320\n",
            "val Loss: 1.5783 Acc: 0.4444\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 1.5815 Acc: 0.4320\n",
            "val Loss: 1.5782 Acc: 0.4444\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 1.5796 Acc: 0.4320\n",
            "val Loss: 1.5804 Acc: 0.4444\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 1.5801 Acc: 0.4320\n",
            "val Loss: 1.5784 Acc: 0.4444\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 1.5813 Acc: 0.4320\n",
            "val Loss: 1.5777 Acc: 0.4444\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 1.5797 Acc: 0.4320\n",
            "val Loss: 1.5764 Acc: 0.4444\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 1.5802 Acc: 0.4320\n",
            "val Loss: 1.5792 Acc: 0.4444\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 1.5797 Acc: 0.4320\n",
            "val Loss: 1.5791 Acc: 0.4444\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 1.5805 Acc: 0.4320\n",
            "val Loss: 1.5761 Acc: 0.4444\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 1.5792 Acc: 0.4320\n",
            "val Loss: 1.5773 Acc: 0.4444\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 1.5792 Acc: 0.4320\n",
            "val Loss: 1.5762 Acc: 0.4444\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 1.5802 Acc: 0.4320\n",
            "val Loss: 1.5760 Acc: 0.4444\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 1.5796 Acc: 0.4320\n",
            "val Loss: 1.5752 Acc: 0.4444\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 1.5794 Acc: 0.4320\n",
            "val Loss: 1.5768 Acc: 0.4444\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 1.5800 Acc: 0.4320\n",
            "val Loss: 1.5765 Acc: 0.4444\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 1.5810 Acc: 0.4320\n",
            "val Loss: 1.5772 Acc: 0.4444\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 1.5798 Acc: 0.4320\n",
            "val Loss: 1.5770 Acc: 0.4444\n",
            "\n",
            "Training complete in 1m 38s\n",
            "Best val Acc: 0.444444\n",
            "Constructing Graph Learning Objects\n",
            "(4856, 1024)\n",
            "Complete\n",
            "Time taken = 111.43493261700132\n",
            "Coreset Size = 20\t Percent of data = 0.41%\n",
            "Coreset =  [4369, 2803, 3490, 3347, 4565, 3877, 2172, 554, 2701, 3668, 3170, 2164, 1339, 1395, 2823, 1969, 4411, 1689, 1052, 1037]\n",
            "[0 1 2 3 4 0 2 2 0 0 4 0 2 4 1 4 0 4 0 4]\n",
            "uc local_max\n",
            "Running half of the iterations takes 8.754679072000727\n",
            "Accuracy for half of the iterations is 74.19152276295134\n",
            "Running all the iterations takes 14.164618726001208\n",
            "Final accuracy is 86.42458100558659\n",
            "86.42458100558659\n",
            "This is experiment 2\n",
            "169\n",
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.6201 Acc: 0.1657\n",
            "val Loss: 1.6215 Acc: 0.1250\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.6201 Acc: 0.1598\n",
            "val Loss: 1.6192 Acc: 0.1250\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.6171 Acc: 0.1598\n",
            "val Loss: 1.6165 Acc: 0.1250\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.6139 Acc: 0.1657\n",
            "val Loss: 1.6144 Acc: 0.1528\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.6106 Acc: 0.1657\n",
            "val Loss: 1.6109 Acc: 0.1528\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.6060 Acc: 0.1716\n",
            "val Loss: 1.6051 Acc: 0.1528\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.6031 Acc: 0.1479\n",
            "val Loss: 1.6008 Acc: 0.1250\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.5984 Acc: 0.1893\n",
            "val Loss: 1.6009 Acc: 0.1250\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 1.5998 Acc: 0.1657\n",
            "val Loss: 1.5977 Acc: 0.1111\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 1.5991 Acc: 0.1893\n",
            "val Loss: 1.5981 Acc: 0.1806\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 1.5986 Acc: 0.1893\n",
            "val Loss: 1.5960 Acc: 0.2222\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 1.5965 Acc: 0.1834\n",
            "val Loss: 1.5977 Acc: 0.2083\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 1.5970 Acc: 0.1953\n",
            "val Loss: 1.5954 Acc: 0.2222\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 1.5967 Acc: 0.1893\n",
            "val Loss: 1.5951 Acc: 0.1667\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 1.5959 Acc: 0.1834\n",
            "val Loss: 1.5969 Acc: 0.2083\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 1.5968 Acc: 0.1598\n",
            "val Loss: 1.5955 Acc: 0.1944\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 1.5960 Acc: 0.2012\n",
            "val Loss: 1.5952 Acc: 0.1806\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 1.5963 Acc: 0.1953\n",
            "val Loss: 1.5945 Acc: 0.1806\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 1.5949 Acc: 0.2308\n",
            "val Loss: 1.5935 Acc: 0.2361\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 1.5964 Acc: 0.2189\n",
            "val Loss: 1.5955 Acc: 0.1389\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 1.5982 Acc: 0.1657\n",
            "val Loss: 1.5946 Acc: 0.1806\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 1.5944 Acc: 0.2308\n",
            "val Loss: 1.5950 Acc: 0.1806\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 1.5965 Acc: 0.1893\n",
            "val Loss: 1.5971 Acc: 0.1389\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 1.5951 Acc: 0.2367\n",
            "val Loss: 1.5937 Acc: 0.2500\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 1.5965 Acc: 0.2130\n",
            "val Loss: 1.5958 Acc: 0.1944\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 1.5974 Acc: 0.1657\n",
            "val Loss: 1.5964 Acc: 0.1389\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 1.5956 Acc: 0.2071\n",
            "val Loss: 1.5937 Acc: 0.1806\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 1.5964 Acc: 0.2189\n",
            "val Loss: 1.5931 Acc: 0.2083\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 1.5950 Acc: 0.2130\n",
            "val Loss: 1.5958 Acc: 0.1667\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 1.5955 Acc: 0.2189\n",
            "val Loss: 1.5944 Acc: 0.2361\n",
            "\n",
            "Training complete in 1m 37s\n",
            "Best val Acc: 0.250000\n",
            "Constructing Graph Learning Objects\n",
            "(4856, 1024)\n",
            "Complete\n",
            "Time taken = 110.78844244100037\n",
            "Coreset Size = 17\t Percent of data = 0.35%\n",
            "Coreset =  [320, 4817, 1094, 2035, 1001, 2276, 3290, 2336, 1332, 3390, 4386, 3951, 2641, 3935, 3987, 1758, 4037]\n",
            "[0 1 2 3 4 0 2 4 0 0 4 0 4 4 0 0 2]\n",
            "uc local_max\n",
            "Running half of the iterations takes 8.61992823899709\n",
            "Accuracy for half of the iterations is 77.10163111668759\n",
            "Running all the iterations takes 13.688959953997255\n",
            "Final accuracy is 89.18014500836587\n",
            "89.18014500836587\n",
            "This is experiment 3\n",
            "169\n",
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.6084 Acc: 0.3195\n",
            "val Loss: 1.6105 Acc: 0.2778\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.6054 Acc: 0.3254\n",
            "val Loss: 1.6097 Acc: 0.2917\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.6032 Acc: 0.3373\n",
            "val Loss: 1.6076 Acc: 0.3194\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.5996 Acc: 0.3373\n",
            "val Loss: 1.6043 Acc: 0.3333\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.5986 Acc: 0.3373\n",
            "val Loss: 1.5984 Acc: 0.3472\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.5934 Acc: 0.3432\n",
            "val Loss: 1.5942 Acc: 0.3472\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.5870 Acc: 0.3373\n",
            "val Loss: 1.5900 Acc: 0.3472\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.5852 Acc: 0.3432\n",
            "val Loss: 1.5891 Acc: 0.3472\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 1.5850 Acc: 0.3491\n",
            "val Loss: 1.5877 Acc: 0.3472\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 1.5848 Acc: 0.3373\n",
            "val Loss: 1.5864 Acc: 0.3472\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 1.5835 Acc: 0.3432\n",
            "val Loss: 1.5848 Acc: 0.3611\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 1.5835 Acc: 0.3373\n",
            "val Loss: 1.5835 Acc: 0.3611\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 1.5826 Acc: 0.3491\n",
            "val Loss: 1.5833 Acc: 0.3472\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 1.5816 Acc: 0.3669\n",
            "val Loss: 1.5840 Acc: 0.3472\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 1.5824 Acc: 0.3432\n",
            "val Loss: 1.5836 Acc: 0.3472\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 1.5818 Acc: 0.3254\n",
            "val Loss: 1.5801 Acc: 0.3472\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 1.5834 Acc: 0.3195\n",
            "val Loss: 1.5812 Acc: 0.3472\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 1.5821 Acc: 0.3491\n",
            "val Loss: 1.5809 Acc: 0.3472\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 1.5823 Acc: 0.3314\n",
            "val Loss: 1.5816 Acc: 0.3611\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 1.5824 Acc: 0.3373\n",
            "val Loss: 1.5827 Acc: 0.3472\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 1.5815 Acc: 0.3373\n",
            "val Loss: 1.5808 Acc: 0.3333\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 1.5822 Acc: 0.3314\n",
            "val Loss: 1.5807 Acc: 0.3611\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 1.5809 Acc: 0.3373\n",
            "val Loss: 1.5797 Acc: 0.3472\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 1.5819 Acc: 0.3373\n",
            "val Loss: 1.5810 Acc: 0.3333\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 1.5815 Acc: 0.3373\n",
            "val Loss: 1.5795 Acc: 0.3611\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 1.5823 Acc: 0.3373\n",
            "val Loss: 1.5797 Acc: 0.3333\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 1.5837 Acc: 0.3373\n",
            "val Loss: 1.5792 Acc: 0.3750\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 1.5826 Acc: 0.3254\n",
            "val Loss: 1.5802 Acc: 0.3333\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 1.5819 Acc: 0.3550\n",
            "val Loss: 1.5817 Acc: 0.2917\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 1.5814 Acc: 0.3491\n",
            "val Loss: 1.5792 Acc: 0.3333\n",
            "\n",
            "Training complete in 1m 40s\n",
            "Best val Acc: 0.375000\n",
            "Constructing Graph Learning Objects\n",
            "(4856, 1024)\n",
            "Complete\n",
            "Time taken = 113.46240394000051\n",
            "Coreset Size = 17\t Percent of data = 0.35%\n",
            "Coreset =  [3360, 4580, 4478, 314, 1807, 3543, 2184, 4823, 3535, 2152, 2903, 2076, 2125, 2394, 3057, 2833, 3795]\n",
            "[0 1 2 3 4 0 4 4 4 2 0 0 0 0 4 0 0]\n",
            "uc local_max\n",
            "Running half of the iterations takes 8.666116790001979\n",
            "Accuracy for half of the iterations is 75.25094102885822\n",
            "Running all the iterations takes 13.757951616000355\n",
            "Final accuracy is 90.1840490797546\n",
            "90.1840490797546\n",
            "This is experiment 4\n",
            "169\n",
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.6136 Acc: 0.0710\n",
            "val Loss: 1.6061 Acc: 0.3750\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.6118 Acc: 0.0888\n",
            "val Loss: 1.6016 Acc: 0.4583\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.6103 Acc: 0.1243\n",
            "val Loss: 1.5973 Acc: 0.5139\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.6069 Acc: 0.2130\n",
            "val Loss: 1.5962 Acc: 0.5139\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.6038 Acc: 0.2781\n",
            "val Loss: 1.5931 Acc: 0.5278\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.5990 Acc: 0.3728\n",
            "val Loss: 1.5891 Acc: 0.5417\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.5943 Acc: 0.4024\n",
            "val Loss: 1.5879 Acc: 0.5139\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.5924 Acc: 0.3728\n",
            "val Loss: 1.5872 Acc: 0.5000\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 1.5912 Acc: 0.3846\n",
            "val Loss: 1.5878 Acc: 0.5278\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 1.5903 Acc: 0.4438\n",
            "val Loss: 1.5865 Acc: 0.5139\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 1.5895 Acc: 0.4260\n",
            "val Loss: 1.5884 Acc: 0.5139\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 1.5892 Acc: 0.4201\n",
            "val Loss: 1.5883 Acc: 0.5139\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 1.5903 Acc: 0.4083\n",
            "val Loss: 1.5865 Acc: 0.4861\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 1.5888 Acc: 0.4024\n",
            "val Loss: 1.5874 Acc: 0.4861\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 1.5882 Acc: 0.4497\n",
            "val Loss: 1.5857 Acc: 0.5417\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 1.5893 Acc: 0.3964\n",
            "val Loss: 1.5865 Acc: 0.4722\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 1.5891 Acc: 0.3964\n",
            "val Loss: 1.5857 Acc: 0.5139\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 1.5888 Acc: 0.3728\n",
            "val Loss: 1.5850 Acc: 0.4583\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 1.5891 Acc: 0.3669\n",
            "val Loss: 1.5853 Acc: 0.5139\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 1.5893 Acc: 0.3787\n",
            "val Loss: 1.5854 Acc: 0.5139\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 1.5888 Acc: 0.4024\n",
            "val Loss: 1.5859 Acc: 0.4444\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 1.5880 Acc: 0.4083\n",
            "val Loss: 1.5853 Acc: 0.5139\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 1.5885 Acc: 0.4083\n",
            "val Loss: 1.5862 Acc: 0.5000\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 1.5874 Acc: 0.4142\n",
            "val Loss: 1.5862 Acc: 0.5139\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 1.5877 Acc: 0.4083\n",
            "val Loss: 1.5875 Acc: 0.3889\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 1.5883 Acc: 0.4024\n",
            "val Loss: 1.5855 Acc: 0.4583\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 1.5876 Acc: 0.4201\n",
            "val Loss: 1.5852 Acc: 0.4861\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 1.5875 Acc: 0.4024\n",
            "val Loss: 1.5839 Acc: 0.5417\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 1.5887 Acc: 0.4083\n",
            "val Loss: 1.5866 Acc: 0.4861\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 1.5868 Acc: 0.4142\n",
            "val Loss: 1.5872 Acc: 0.4722\n",
            "\n",
            "Training complete in 1m 36s\n",
            "Best val Acc: 0.541667\n",
            "Constructing Graph Learning Objects\n",
            "(4856, 1024)\n",
            "Complete\n",
            "Time taken = 111.99634758600223\n",
            "Coreset Size = 21\t Percent of data = 0.43%\n",
            "Coreset =  [2952, 1630, 4394, 2968, 3370, 3525, 2250, 4134, 3681, 1806, 2630, 3643, 3064, 4516, 2510, 4833, 1323, 964, 3539, 4467, 1580]\n",
            "[0 1 2 3 4 4 4 0 0 0 0 0 4 2 2 0 2 0 0 0 2]\n",
            "uc local_max\n",
            "Running half of the iterations takes 8.205595867999364\n",
            "Accuracy for half of the iterations is 76.09924623115577\n",
            "Running all the iterations takes 13.186814024000341\n",
            "Final accuracy is 88.65287870318613\n",
            "88.65287870318613\n",
            "This is experiment 5\n",
            "169\n",
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.6127 Acc: 0.1893\n",
            "val Loss: 1.6142 Acc: 0.1528\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.6087 Acc: 0.2899\n",
            "val Loss: 1.6152 Acc: 0.1806\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.6065 Acc: 0.3136\n",
            "val Loss: 1.6134 Acc: 0.1667\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.6036 Acc: 0.3964\n",
            "val Loss: 1.6086 Acc: 0.3333\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.5982 Acc: 0.4438\n",
            "val Loss: 1.6048 Acc: 0.3889\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.5941 Acc: 0.4497\n",
            "val Loss: 1.5991 Acc: 0.4167\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.5896 Acc: 0.4497\n",
            "val Loss: 1.5930 Acc: 0.4028\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.5849 Acc: 0.4497\n",
            "val Loss: 1.5903 Acc: 0.4028\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 1.5862 Acc: 0.4497\n",
            "val Loss: 1.5902 Acc: 0.4028\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 1.5859 Acc: 0.4497\n",
            "val Loss: 1.5898 Acc: 0.4028\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 1.5839 Acc: 0.4497\n",
            "val Loss: 1.5884 Acc: 0.4028\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 1.5841 Acc: 0.4497\n",
            "val Loss: 1.5879 Acc: 0.4028\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 1.5833 Acc: 0.4497\n",
            "val Loss: 1.5874 Acc: 0.3889\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 1.5830 Acc: 0.4497\n",
            "val Loss: 1.5872 Acc: 0.4028\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 1.5838 Acc: 0.4497\n",
            "val Loss: 1.5858 Acc: 0.4028\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 1.5823 Acc: 0.4497\n",
            "val Loss: 1.5862 Acc: 0.4028\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 1.5819 Acc: 0.4497\n",
            "val Loss: 1.5857 Acc: 0.4028\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 1.5827 Acc: 0.4497\n",
            "val Loss: 1.5854 Acc: 0.4028\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 1.5825 Acc: 0.4497\n",
            "val Loss: 1.5843 Acc: 0.4028\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 1.5814 Acc: 0.4497\n",
            "val Loss: 1.5864 Acc: 0.4028\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 1.5825 Acc: 0.4497\n",
            "val Loss: 1.5864 Acc: 0.4028\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 1.5814 Acc: 0.4497\n",
            "val Loss: 1.5855 Acc: 0.4028\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 1.5826 Acc: 0.4497\n",
            "val Loss: 1.5859 Acc: 0.4028\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 1.5812 Acc: 0.4497\n",
            "val Loss: 1.5871 Acc: 0.4028\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 1.5824 Acc: 0.4497\n",
            "val Loss: 1.5847 Acc: 0.4028\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 1.5809 Acc: 0.4497\n",
            "val Loss: 1.5856 Acc: 0.4028\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 1.5819 Acc: 0.4497\n",
            "val Loss: 1.5846 Acc: 0.4028\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 1.5817 Acc: 0.4497\n",
            "val Loss: 1.5843 Acc: 0.4028\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 1.5812 Acc: 0.4497\n",
            "val Loss: 1.5856 Acc: 0.4028\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 1.5822 Acc: 0.4497\n",
            "val Loss: 1.5841 Acc: 0.4028\n",
            "\n",
            "Training complete in 1m 36s\n",
            "Best val Acc: 0.416667\n",
            "Constructing Graph Learning Objects\n",
            "(4856, 1024)\n",
            "Complete\n",
            "Time taken = 109.12243370200304\n",
            "Coreset Size = 19\t Percent of data = 0.39%\n",
            "Coreset =  [4607, 4342, 306, 2043, 2645, 2750, 1042, 4339, 1049, 1914, 8, 1583, 395, 219, 1037, 1861, 1459, 3899, 1961]\n",
            "[0 1 2 3 4 0 0 4 4 0 0 0 2 4 4 0 0 2 0]\n",
            "uc local_max\n",
            "Running half of the iterations takes 8.33912357400186\n",
            "Accuracy for half of the iterations is 75.95731324544884\n",
            "Running all the iterations takes 13.472027617001004\n",
            "Final accuracy is 87.60469011725293\n",
            "87.60469011725293\n",
            "This is experiment 6\n",
            "169\n",
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.6113 Acc: 0.1893\n",
            "val Loss: 1.6073 Acc: 0.1250\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.6103 Acc: 0.1893\n",
            "val Loss: 1.6069 Acc: 0.1250\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.6080 Acc: 0.2130\n",
            "val Loss: 1.6050 Acc: 0.1250\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.6055 Acc: 0.2663\n",
            "val Loss: 1.6016 Acc: 0.1389\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.6021 Acc: 0.2781\n",
            "val Loss: 1.5988 Acc: 0.1389\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.5989 Acc: 0.3136\n",
            "val Loss: 1.5946 Acc: 0.1528\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.5936 Acc: 0.3669\n",
            "val Loss: 1.5918 Acc: 0.1389\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.5908 Acc: 0.3550\n",
            "val Loss: 1.5921 Acc: 0.1944\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 1.5909 Acc: 0.3314\n",
            "val Loss: 1.5916 Acc: 0.1389\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 1.5903 Acc: 0.3609\n",
            "val Loss: 1.5902 Acc: 0.2500\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 1.5891 Acc: 0.3728\n",
            "val Loss: 1.5895 Acc: 0.2222\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 1.5899 Acc: 0.3491\n",
            "val Loss: 1.5880 Acc: 0.3194\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 1.5893 Acc: 0.3195\n",
            "val Loss: 1.5877 Acc: 0.3194\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 1.5887 Acc: 0.3432\n",
            "val Loss: 1.5884 Acc: 0.2639\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 1.5889 Acc: 0.3787\n",
            "val Loss: 1.5882 Acc: 0.3333\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 1.5880 Acc: 0.3432\n",
            "val Loss: 1.5900 Acc: 0.2639\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 1.5873 Acc: 0.3787\n",
            "val Loss: 1.5882 Acc: 0.2639\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 1.5883 Acc: 0.3609\n",
            "val Loss: 1.5893 Acc: 0.3056\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 1.5884 Acc: 0.3373\n",
            "val Loss: 1.5897 Acc: 0.2778\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 1.5882 Acc: 0.3195\n",
            "val Loss: 1.5876 Acc: 0.2639\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 1.5873 Acc: 0.3314\n",
            "val Loss: 1.5884 Acc: 0.2778\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 1.5871 Acc: 0.3550\n",
            "val Loss: 1.5883 Acc: 0.2917\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 1.5876 Acc: 0.3728\n",
            "val Loss: 1.5877 Acc: 0.2500\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 1.5862 Acc: 0.3787\n",
            "val Loss: 1.5874 Acc: 0.2361\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 1.5888 Acc: 0.3314\n",
            "val Loss: 1.5878 Acc: 0.3194\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 1.5876 Acc: 0.3550\n",
            "val Loss: 1.5850 Acc: 0.2778\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 1.5871 Acc: 0.3669\n",
            "val Loss: 1.5866 Acc: 0.2917\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 1.5879 Acc: 0.3550\n",
            "val Loss: 1.5862 Acc: 0.2778\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 1.5877 Acc: 0.3550\n",
            "val Loss: 1.5856 Acc: 0.3194\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 1.5878 Acc: 0.3077\n",
            "val Loss: 1.5842 Acc: 0.3194\n",
            "\n",
            "Training complete in 1m 37s\n",
            "Best val Acc: 0.333333\n",
            "Constructing Graph Learning Objects\n",
            "(4856, 1024)\n",
            "Complete\n",
            "Time taken = 109.87338168899805\n",
            "Coreset Size = 17\t Percent of data = 0.35%\n",
            "Coreset =  [3360, 4580, 4478, 314, 1807, 1580, 1954, 4785, 1743, 510, 3016, 2833, 4392, 2597, 611, 23, 4565]\n",
            "[0 1 2 3 4 2 4 4 0 0 2 0 4 0 4 0 4]\n",
            "uc local_max\n",
            "Running half of the iterations takes 8.122711677999177\n",
            "Accuracy for half of the iterations is 76.97616060225847\n",
            "Running all the iterations takes 12.897954381998716\n",
            "Final accuracy is 90.35136642498605\n",
            "90.35136642498605\n",
            "This is experiment 7\n",
            "169\n",
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.6042 Acc: 0.2663\n",
            "val Loss: 1.5979 Acc: 0.4722\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.6029 Acc: 0.3609\n",
            "val Loss: 1.5946 Acc: 0.4722\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.5990 Acc: 0.3669\n",
            "val Loss: 1.5915 Acc: 0.4722\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.5966 Acc: 0.4142\n",
            "val Loss: 1.5872 Acc: 0.4722\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.5935 Acc: 0.3964\n",
            "val Loss: 1.5809 Acc: 0.4722\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.5885 Acc: 0.4201\n",
            "val Loss: 1.5789 Acc: 0.4722\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.5848 Acc: 0.4083\n",
            "val Loss: 1.5736 Acc: 0.4722\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.5820 Acc: 0.4024\n",
            "val Loss: 1.5752 Acc: 0.4861\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 1.5807 Acc: 0.4201\n",
            "val Loss: 1.5749 Acc: 0.4722\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 1.5800 Acc: 0.4142\n",
            "val Loss: 1.5757 Acc: 0.4444\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 1.5795 Acc: 0.4024\n",
            "val Loss: 1.5752 Acc: 0.4861\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 1.5799 Acc: 0.4024\n",
            "val Loss: 1.5736 Acc: 0.4444\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 1.5784 Acc: 0.4379\n",
            "val Loss: 1.5739 Acc: 0.4583\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 1.5784 Acc: 0.4024\n",
            "val Loss: 1.5745 Acc: 0.4861\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 1.5774 Acc: 0.4260\n",
            "val Loss: 1.5768 Acc: 0.4444\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 1.5792 Acc: 0.4142\n",
            "val Loss: 1.5760 Acc: 0.4306\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 1.5778 Acc: 0.4024\n",
            "val Loss: 1.5756 Acc: 0.4583\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 1.5776 Acc: 0.3964\n",
            "val Loss: 1.5769 Acc: 0.4444\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 1.5772 Acc: 0.4083\n",
            "val Loss: 1.5759 Acc: 0.4861\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 1.5777 Acc: 0.4083\n",
            "val Loss: 1.5764 Acc: 0.4722\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 1.5771 Acc: 0.4379\n",
            "val Loss: 1.5768 Acc: 0.4722\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 1.5780 Acc: 0.4024\n",
            "val Loss: 1.5771 Acc: 0.4444\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 1.5776 Acc: 0.3846\n",
            "val Loss: 1.5759 Acc: 0.4444\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 1.5781 Acc: 0.4083\n",
            "val Loss: 1.5756 Acc: 0.4722\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 1.5784 Acc: 0.4024\n",
            "val Loss: 1.5767 Acc: 0.4583\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 1.5784 Acc: 0.4083\n",
            "val Loss: 1.5781 Acc: 0.4444\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 1.5778 Acc: 0.3905\n",
            "val Loss: 1.5788 Acc: 0.4583\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 1.5788 Acc: 0.3964\n",
            "val Loss: 1.5760 Acc: 0.4722\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 1.5778 Acc: 0.4201\n",
            "val Loss: 1.5781 Acc: 0.4583\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 1.5779 Acc: 0.4142\n",
            "val Loss: 1.5764 Acc: 0.4861\n",
            "\n",
            "Training complete in 1m 36s\n",
            "Best val Acc: 0.486111\n",
            "Constructing Graph Learning Objects\n",
            "(4856, 1024)\n",
            "Complete\n",
            "Time taken = 109.18274154999744\n",
            "Coreset Size = 16\t Percent of data = 0.33%\n",
            "Coreset =  [4705, 3030, 4242, 234, 1249, 864, 3929, 3758, 4171, 3106, 2425, 2933, 1855, 3932, 1138, 1037]\n",
            "[0 1 2 3 4 0 0 0 0 3 4 3 2 2 0 4]\n",
            "uc local_max\n",
            "Running half of the iterations takes 9.048130772996956\n",
            "Accuracy for half of the iterations is 76.51301348385074\n",
            "Running all the iterations takes 14.498061579997739\n",
            "Final accuracy is 87.9041248606466\n",
            "87.9041248606466\n",
            "This is experiment 8\n",
            "169\n",
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.6196 Acc: 0.0710\n",
            "val Loss: 1.6191 Acc: 0.1250\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.6181 Acc: 0.1006\n",
            "val Loss: 1.6146 Acc: 0.1806\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.6173 Acc: 0.0828\n",
            "val Loss: 1.6141 Acc: 0.0833\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.6129 Acc: 0.1361\n",
            "val Loss: 1.6121 Acc: 0.1250\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.6086 Acc: 0.2189\n",
            "val Loss: 1.6079 Acc: 0.2222\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.6047 Acc: 0.2604\n",
            "val Loss: 1.6048 Acc: 0.2917\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.6002 Acc: 0.3254\n",
            "val Loss: 1.6020 Acc: 0.2917\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.5960 Acc: 0.4083\n",
            "val Loss: 1.5996 Acc: 0.4444\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 1.5976 Acc: 0.3432\n",
            "val Loss: 1.6029 Acc: 0.2917\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 1.5963 Acc: 0.3905\n",
            "val Loss: 1.6009 Acc: 0.3611\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 1.5959 Acc: 0.3669\n",
            "val Loss: 1.6022 Acc: 0.3333\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 1.5950 Acc: 0.4142\n",
            "val Loss: 1.5987 Acc: 0.3472\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 1.5947 Acc: 0.3787\n",
            "val Loss: 1.6001 Acc: 0.3333\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 1.5939 Acc: 0.4083\n",
            "val Loss: 1.5984 Acc: 0.3889\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 1.5936 Acc: 0.3964\n",
            "val Loss: 1.5984 Acc: 0.3889\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 1.5934 Acc: 0.4201\n",
            "val Loss: 1.5978 Acc: 0.4028\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 1.5930 Acc: 0.4320\n",
            "val Loss: 1.5963 Acc: 0.3750\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 1.5935 Acc: 0.4320\n",
            "val Loss: 1.5955 Acc: 0.4306\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 1.5941 Acc: 0.3964\n",
            "val Loss: 1.5959 Acc: 0.3750\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 1.5922 Acc: 0.4379\n",
            "val Loss: 1.5943 Acc: 0.3889\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 1.5934 Acc: 0.3846\n",
            "val Loss: 1.5947 Acc: 0.3889\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 1.5939 Acc: 0.4083\n",
            "val Loss: 1.5948 Acc: 0.3889\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 1.5939 Acc: 0.4083\n",
            "val Loss: 1.5957 Acc: 0.3750\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 1.5921 Acc: 0.3846\n",
            "val Loss: 1.5945 Acc: 0.4028\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 1.5930 Acc: 0.4320\n",
            "val Loss: 1.5956 Acc: 0.3889\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 1.5932 Acc: 0.4438\n",
            "val Loss: 1.5954 Acc: 0.4028\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 1.5928 Acc: 0.4497\n",
            "val Loss: 1.5971 Acc: 0.3611\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 1.5929 Acc: 0.4083\n",
            "val Loss: 1.5977 Acc: 0.3611\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 1.5935 Acc: 0.3787\n",
            "val Loss: 1.5932 Acc: 0.5000\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 1.5916 Acc: 0.4260\n",
            "val Loss: 1.5938 Acc: 0.4028\n",
            "\n",
            "Training complete in 1m 36s\n",
            "Best val Acc: 0.500000\n",
            "Constructing Graph Learning Objects\n",
            "(4856, 1024)\n",
            "Complete\n",
            "Time taken = 109.32131345599919\n",
            "Coreset Size = 19\t Percent of data = 0.39%\n",
            "Coreset =  [3504, 2329, 937, 4692, 3066, 4804, 2968, 3045, 934, 1125, 2659, 2070, 3536, 291, 269, 1852, 2035, 911, 1652]\n",
            "[0 1 2 3 4 0 3 4 2 0 0 0 3 3 0 0 3 0 0]\n",
            "uc local_max\n",
            "Running half of the iterations takes 8.430928028999915\n",
            "Accuracy for half of the iterations is 76.02008788449466\n",
            "Running all the iterations takes 13.430674136001471\n",
            "Final accuracy is 90.73143495254048\n",
            "90.73143495254048\n",
            "This is experiment 9\n",
            "169\n",
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.6130 Acc: 0.1243\n",
            "val Loss: 1.6126 Acc: 0.1944\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.6113 Acc: 0.1479\n",
            "val Loss: 1.6121 Acc: 0.1944\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.6103 Acc: 0.1716\n",
            "val Loss: 1.6081 Acc: 0.2778\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.6061 Acc: 0.1657\n",
            "val Loss: 1.6058 Acc: 0.2639\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.6009 Acc: 0.2663\n",
            "val Loss: 1.6026 Acc: 0.2639\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.5990 Acc: 0.2130\n",
            "val Loss: 1.5971 Acc: 0.3056\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.5937 Acc: 0.2959\n",
            "val Loss: 1.5934 Acc: 0.3056\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.5907 Acc: 0.3609\n",
            "val Loss: 1.5941 Acc: 0.3333\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 1.5900 Acc: 0.3609\n",
            "val Loss: 1.5931 Acc: 0.2917\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 1.5903 Acc: 0.3905\n",
            "val Loss: 1.5921 Acc: 0.2500\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 1.5891 Acc: 0.3728\n",
            "val Loss: 1.5927 Acc: 0.2778\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 1.5892 Acc: 0.3550\n",
            "val Loss: 1.5916 Acc: 0.2778\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 1.5867 Acc: 0.4142\n",
            "val Loss: 1.5897 Acc: 0.2778\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 1.5873 Acc: 0.4083\n",
            "val Loss: 1.5908 Acc: 0.3056\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 1.5877 Acc: 0.3787\n",
            "val Loss: 1.5881 Acc: 0.3472\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 1.5877 Acc: 0.3787\n",
            "val Loss: 1.5879 Acc: 0.2222\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 1.5879 Acc: 0.3787\n",
            "val Loss: 1.5884 Acc: 0.3056\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 1.5865 Acc: 0.4142\n",
            "val Loss: 1.5871 Acc: 0.2917\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 1.5872 Acc: 0.3254\n",
            "val Loss: 1.5870 Acc: 0.3194\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 1.5867 Acc: 0.3905\n",
            "val Loss: 1.5870 Acc: 0.2917\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 1.5876 Acc: 0.3669\n",
            "val Loss: 1.5862 Acc: 0.2639\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 1.5874 Acc: 0.3846\n",
            "val Loss: 1.5848 Acc: 0.3194\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 1.5876 Acc: 0.3195\n",
            "val Loss: 1.5863 Acc: 0.2917\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 1.5879 Acc: 0.3728\n",
            "val Loss: 1.5862 Acc: 0.2361\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 1.5876 Acc: 0.3550\n",
            "val Loss: 1.5847 Acc: 0.3056\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 1.5867 Acc: 0.3669\n",
            "val Loss: 1.5842 Acc: 0.3056\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 1.5866 Acc: 0.4024\n",
            "val Loss: 1.5862 Acc: 0.2361\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 1.5868 Acc: 0.3728\n",
            "val Loss: 1.5854 Acc: 0.2639\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 1.5877 Acc: 0.3432\n",
            "val Loss: 1.5846 Acc: 0.2778\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 1.5866 Acc: 0.3491\n",
            "val Loss: 1.5843 Acc: 0.3333\n",
            "\n",
            "Training complete in 1m 37s\n",
            "Best val Acc: 0.347222\n",
            "Constructing Graph Learning Objects\n",
            "(4856, 1024)\n",
            "Complete\n",
            "Time taken = 110.02851744899817\n",
            "Coreset Size = 17\t Percent of data = 0.35%\n",
            "Coreset =  [3360, 4580, 4478, 314, 1807, 4479, 4356, 2034, 2336, 279, 1774, 676, 1804, 1959, 574, 1193, 4628]\n",
            "[0 1 2 3 4 0 4 0 4 0 0 4 4 4 0 0 0]\n",
            "uc local_max\n",
            "Running half of the iterations takes 8.272566964998987\n",
            "Accuracy for half of the iterations is 76.69385194479297\n",
            "Running all the iterations takes 13.130420579000202\n",
            "Final accuracy is 88.95705521472392\n",
            "88.95705521472392\n",
            "This is experiment 10\n",
            "169\n",
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.6011 Acc: 0.1420\n",
            "val Loss: 1.6000 Acc: 0.2361\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.5995 Acc: 0.1420\n",
            "val Loss: 1.5987 Acc: 0.2917\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.5973 Acc: 0.2722\n",
            "val Loss: 1.5950 Acc: 0.3472\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.5933 Acc: 0.3018\n",
            "val Loss: 1.5908 Acc: 0.4306\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.5906 Acc: 0.3609\n",
            "val Loss: 1.5859 Acc: 0.4583\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.5866 Acc: 0.4201\n",
            "val Loss: 1.5828 Acc: 0.4583\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.5818 Acc: 0.3964\n",
            "val Loss: 1.5780 Acc: 0.4722\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.5795 Acc: 0.4379\n",
            "val Loss: 1.5765 Acc: 0.4583\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 1.5781 Acc: 0.4024\n",
            "val Loss: 1.5776 Acc: 0.4722\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 1.5778 Acc: 0.4320\n",
            "val Loss: 1.5756 Acc: 0.4583\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 1.5777 Acc: 0.4260\n",
            "val Loss: 1.5756 Acc: 0.4167\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 1.5751 Acc: 0.4438\n",
            "val Loss: 1.5762 Acc: 0.4306\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 1.5763 Acc: 0.4260\n",
            "val Loss: 1.5754 Acc: 0.4583\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 1.5755 Acc: 0.4438\n",
            "val Loss: 1.5742 Acc: 0.4583\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 1.5760 Acc: 0.4379\n",
            "val Loss: 1.5757 Acc: 0.4306\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 1.5764 Acc: 0.4024\n",
            "val Loss: 1.5749 Acc: 0.4722\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 1.5748 Acc: 0.4497\n",
            "val Loss: 1.5739 Acc: 0.4444\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 1.5749 Acc: 0.4438\n",
            "val Loss: 1.5739 Acc: 0.4444\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 1.5750 Acc: 0.4024\n",
            "val Loss: 1.5730 Acc: 0.4167\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 1.5760 Acc: 0.4260\n",
            "val Loss: 1.5741 Acc: 0.4306\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 1.5762 Acc: 0.3964\n",
            "val Loss: 1.5756 Acc: 0.4167\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 1.5745 Acc: 0.4320\n",
            "val Loss: 1.5744 Acc: 0.4167\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 1.5754 Acc: 0.4201\n",
            "val Loss: 1.5760 Acc: 0.4583\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 1.5753 Acc: 0.4142\n",
            "val Loss: 1.5742 Acc: 0.4306\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 1.5770 Acc: 0.4024\n",
            "val Loss: 1.5762 Acc: 0.4583\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 1.5739 Acc: 0.4320\n",
            "val Loss: 1.5769 Acc: 0.4306\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 1.5740 Acc: 0.4142\n",
            "val Loss: 1.5762 Acc: 0.4306\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 1.5750 Acc: 0.4201\n",
            "val Loss: 1.5745 Acc: 0.4444\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 1.5751 Acc: 0.4320\n",
            "val Loss: 1.5766 Acc: 0.4306\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 1.5750 Acc: 0.4379\n",
            "val Loss: 1.5766 Acc: 0.4306\n",
            "\n",
            "Training complete in 1m 37s\n",
            "Best val Acc: 0.472222\n",
            "Constructing Graph Learning Objects\n",
            "(4856, 1024)\n",
            "Complete\n",
            "Time taken = 110.0307065909983\n",
            "Coreset Size = 16\t Percent of data = 0.33%\n",
            "Coreset =  [4705, 3030, 4242, 234, 1249, 3444, 2844, 158, 4683, 944, 177, 2605, 1838, 2306, 102, 104]\n",
            "[0 1 2 3 4 0 2 0 0 4 0 0 4 4 4 0]\n",
            "uc local_max\n",
            "Running half of the iterations takes 8.881141439997009\n",
            "Accuracy for half of the iterations is 75.5409219190969\n",
            "Running all the iterations takes 14.312170973997127\n",
            "Final accuracy is 88.29431438127091\n",
            "88.29431438127091\n",
            "This is experiment 11\n",
            "169\n",
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.6007 Acc: 0.3964\n",
            "val Loss: 1.6049 Acc: 0.4306\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.5980 Acc: 0.4260\n",
            "val Loss: 1.6026 Acc: 0.4861\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.5961 Acc: 0.4024\n",
            "val Loss: 1.6012 Acc: 0.4306\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.5937 Acc: 0.4201\n",
            "val Loss: 1.5948 Acc: 0.3889\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.5895 Acc: 0.4497\n",
            "val Loss: 1.5886 Acc: 0.4861\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.5861 Acc: 0.4320\n",
            "val Loss: 1.5844 Acc: 0.4583\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.5830 Acc: 0.4142\n",
            "val Loss: 1.5776 Acc: 0.5000\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.5808 Acc: 0.4379\n",
            "val Loss: 1.5748 Acc: 0.5139\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 1.5794 Acc: 0.3964\n",
            "val Loss: 1.5744 Acc: 0.5278\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 1.5791 Acc: 0.3905\n",
            "val Loss: 1.5739 Acc: 0.5139\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 1.5789 Acc: 0.3728\n",
            "val Loss: 1.5718 Acc: 0.5139\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 1.5781 Acc: 0.3964\n",
            "val Loss: 1.5712 Acc: 0.5000\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 1.5774 Acc: 0.4142\n",
            "val Loss: 1.5688 Acc: 0.5417\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 1.5770 Acc: 0.3846\n",
            "val Loss: 1.5693 Acc: 0.5278\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 1.5769 Acc: 0.3846\n",
            "val Loss: 1.5699 Acc: 0.5278\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 1.5773 Acc: 0.3964\n",
            "val Loss: 1.5689 Acc: 0.4861\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 1.5759 Acc: 0.4260\n",
            "val Loss: 1.5716 Acc: 0.5417\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 1.5760 Acc: 0.4201\n",
            "val Loss: 1.5704 Acc: 0.5278\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 1.5770 Acc: 0.3905\n",
            "val Loss: 1.5692 Acc: 0.5278\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 1.5764 Acc: 0.3787\n",
            "val Loss: 1.5691 Acc: 0.5000\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 1.5766 Acc: 0.4024\n",
            "val Loss: 1.5708 Acc: 0.5278\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 1.5767 Acc: 0.4142\n",
            "val Loss: 1.5725 Acc: 0.5139\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 1.5772 Acc: 0.3787\n",
            "val Loss: 1.5724 Acc: 0.4861\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 1.5757 Acc: 0.3964\n",
            "val Loss: 1.5714 Acc: 0.5000\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 1.5764 Acc: 0.3964\n",
            "val Loss: 1.5698 Acc: 0.5000\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 1.5765 Acc: 0.4320\n",
            "val Loss: 1.5732 Acc: 0.4861\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 1.5765 Acc: 0.4024\n",
            "val Loss: 1.5703 Acc: 0.5417\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 1.5764 Acc: 0.4083\n",
            "val Loss: 1.5715 Acc: 0.4861\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 1.5782 Acc: 0.4024\n",
            "val Loss: 1.5728 Acc: 0.4722\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 1.5768 Acc: 0.3964\n",
            "val Loss: 1.5715 Acc: 0.5278\n",
            "\n",
            "Training complete in 1m 37s\n",
            "Best val Acc: 0.541667\n",
            "Constructing Graph Learning Objects\n",
            "(4856, 1024)\n",
            "Complete\n",
            "Time taken = 109.64101514999857\n",
            "Coreset Size = 18\t Percent of data = 0.37%\n",
            "Coreset =  [1312, 2707, 395, 4846, 1126, 1406, 2659, 207, 1769, 3535, 4822, 2540, 4483, 457, 428, 2662, 2119, 1861]\n",
            "[0 1 2 3 4 2 0 4 2 4 4 2 2 0 4 0 4 0]\n",
            "uc local_max\n",
            "Running half of the iterations takes 8.203641615000379\n",
            "Accuracy for half of the iterations is 76.43551929714465\n",
            "Running all the iterations takes 13.239411321999796\n",
            "Final accuracy is 89.50892857142857\n",
            "89.50892857142857\n",
            "This is experiment 12\n",
            "169\n",
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.5969 Acc: 0.4142\n",
            "val Loss: 1.5998 Acc: 0.3889\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.5951 Acc: 0.4497\n",
            "val Loss: 1.5992 Acc: 0.4028\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.5924 Acc: 0.4497\n",
            "val Loss: 1.5957 Acc: 0.4028\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.5892 Acc: 0.4497\n",
            "val Loss: 1.5917 Acc: 0.4028\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.5860 Acc: 0.4497\n",
            "val Loss: 1.5878 Acc: 0.4028\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.5815 Acc: 0.4497\n",
            "val Loss: 1.5828 Acc: 0.4028\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.5765 Acc: 0.4497\n",
            "val Loss: 1.5772 Acc: 0.4028\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.5736 Acc: 0.4497\n",
            "val Loss: 1.5776 Acc: 0.4028\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 1.5720 Acc: 0.4497\n",
            "val Loss: 1.5776 Acc: 0.4028\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 1.5722 Acc: 0.4497\n",
            "val Loss: 1.5762 Acc: 0.4028\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 1.5707 Acc: 0.4497\n",
            "val Loss: 1.5745 Acc: 0.4028\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 1.5715 Acc: 0.4497\n",
            "val Loss: 1.5740 Acc: 0.4028\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 1.5711 Acc: 0.4497\n",
            "val Loss: 1.5713 Acc: 0.4028\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 1.5700 Acc: 0.4497\n",
            "val Loss: 1.5721 Acc: 0.4028\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 1.5703 Acc: 0.4497\n",
            "val Loss: 1.5720 Acc: 0.4028\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 1.5703 Acc: 0.4497\n",
            "val Loss: 1.5739 Acc: 0.4028\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 1.5700 Acc: 0.4497\n",
            "val Loss: 1.5728 Acc: 0.4028\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 1.5696 Acc: 0.4497\n",
            "val Loss: 1.5718 Acc: 0.4028\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 1.5713 Acc: 0.4497\n",
            "val Loss: 1.5729 Acc: 0.4028\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 1.5703 Acc: 0.4497\n",
            "val Loss: 1.5718 Acc: 0.4028\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 1.5692 Acc: 0.4497\n",
            "val Loss: 1.5748 Acc: 0.4028\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 1.5713 Acc: 0.4497\n",
            "val Loss: 1.5716 Acc: 0.4028\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 1.5707 Acc: 0.4497\n",
            "val Loss: 1.5719 Acc: 0.4028\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 1.5695 Acc: 0.4497\n",
            "val Loss: 1.5726 Acc: 0.4028\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 1.5701 Acc: 0.4497\n",
            "val Loss: 1.5726 Acc: 0.4028\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 1.5690 Acc: 0.4497\n",
            "val Loss: 1.5735 Acc: 0.4028\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 1.5695 Acc: 0.4497\n",
            "val Loss: 1.5738 Acc: 0.4028\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 1.5692 Acc: 0.4497\n",
            "val Loss: 1.5739 Acc: 0.4028\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 1.5689 Acc: 0.4497\n",
            "val Loss: 1.5728 Acc: 0.4028\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 1.5704 Acc: 0.4497\n",
            "val Loss: 1.5737 Acc: 0.4028\n",
            "\n",
            "Training complete in 1m 38s\n",
            "Best val Acc: 0.402778\n",
            "Constructing Graph Learning Objects\n",
            "(4856, 1024)\n",
            "Complete\n",
            "Time taken = 110.66701612500037\n",
            "Coreset Size = 19\t Percent of data = 0.39%\n",
            "Coreset =  [320, 4817, 1094, 2035, 1001, 3693, 4544, 3826, 3965, 785, 1751, 2954, 2731, 3905, 1369, 4823, 2125, 1780, 37]\n",
            "[0 1 2 3 4 0 4 4 4 4 0 0 4 0 0 4 0 4 0]\n",
            "uc local_max\n",
            "Running half of the iterations takes 9.187067069000477\n",
            "Accuracy for half of the iterations is 75.67482736974263\n",
            "Running all the iterations takes 14.622401038002863\n",
            "Final accuracy is 88.38637632607482\n",
            "88.38637632607482\n",
            "This is experiment 13\n",
            "169\n",
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.5994 Acc: 0.2959\n",
            "val Loss: 1.5970 Acc: 0.3472\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.5978 Acc: 0.3254\n",
            "val Loss: 1.5946 Acc: 0.3472\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.5950 Acc: 0.3018\n",
            "val Loss: 1.5920 Acc: 0.3472\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.5935 Acc: 0.3254\n",
            "val Loss: 1.5861 Acc: 0.3611\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.5900 Acc: 0.3136\n",
            "val Loss: 1.5839 Acc: 0.3750\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.5852 Acc: 0.3609\n",
            "val Loss: 1.5776 Acc: 0.3750\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.5825 Acc: 0.3550\n",
            "val Loss: 1.5749 Acc: 0.4028\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.5773 Acc: 0.3846\n",
            "val Loss: 1.5730 Acc: 0.3889\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 1.5782 Acc: 0.3728\n",
            "val Loss: 1.5724 Acc: 0.3611\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 1.5774 Acc: 0.3609\n",
            "val Loss: 1.5709 Acc: 0.3889\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 1.5770 Acc: 0.3846\n",
            "val Loss: 1.5709 Acc: 0.4167\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 1.5764 Acc: 0.4083\n",
            "val Loss: 1.5697 Acc: 0.3472\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 1.5765 Acc: 0.3491\n",
            "val Loss: 1.5692 Acc: 0.4583\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 1.5756 Acc: 0.3787\n",
            "val Loss: 1.5686 Acc: 0.4306\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 1.5754 Acc: 0.3609\n",
            "val Loss: 1.5686 Acc: 0.4722\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 1.5750 Acc: 0.3905\n",
            "val Loss: 1.5723 Acc: 0.3750\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 1.5746 Acc: 0.3964\n",
            "val Loss: 1.5718 Acc: 0.3472\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 1.5762 Acc: 0.3550\n",
            "val Loss: 1.5716 Acc: 0.3750\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 1.5755 Acc: 0.3905\n",
            "val Loss: 1.5725 Acc: 0.3750\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 1.5753 Acc: 0.4083\n",
            "val Loss: 1.5731 Acc: 0.3889\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 1.5748 Acc: 0.3787\n",
            "val Loss: 1.5729 Acc: 0.3750\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 1.5747 Acc: 0.3846\n",
            "val Loss: 1.5725 Acc: 0.4028\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 1.5752 Acc: 0.3846\n",
            "val Loss: 1.5724 Acc: 0.4028\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 1.5750 Acc: 0.3550\n",
            "val Loss: 1.5721 Acc: 0.4722\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 1.5748 Acc: 0.3609\n",
            "val Loss: 1.5726 Acc: 0.3889\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 1.5765 Acc: 0.3314\n",
            "val Loss: 1.5736 Acc: 0.3750\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 1.5749 Acc: 0.4024\n",
            "val Loss: 1.5737 Acc: 0.3194\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 1.5750 Acc: 0.3728\n",
            "val Loss: 1.5735 Acc: 0.3472\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 1.5770 Acc: 0.2781\n",
            "val Loss: 1.5736 Acc: 0.4444\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 1.5745 Acc: 0.3373\n",
            "val Loss: 1.5724 Acc: 0.4444\n",
            "\n",
            "Training complete in 1m 38s\n",
            "Best val Acc: 0.472222\n",
            "Constructing Graph Learning Objects\n",
            "(4856, 1024)\n",
            "Complete\n",
            "Time taken = 111.10009009200076\n",
            "Coreset Size = 16\t Percent of data = 0.33%\n",
            "Coreset =  [4232, 39, 1253, 2496, 315, 38, 4350, 2416, 535, 2040, 4327, 1411, 4288, 4588, 3899, 4721]\n",
            "[0 1 2 3 4 0 0 4 4 4 4 4 4 4 2 2]\n",
            "uc local_max\n",
            "Running half of the iterations takes 8.254096611999557\n",
            "Accuracy for half of the iterations is 76.95202257761053\n",
            "Running all the iterations takes 13.362004736998642\n",
            "Final accuracy is 90.41248606465997\n",
            "90.41248606465997\n",
            "This is experiment 14\n",
            "169\n",
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.6075 Acc: 0.3314\n",
            "val Loss: 1.6082 Acc: 0.2778\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.6056 Acc: 0.3373\n",
            "val Loss: 1.6066 Acc: 0.2778\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.6038 Acc: 0.3550\n",
            "val Loss: 1.6041 Acc: 0.2778\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.6002 Acc: 0.3491\n",
            "val Loss: 1.6001 Acc: 0.2778\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.5958 Acc: 0.3728\n",
            "val Loss: 1.5955 Acc: 0.2778\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.5918 Acc: 0.3669\n",
            "val Loss: 1.5928 Acc: 0.2778\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.5879 Acc: 0.3669\n",
            "val Loss: 1.5878 Acc: 0.2917\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.5843 Acc: 0.3669\n",
            "val Loss: 1.5862 Acc: 0.2778\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 1.5824 Acc: 0.3669\n",
            "val Loss: 1.5867 Acc: 0.2778\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 1.5827 Acc: 0.3728\n",
            "val Loss: 1.5857 Acc: 0.2778\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 1.5826 Acc: 0.3728\n",
            "val Loss: 1.5835 Acc: 0.3056\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 1.5817 Acc: 0.3609\n",
            "val Loss: 1.5851 Acc: 0.2778\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 1.5801 Acc: 0.3669\n",
            "val Loss: 1.5850 Acc: 0.2778\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 1.5806 Acc: 0.3728\n",
            "val Loss: 1.5855 Acc: 0.2917\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 1.5814 Acc: 0.3669\n",
            "val Loss: 1.5866 Acc: 0.2778\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 1.5807 Acc: 0.3669\n",
            "val Loss: 1.5848 Acc: 0.2917\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 1.5804 Acc: 0.3609\n",
            "val Loss: 1.5857 Acc: 0.2917\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 1.5800 Acc: 0.3728\n",
            "val Loss: 1.5867 Acc: 0.3056\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 1.5793 Acc: 0.3669\n",
            "val Loss: 1.5847 Acc: 0.3056\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 1.5796 Acc: 0.3669\n",
            "val Loss: 1.5864 Acc: 0.2778\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 1.5796 Acc: 0.3609\n",
            "val Loss: 1.5880 Acc: 0.2778\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 1.5801 Acc: 0.3669\n",
            "val Loss: 1.5844 Acc: 0.3194\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 1.5796 Acc: 0.3550\n",
            "val Loss: 1.5881 Acc: 0.2639\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 1.5804 Acc: 0.3609\n",
            "val Loss: 1.5870 Acc: 0.2778\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 1.5804 Acc: 0.3550\n",
            "val Loss: 1.5883 Acc: 0.2917\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 1.5799 Acc: 0.3669\n",
            "val Loss: 1.5845 Acc: 0.3056\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 1.5803 Acc: 0.3728\n",
            "val Loss: 1.5871 Acc: 0.2500\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 1.5794 Acc: 0.3609\n",
            "val Loss: 1.5853 Acc: 0.2917\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 1.5793 Acc: 0.3669\n",
            "val Loss: 1.5838 Acc: 0.2917\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 1.5798 Acc: 0.3728\n",
            "val Loss: 1.5847 Acc: 0.3056\n",
            "\n",
            "Training complete in 1m 37s\n",
            "Best val Acc: 0.319444\n",
            "Constructing Graph Learning Objects\n",
            "(4856, 1024)\n",
            "Complete\n",
            "Time taken = 110.16613740199682\n",
            "Coreset Size = 19\t Percent of data = 0.39%\n",
            "Coreset =  [2952, 1630, 4394, 2968, 3370, 3935, 4700, 4699, 1454, 2111, 2821, 200, 1165, 184, 2529, 2798, 2870, 302, 4431]\n",
            "[0 1 2 3 4 4 2 4 3 0 0 0 4 4 4 0 4 4 0]\n",
            "uc local_max\n",
            "Running half of the iterations takes 8.108816388001287\n",
            "Accuracy for half of the iterations is 77.80916509730069\n",
            "Running all the iterations takes 12.929620743998385\n",
            "Final accuracy is 90.45226130653266\n",
            "90.45226130653266\n",
            "This is experiment 15\n",
            "169\n",
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.6244 Acc: 0.1479\n",
            "val Loss: 1.6262 Acc: 0.1806\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.6219 Acc: 0.1538\n",
            "val Loss: 1.6236 Acc: 0.1806\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.6204 Acc: 0.1598\n",
            "val Loss: 1.6194 Acc: 0.1806\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.6166 Acc: 0.1538\n",
            "val Loss: 1.6150 Acc: 0.1944\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.6135 Acc: 0.1538\n",
            "val Loss: 1.6090 Acc: 0.1944\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.6086 Acc: 0.1598\n",
            "val Loss: 1.6046 Acc: 0.2222\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.6051 Acc: 0.1538\n",
            "val Loss: 1.5981 Acc: 0.1667\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.6017 Acc: 0.1834\n",
            "val Loss: 1.5964 Acc: 0.1944\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 1.6017 Acc: 0.1775\n",
            "val Loss: 1.5965 Acc: 0.1944\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 1.6017 Acc: 0.1538\n",
            "val Loss: 1.5976 Acc: 0.1944\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 1.5999 Acc: 0.2189\n",
            "val Loss: 1.5946 Acc: 0.2639\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 1.5999 Acc: 0.2130\n",
            "val Loss: 1.5943 Acc: 0.2361\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 1.5984 Acc: 0.1953\n",
            "val Loss: 1.5936 Acc: 0.2778\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 1.5976 Acc: 0.2012\n",
            "val Loss: 1.5942 Acc: 0.2361\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 1.5985 Acc: 0.1893\n",
            "val Loss: 1.5949 Acc: 0.2222\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 1.5993 Acc: 0.1775\n",
            "val Loss: 1.5941 Acc: 0.2639\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 1.5969 Acc: 0.2130\n",
            "val Loss: 1.5958 Acc: 0.2500\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 1.5993 Acc: 0.1893\n",
            "val Loss: 1.5955 Acc: 0.2500\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 1.5975 Acc: 0.2308\n",
            "val Loss: 1.5965 Acc: 0.1944\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 1.5986 Acc: 0.1657\n",
            "val Loss: 1.5933 Acc: 0.3056\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 1.5972 Acc: 0.2308\n",
            "val Loss: 1.5955 Acc: 0.2639\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 1.5984 Acc: 0.1893\n",
            "val Loss: 1.5953 Acc: 0.1528\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 1.5976 Acc: 0.2189\n",
            "val Loss: 1.5964 Acc: 0.2222\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 1.5972 Acc: 0.2130\n",
            "val Loss: 1.5960 Acc: 0.2500\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 1.5981 Acc: 0.2130\n",
            "val Loss: 1.5924 Acc: 0.3472\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 1.5973 Acc: 0.1893\n",
            "val Loss: 1.5934 Acc: 0.2500\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 1.5985 Acc: 0.1775\n",
            "val Loss: 1.5948 Acc: 0.2778\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 1.5981 Acc: 0.1834\n",
            "val Loss: 1.5947 Acc: 0.2639\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 1.5983 Acc: 0.2012\n",
            "val Loss: 1.5934 Acc: 0.2917\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 1.5977 Acc: 0.1834\n",
            "val Loss: 1.5914 Acc: 0.3472\n",
            "\n",
            "Training complete in 1m 38s\n",
            "Best val Acc: 0.347222\n",
            "Constructing Graph Learning Objects\n",
            "(4856, 1024)\n",
            "Complete\n",
            "Time taken = 111.32732346199919\n",
            "Coreset Size = 16\t Percent of data = 0.33%\n",
            "Coreset =  [3360, 4580, 4478, 314, 1807, 2416, 1856, 372, 4534, 4412, 1595, 23, 184, 3795, 1459, 1393]\n",
            "[0 1 2 3 4 4 1 2 3 0 0 0 4 0 0 4]\n",
            "uc local_max\n",
            "Running half of the iterations takes 8.267649444998824\n",
            "Accuracy for half of the iterations is 77.3283160865475\n",
            "Running all the iterations takes 13.203739292999671\n",
            "Final accuracy is 89.52062430323299\n",
            "89.52062430323299\n",
            "This is experiment 16\n",
            "169\n",
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.6082 Acc: 0.1834\n",
            "val Loss: 1.6077 Acc: 0.2083\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.6081 Acc: 0.2367\n",
            "val Loss: 1.6066 Acc: 0.2083\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.6046 Acc: 0.3195\n",
            "val Loss: 1.6043 Acc: 0.4028\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.6016 Acc: 0.4379\n",
            "val Loss: 1.6032 Acc: 0.3889\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.5969 Acc: 0.4201\n",
            "val Loss: 1.5992 Acc: 0.3750\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.5928 Acc: 0.4497\n",
            "val Loss: 1.5946 Acc: 0.3194\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.5880 Acc: 0.4201\n",
            "val Loss: 1.5894 Acc: 0.3889\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.5833 Acc: 0.4793\n",
            "val Loss: 1.5885 Acc: 0.4306\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 1.5845 Acc: 0.4438\n",
            "val Loss: 1.5883 Acc: 0.4028\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 1.5831 Acc: 0.4793\n",
            "val Loss: 1.5839 Acc: 0.4444\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 1.5814 Acc: 0.4970\n",
            "val Loss: 1.5864 Acc: 0.3889\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 1.5817 Acc: 0.4970\n",
            "val Loss: 1.5838 Acc: 0.4722\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 1.5806 Acc: 0.4911\n",
            "val Loss: 1.5832 Acc: 0.4444\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 1.5796 Acc: 0.5385\n",
            "val Loss: 1.5832 Acc: 0.3611\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 1.5804 Acc: 0.4497\n",
            "val Loss: 1.5839 Acc: 0.4028\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 1.5806 Acc: 0.4734\n",
            "val Loss: 1.5839 Acc: 0.4167\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 1.5805 Acc: 0.4734\n",
            "val Loss: 1.5845 Acc: 0.4167\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 1.5807 Acc: 0.4556\n",
            "val Loss: 1.5822 Acc: 0.3889\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 1.5800 Acc: 0.4556\n",
            "val Loss: 1.5830 Acc: 0.4167\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 1.5797 Acc: 0.4497\n",
            "val Loss: 1.5835 Acc: 0.3333\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 1.5793 Acc: 0.4911\n",
            "val Loss: 1.5840 Acc: 0.4167\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 1.5802 Acc: 0.4615\n",
            "val Loss: 1.5839 Acc: 0.4028\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 1.5807 Acc: 0.4556\n",
            "val Loss: 1.5824 Acc: 0.3611\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 1.5803 Acc: 0.4734\n",
            "val Loss: 1.5869 Acc: 0.3333\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 1.5799 Acc: 0.4852\n",
            "val Loss: 1.5843 Acc: 0.3889\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 1.5808 Acc: 0.4675\n",
            "val Loss: 1.5867 Acc: 0.3750\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 1.5798 Acc: 0.4734\n",
            "val Loss: 1.5829 Acc: 0.4028\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 1.5795 Acc: 0.4793\n",
            "val Loss: 1.5826 Acc: 0.3889\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 1.5806 Acc: 0.4793\n",
            "val Loss: 1.5834 Acc: 0.4583\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 1.5806 Acc: 0.4556\n",
            "val Loss: 1.5820 Acc: 0.4306\n",
            "\n",
            "Training complete in 1m 37s\n",
            "Best val Acc: 0.472222\n",
            "Constructing Graph Learning Objects\n",
            "(4856, 1024)\n",
            "Complete\n",
            "Time taken = 109.77772061299765\n",
            "Coreset Size = 18\t Percent of data = 0.37%\n",
            "Coreset =  [2952, 1630, 4394, 2968, 3370, 4333, 2922, 414, 2707, 1862, 3296, 3732, 2009, 927, 1944, 1772, 3758, 4316]\n",
            "[0 1 2 3 4 0 3 4 1 4 4 0 0 2 2 4 0 2]\n",
            "uc local_max\n",
            "Running half of the iterations takes 8.447874370998761\n",
            "Accuracy for half of the iterations is 77.34546595544398\n",
            "Running all the iterations takes 13.440218214997003\n",
            "Final accuracy is 89.95535714285714\n",
            "89.95535714285714\n",
            "This is experiment 17\n",
            "169\n",
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.6001 Acc: 0.4260\n",
            "val Loss: 1.6019 Acc: 0.4306\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.5980 Acc: 0.4024\n",
            "val Loss: 1.5999 Acc: 0.4444\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.5969 Acc: 0.4379\n",
            "val Loss: 1.5942 Acc: 0.4306\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.5936 Acc: 0.4260\n",
            "val Loss: 1.5915 Acc: 0.4444\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.5893 Acc: 0.4201\n",
            "val Loss: 1.5847 Acc: 0.4444\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.5856 Acc: 0.4497\n",
            "val Loss: 1.5794 Acc: 0.4444\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.5837 Acc: 0.4260\n",
            "val Loss: 1.5744 Acc: 0.4444\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.5799 Acc: 0.4260\n",
            "val Loss: 1.5736 Acc: 0.4444\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 1.5781 Acc: 0.4320\n",
            "val Loss: 1.5700 Acc: 0.4444\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 1.5783 Acc: 0.4260\n",
            "val Loss: 1.5701 Acc: 0.4444\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 1.5778 Acc: 0.4260\n",
            "val Loss: 1.5705 Acc: 0.4444\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 1.5780 Acc: 0.4320\n",
            "val Loss: 1.5698 Acc: 0.4444\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 1.5766 Acc: 0.4260\n",
            "val Loss: 1.5682 Acc: 0.4444\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 1.5774 Acc: 0.4379\n",
            "val Loss: 1.5692 Acc: 0.4444\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 1.5762 Acc: 0.4260\n",
            "val Loss: 1.5698 Acc: 0.4444\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 1.5754 Acc: 0.4320\n",
            "val Loss: 1.5706 Acc: 0.4444\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 1.5766 Acc: 0.4320\n",
            "val Loss: 1.5697 Acc: 0.4444\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 1.5755 Acc: 0.4320\n",
            "val Loss: 1.5701 Acc: 0.4444\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 1.5746 Acc: 0.4320\n",
            "val Loss: 1.5710 Acc: 0.4444\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 1.5768 Acc: 0.4320\n",
            "val Loss: 1.5703 Acc: 0.4444\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 1.5758 Acc: 0.4320\n",
            "val Loss: 1.5691 Acc: 0.4444\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 1.5760 Acc: 0.4260\n",
            "val Loss: 1.5682 Acc: 0.4444\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 1.5752 Acc: 0.4320\n",
            "val Loss: 1.5702 Acc: 0.4444\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 1.5761 Acc: 0.4320\n",
            "val Loss: 1.5679 Acc: 0.4444\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 1.5750 Acc: 0.4320\n",
            "val Loss: 1.5697 Acc: 0.4444\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 1.5754 Acc: 0.4379\n",
            "val Loss: 1.5679 Acc: 0.4444\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 1.5746 Acc: 0.4497\n",
            "val Loss: 1.5686 Acc: 0.4444\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 1.5758 Acc: 0.4320\n",
            "val Loss: 1.5692 Acc: 0.4444\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 1.5760 Acc: 0.4260\n",
            "val Loss: 1.5692 Acc: 0.4444\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 1.5764 Acc: 0.4320\n",
            "val Loss: 1.5688 Acc: 0.4583\n",
            "\n",
            "Training complete in 1m 37s\n",
            "Best val Acc: 0.458333\n",
            "Constructing Graph Learning Objects\n",
            "(4856, 1024)\n",
            "Complete\n",
            "Time taken = 109.6746847430004\n",
            "Coreset Size = 17\t Percent of data = 0.35%\n",
            "Coreset =  [4810, 1346, 1834, 1227, 483, 3925, 2499, 4038, 3919, 4438, 4790, 3300, 2525, 4574, 1321, 2866, 2246]\n",
            "[0 1 2 3 4 0 4 0 0 0 2 2 2 4 3 4 4]\n",
            "uc local_max\n",
            "Running half of the iterations takes 8.272671569997328\n",
            "Accuracy for half of the iterations is 77.0702634880803\n",
            "Running all the iterations takes 13.251231211997947\n",
            "Final accuracy is 90.01673173452315\n",
            "90.01673173452315\n",
            "This is experiment 18\n",
            "169\n",
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.5913 Acc: 0.3550\n",
            "val Loss: 1.5890 Acc: 0.3472\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.5895 Acc: 0.3550\n",
            "val Loss: 1.5863 Acc: 0.4028\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.5874 Acc: 0.3669\n",
            "val Loss: 1.5830 Acc: 0.4028\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.5847 Acc: 0.3314\n",
            "val Loss: 1.5780 Acc: 0.3611\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.5803 Acc: 0.3609\n",
            "val Loss: 1.5753 Acc: 0.3194\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.5764 Acc: 0.3728\n",
            "val Loss: 1.5704 Acc: 0.3611\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.5733 Acc: 0.3491\n",
            "val Loss: 1.5655 Acc: 0.4306\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.5678 Acc: 0.3964\n",
            "val Loss: 1.5625 Acc: 0.4583\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 1.5684 Acc: 0.3846\n",
            "val Loss: 1.5635 Acc: 0.3333\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 1.5683 Acc: 0.3964\n",
            "val Loss: 1.5631 Acc: 0.3333\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 1.5689 Acc: 0.3728\n",
            "val Loss: 1.5641 Acc: 0.3750\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 1.5677 Acc: 0.3787\n",
            "val Loss: 1.5644 Acc: 0.3333\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 1.5673 Acc: 0.3787\n",
            "val Loss: 1.5620 Acc: 0.3611\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 1.5672 Acc: 0.3314\n",
            "val Loss: 1.5624 Acc: 0.3750\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 1.5664 Acc: 0.3905\n",
            "val Loss: 1.5628 Acc: 0.3611\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 1.5657 Acc: 0.3846\n",
            "val Loss: 1.5622 Acc: 0.3611\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 1.5658 Acc: 0.3846\n",
            "val Loss: 1.5636 Acc: 0.4306\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 1.5677 Acc: 0.3609\n",
            "val Loss: 1.5625 Acc: 0.4028\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 1.5659 Acc: 0.3669\n",
            "val Loss: 1.5651 Acc: 0.3194\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 1.5659 Acc: 0.3905\n",
            "val Loss: 1.5645 Acc: 0.4028\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 1.5648 Acc: 0.4379\n",
            "val Loss: 1.5623 Acc: 0.4722\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 1.5654 Acc: 0.3787\n",
            "val Loss: 1.5649 Acc: 0.4028\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 1.5658 Acc: 0.3609\n",
            "val Loss: 1.5628 Acc: 0.3611\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 1.5642 Acc: 0.4024\n",
            "val Loss: 1.5640 Acc: 0.3889\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 1.5662 Acc: 0.3195\n",
            "val Loss: 1.5654 Acc: 0.3750\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 1.5652 Acc: 0.4260\n",
            "val Loss: 1.5640 Acc: 0.4028\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 1.5656 Acc: 0.3550\n",
            "val Loss: 1.5653 Acc: 0.3611\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 1.5661 Acc: 0.3432\n",
            "val Loss: 1.5666 Acc: 0.3056\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 1.5658 Acc: 0.3550\n",
            "val Loss: 1.5644 Acc: 0.3611\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 1.5662 Acc: 0.3669\n",
            "val Loss: 1.5661 Acc: 0.3333\n",
            "\n",
            "Training complete in 1m 38s\n",
            "Best val Acc: 0.472222\n",
            "Constructing Graph Learning Objects\n",
            "(4856, 1024)\n",
            "Complete\n",
            "Time taken = 110.47252966900123\n",
            "Coreset Size = 17\t Percent of data = 0.35%\n",
            "Coreset =  [4607, 4342, 306, 2043, 2645, 2058, 4598, 4103, 2176, 3761, 1267, 4571, 2385, 248, 3263, 3899, 3965]\n",
            "[0 1 2 3 4 0 2 0 4 4 4 0 0 0 0 2 4]\n",
            "uc local_max\n",
            "Running half of the iterations takes 8.386716812001396\n",
            "Accuracy for half of the iterations is 78.01129234629862\n",
            "Running all the iterations takes 13.365407291999873\n",
            "Final accuracy is 89.57055214723927\n",
            "89.57055214723927\n",
            "This is experiment 19\n",
            "169\n",
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.6074 Acc: 0.3432\n",
            "val Loss: 1.6051 Acc: 0.2639\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.6063 Acc: 0.3491\n",
            "val Loss: 1.6027 Acc: 0.3056\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.6042 Acc: 0.4142\n",
            "val Loss: 1.5996 Acc: 0.4306\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.6007 Acc: 0.4260\n",
            "val Loss: 1.5957 Acc: 0.4306\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.5969 Acc: 0.4320\n",
            "val Loss: 1.5931 Acc: 0.4444\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.5924 Acc: 0.4320\n",
            "val Loss: 1.5899 Acc: 0.4444\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.5869 Acc: 0.4320\n",
            "val Loss: 1.5857 Acc: 0.4444\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.5838 Acc: 0.4320\n",
            "val Loss: 1.5856 Acc: 0.4444\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 1.5824 Acc: 0.4320\n",
            "val Loss: 1.5849 Acc: 0.4444\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 1.5831 Acc: 0.4320\n",
            "val Loss: 1.5855 Acc: 0.4444\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 1.5815 Acc: 0.4260\n",
            "val Loss: 1.5857 Acc: 0.4444\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 1.5824 Acc: 0.4320\n",
            "val Loss: 1.5824 Acc: 0.4444\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 1.5805 Acc: 0.4320\n",
            "val Loss: 1.5827 Acc: 0.4444\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 1.5798 Acc: 0.4320\n",
            "val Loss: 1.5849 Acc: 0.4444\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 1.5794 Acc: 0.4320\n",
            "val Loss: 1.5815 Acc: 0.4444\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 1.5802 Acc: 0.4320\n",
            "val Loss: 1.5851 Acc: 0.4444\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 1.5793 Acc: 0.4320\n",
            "val Loss: 1.5824 Acc: 0.4444\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 1.5804 Acc: 0.4320\n",
            "val Loss: 1.5845 Acc: 0.4444\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 1.5798 Acc: 0.4320\n",
            "val Loss: 1.5829 Acc: 0.4306\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 1.5798 Acc: 0.4320\n",
            "val Loss: 1.5822 Acc: 0.4583\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 1.5816 Acc: 0.4320\n",
            "val Loss: 1.5825 Acc: 0.4444\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 1.5791 Acc: 0.4320\n",
            "val Loss: 1.5819 Acc: 0.4444\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 1.5808 Acc: 0.4320\n",
            "val Loss: 1.5823 Acc: 0.4444\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 1.5792 Acc: 0.4320\n",
            "val Loss: 1.5809 Acc: 0.4444\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 1.5780 Acc: 0.4320\n",
            "val Loss: 1.5827 Acc: 0.4444\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 1.5802 Acc: 0.4379\n",
            "val Loss: 1.5810 Acc: 0.4444\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 1.5813 Acc: 0.4320\n",
            "val Loss: 1.5817 Acc: 0.4444\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 1.5803 Acc: 0.4260\n",
            "val Loss: 1.5811 Acc: 0.4444\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 1.5799 Acc: 0.4320\n",
            "val Loss: 1.5831 Acc: 0.4444\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 1.5794 Acc: 0.4379\n",
            "val Loss: 1.5814 Acc: 0.4444\n",
            "\n",
            "Training complete in 1m 37s\n",
            "Best val Acc: 0.458333\n",
            "Constructing Graph Learning Objects\n",
            "(4856, 1024)\n",
            "Complete\n",
            "Time taken = 110.4701567919983\n",
            "Coreset Size = 16\t Percent of data = 0.33%\n",
            "Coreset =  [4705, 3030, 4242, 234, 1249, 77, 3978, 98, 726, 2362, 1235, 4474, 340, 844, 3232, 2641]\n",
            "[0 1 2 3 4 0 0 4 4 0 0 4 0 1 4 4]\n",
            "uc local_max\n",
            "Running half of the iterations takes 9.34561522399963\n",
            "Accuracy for half of the iterations is 76.6698024459078\n",
            "Running all the iterations takes 14.516123223998875\n",
            "Final accuracy is 88.85172798216277\n",
            "88.85172798216277\n",
            "This is experiment 20\n",
            "169\n",
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.5982 Acc: 0.3077\n",
            "val Loss: 1.5942 Acc: 0.3611\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.5964 Acc: 0.3373\n",
            "val Loss: 1.5930 Acc: 0.3750\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.5951 Acc: 0.3550\n",
            "val Loss: 1.5920 Acc: 0.3056\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.5914 Acc: 0.3669\n",
            "val Loss: 1.5883 Acc: 0.3472\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.5888 Acc: 0.3964\n",
            "val Loss: 1.5848 Acc: 0.4167\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.5850 Acc: 0.3550\n",
            "val Loss: 1.5817 Acc: 0.4306\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.5797 Acc: 0.3728\n",
            "val Loss: 1.5780 Acc: 0.3472\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.5768 Acc: 0.4142\n",
            "val Loss: 1.5780 Acc: 0.4028\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 1.5748 Acc: 0.4083\n",
            "val Loss: 1.5768 Acc: 0.4722\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 1.5758 Acc: 0.3787\n",
            "val Loss: 1.5782 Acc: 0.3333\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 1.5743 Acc: 0.4201\n",
            "val Loss: 1.5792 Acc: 0.3889\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 1.5740 Acc: 0.3846\n",
            "val Loss: 1.5770 Acc: 0.3889\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 1.5745 Acc: 0.3254\n",
            "val Loss: 1.5769 Acc: 0.3611\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 1.5740 Acc: 0.3432\n",
            "val Loss: 1.5775 Acc: 0.3194\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 1.5739 Acc: 0.3787\n",
            "val Loss: 1.5767 Acc: 0.3333\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 1.5732 Acc: 0.3491\n",
            "val Loss: 1.5767 Acc: 0.4028\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 1.5728 Acc: 0.4260\n",
            "val Loss: 1.5773 Acc: 0.4028\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 1.5735 Acc: 0.3609\n",
            "val Loss: 1.5764 Acc: 0.4167\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 1.5731 Acc: 0.3964\n",
            "val Loss: 1.5757 Acc: 0.3472\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 1.5738 Acc: 0.4201\n",
            "val Loss: 1.5766 Acc: 0.3750\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 1.5737 Acc: 0.3964\n",
            "val Loss: 1.5762 Acc: 0.3472\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 1.5728 Acc: 0.3787\n",
            "val Loss: 1.5765 Acc: 0.3472\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 1.5731 Acc: 0.3491\n",
            "val Loss: 1.5756 Acc: 0.3750\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 1.5720 Acc: 0.4083\n",
            "val Loss: 1.5761 Acc: 0.3472\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 1.5717 Acc: 0.4675\n",
            "val Loss: 1.5754 Acc: 0.4306\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 1.5717 Acc: 0.4379\n",
            "val Loss: 1.5737 Acc: 0.4722\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 1.5717 Acc: 0.4201\n",
            "val Loss: 1.5735 Acc: 0.4306\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 1.5726 Acc: 0.4379\n",
            "val Loss: 1.5736 Acc: 0.4583\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 1.5731 Acc: 0.4379\n",
            "val Loss: 1.5733 Acc: 0.4583\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 1.5721 Acc: 0.3905\n",
            "val Loss: 1.5738 Acc: 0.4861\n",
            "\n",
            "Training complete in 1m 37s\n",
            "Best val Acc: 0.486111\n",
            "Constructing Graph Learning Objects\n",
            "(4856, 1024)\n",
            "Complete\n",
            "Time taken = 110.51783626700126\n",
            "Coreset Size = 18\t Percent of data = 0.37%\n",
            "Coreset =  [4705, 3030, 4242, 234, 1249, 1307, 4121, 1757, 4435, 4648, 1689, 3666, 1014, 859, 1007, 4798, 2632, 3366]\n",
            "[0 1 2 3 4 0 0 0 0 0 4 4 4 0 2 0 4 3]\n",
            "uc local_max\n",
            "Running half of the iterations takes 8.447836654999264\n",
            "Accuracy for half of the iterations is 76.1531220583621\n",
            "Running all the iterations takes 13.551974396999867\n",
            "Final accuracy is 89.453125\n",
            "89.453125\n",
            "This is experiment 21\n",
            "169\n",
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.6206 Acc: 0.0296\n",
            "val Loss: 1.6128 Acc: 0.0278\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.6189 Acc: 0.0296\n",
            "val Loss: 1.6102 Acc: 0.0278\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.6175 Acc: 0.0710\n",
            "val Loss: 1.6077 Acc: 0.0833\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.6137 Acc: 0.1065\n",
            "val Loss: 1.6041 Acc: 0.0694\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.6102 Acc: 0.1893\n",
            "val Loss: 1.6014 Acc: 0.1667\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.6059 Acc: 0.3077\n",
            "val Loss: 1.5975 Acc: 0.2222\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.6010 Acc: 0.3846\n",
            "val Loss: 1.5924 Acc: 0.3889\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.5996 Acc: 0.3787\n",
            "val Loss: 1.5922 Acc: 0.3889\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 1.5981 Acc: 0.3787\n",
            "val Loss: 1.5937 Acc: 0.3194\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 1.5981 Acc: 0.3669\n",
            "val Loss: 1.5927 Acc: 0.4028\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 1.5981 Acc: 0.3609\n",
            "val Loss: 1.5921 Acc: 0.3333\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 1.5974 Acc: 0.3669\n",
            "val Loss: 1.5911 Acc: 0.4444\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 1.5968 Acc: 0.3728\n",
            "val Loss: 1.5925 Acc: 0.4444\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 1.5955 Acc: 0.3314\n",
            "val Loss: 1.5900 Acc: 0.4861\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 1.5963 Acc: 0.3669\n",
            "val Loss: 1.5922 Acc: 0.3750\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 1.5959 Acc: 0.3669\n",
            "val Loss: 1.5897 Acc: 0.5000\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 1.5960 Acc: 0.3254\n",
            "val Loss: 1.5899 Acc: 0.4444\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 1.5960 Acc: 0.3195\n",
            "val Loss: 1.5929 Acc: 0.4028\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 1.5954 Acc: 0.3195\n",
            "val Loss: 1.5907 Acc: 0.4167\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 1.5961 Acc: 0.3846\n",
            "val Loss: 1.5910 Acc: 0.5000\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 1.5950 Acc: 0.3609\n",
            "val Loss: 1.5915 Acc: 0.4028\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 1.5947 Acc: 0.3787\n",
            "val Loss: 1.5926 Acc: 0.4028\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 1.5946 Acc: 0.4142\n",
            "val Loss: 1.5920 Acc: 0.4028\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 1.5948 Acc: 0.3728\n",
            "val Loss: 1.5923 Acc: 0.4167\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 1.5961 Acc: 0.3905\n",
            "val Loss: 1.5918 Acc: 0.4306\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 1.5953 Acc: 0.3728\n",
            "val Loss: 1.5920 Acc: 0.3750\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 1.5952 Acc: 0.4024\n",
            "val Loss: 1.5925 Acc: 0.3889\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 1.5954 Acc: 0.3254\n",
            "val Loss: 1.5912 Acc: 0.4861\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 1.5963 Acc: 0.3195\n",
            "val Loss: 1.5916 Acc: 0.3750\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 1.5956 Acc: 0.3846\n",
            "val Loss: 1.5909 Acc: 0.4306\n",
            "\n",
            "Training complete in 1m 38s\n",
            "Best val Acc: 0.500000\n",
            "Constructing Graph Learning Objects\n",
            "(4856, 1024)\n",
            "Complete\n",
            "Time taken = 110.6461246229992\n",
            "Coreset Size = 21\t Percent of data = 0.43%\n",
            "Coreset =  [4369, 2803, 3490, 3347, 4565, 4267, 2511, 2429, 3066, 2974, 3296, 4308, 2306, 2978, 4370, 146, 2529, 2922, 4122, 2204, 302]\n",
            "[0 1 2 3 4 4 0 2 4 0 4 4 4 0 0 1 4 3 4 0 4]\n",
            "uc local_max\n",
            "Running half of the iterations takes 8.213707352999336\n",
            "Accuracy for half of the iterations is 77.32412060301507\n",
            "Running all the iterations takes 13.062982707000629\n",
            "Final accuracy is 89.43543879262158\n",
            "89.43543879262158\n",
            "This is experiment 22\n",
            "169\n",
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.6167 Acc: 0.1124\n",
            "val Loss: 1.6123 Acc: 0.1111\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.6130 Acc: 0.1893\n",
            "val Loss: 1.6108 Acc: 0.1528\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.6112 Acc: 0.2071\n",
            "val Loss: 1.6073 Acc: 0.2500\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.6083 Acc: 0.2781\n",
            "val Loss: 1.6033 Acc: 0.2778\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.6038 Acc: 0.3609\n",
            "val Loss: 1.5998 Acc: 0.4306\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.6000 Acc: 0.3432\n",
            "val Loss: 1.5946 Acc: 0.3611\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.5953 Acc: 0.3373\n",
            "val Loss: 1.5906 Acc: 0.3472\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.5908 Acc: 0.3669\n",
            "val Loss: 1.5900 Acc: 0.3611\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 1.5917 Acc: 0.3491\n",
            "val Loss: 1.5905 Acc: 0.4028\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 1.5913 Acc: 0.3550\n",
            "val Loss: 1.5919 Acc: 0.3889\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 1.5906 Acc: 0.3669\n",
            "val Loss: 1.5895 Acc: 0.4444\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 1.5913 Acc: 0.3669\n",
            "val Loss: 1.5899 Acc: 0.4167\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 1.5910 Acc: 0.3550\n",
            "val Loss: 1.5874 Acc: 0.3472\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 1.5882 Acc: 0.3846\n",
            "val Loss: 1.5911 Acc: 0.4028\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 1.5878 Acc: 0.3609\n",
            "val Loss: 1.5889 Acc: 0.4444\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 1.5893 Acc: 0.3669\n",
            "val Loss: 1.5897 Acc: 0.3889\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 1.5893 Acc: 0.3846\n",
            "val Loss: 1.5911 Acc: 0.3056\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 1.5874 Acc: 0.3669\n",
            "val Loss: 1.5905 Acc: 0.2917\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 1.5879 Acc: 0.3846\n",
            "val Loss: 1.5892 Acc: 0.3194\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 1.5876 Acc: 0.3669\n",
            "val Loss: 1.5900 Acc: 0.3750\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 1.5880 Acc: 0.3669\n",
            "val Loss: 1.5912 Acc: 0.2917\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 1.5878 Acc: 0.3669\n",
            "val Loss: 1.5907 Acc: 0.3611\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 1.5884 Acc: 0.3254\n",
            "val Loss: 1.5914 Acc: 0.4167\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 1.5880 Acc: 0.3669\n",
            "val Loss: 1.5888 Acc: 0.3333\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 1.5884 Acc: 0.3254\n",
            "val Loss: 1.5895 Acc: 0.3611\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 1.5896 Acc: 0.3314\n",
            "val Loss: 1.5906 Acc: 0.3333\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 1.5874 Acc: 0.3728\n",
            "val Loss: 1.5896 Acc: 0.2500\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 1.5890 Acc: 0.3254\n",
            "val Loss: 1.5892 Acc: 0.4028\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 1.5884 Acc: 0.3609\n",
            "val Loss: 1.5901 Acc: 0.3611\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 1.5875 Acc: 0.3728\n",
            "val Loss: 1.5894 Acc: 0.2500\n",
            "\n",
            "Training complete in 1m 37s\n",
            "Best val Acc: 0.444444\n",
            "Constructing Graph Learning Objects\n",
            "(4856, 1024)\n",
            "Complete\n",
            "Time taken = 110.50489218700022\n",
            "Coreset Size = 17\t Percent of data = 0.35%\n",
            "Coreset =  [4607, 4342, 306, 2043, 2645, 4319, 4505, 1943, 1612, 2345, 3513, 3906, 813, 3790, 269, 4833, 23]\n",
            "[0 1 2 3 4 0 4 2 4 4 2 4 0 0 0 0 0]\n",
            "uc local_max\n",
            "Running half of the iterations takes 8.321086164000008\n",
            "Accuracy for half of the iterations is 76.41154328732748\n",
            "Running all the iterations takes 13.21994791200268\n",
            "Final accuracy is 89.4032348020078\n",
            "89.4032348020078\n",
            "This is experiment 23\n",
            "169\n",
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.6172 Acc: 0.0473\n",
            "val Loss: 1.6123 Acc: 0.0000\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.6148 Acc: 0.0533\n",
            "val Loss: 1.6125 Acc: 0.0139\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.6127 Acc: 0.0888\n",
            "val Loss: 1.6089 Acc: 0.0694\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.6092 Acc: 0.1538\n",
            "val Loss: 1.6055 Acc: 0.0972\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.6059 Acc: 0.2485\n",
            "val Loss: 1.6018 Acc: 0.3333\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.6002 Acc: 0.3609\n",
            "val Loss: 1.5973 Acc: 0.4167\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.5951 Acc: 0.4260\n",
            "val Loss: 1.5917 Acc: 0.5000\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.5920 Acc: 0.3964\n",
            "val Loss: 1.5940 Acc: 0.4444\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 1.5932 Acc: 0.3491\n",
            "val Loss: 1.5945 Acc: 0.3750\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 1.5905 Acc: 0.4438\n",
            "val Loss: 1.5924 Acc: 0.4861\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 1.5913 Acc: 0.3728\n",
            "val Loss: 1.5910 Acc: 0.4306\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 1.5893 Acc: 0.4379\n",
            "val Loss: 1.5914 Acc: 0.4444\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 1.5896 Acc: 0.3964\n",
            "val Loss: 1.5914 Acc: 0.4583\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 1.5891 Acc: 0.4142\n",
            "val Loss: 1.5901 Acc: 0.4722\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 1.5891 Acc: 0.4320\n",
            "val Loss: 1.5905 Acc: 0.4306\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 1.5898 Acc: 0.4083\n",
            "val Loss: 1.5898 Acc: 0.4722\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 1.5882 Acc: 0.4438\n",
            "val Loss: 1.5900 Acc: 0.4722\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 1.5886 Acc: 0.4142\n",
            "val Loss: 1.5904 Acc: 0.5278\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 1.5883 Acc: 0.3787\n",
            "val Loss: 1.5902 Acc: 0.4722\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 1.5885 Acc: 0.4379\n",
            "val Loss: 1.5897 Acc: 0.4306\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 1.5887 Acc: 0.4083\n",
            "val Loss: 1.5923 Acc: 0.4722\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 1.5884 Acc: 0.4024\n",
            "val Loss: 1.5913 Acc: 0.4306\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 1.5885 Acc: 0.3669\n",
            "val Loss: 1.5917 Acc: 0.5139\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 1.5885 Acc: 0.3669\n",
            "val Loss: 1.5916 Acc: 0.4583\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 1.5883 Acc: 0.3728\n",
            "val Loss: 1.5891 Acc: 0.4306\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 1.5885 Acc: 0.3609\n",
            "val Loss: 1.5906 Acc: 0.4306\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 1.5874 Acc: 0.4142\n",
            "val Loss: 1.5905 Acc: 0.4444\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 1.5881 Acc: 0.3787\n",
            "val Loss: 1.5910 Acc: 0.4444\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 1.5872 Acc: 0.4320\n",
            "val Loss: 1.5913 Acc: 0.4306\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 1.5887 Acc: 0.3491\n",
            "val Loss: 1.5888 Acc: 0.4583\n",
            "\n",
            "Training complete in 1m 37s\n",
            "Best val Acc: 0.527778\n",
            "Constructing Graph Learning Objects\n",
            "(4856, 1024)\n",
            "Complete\n",
            "Time taken = 110.36000457800037\n",
            "Coreset Size = 19\t Percent of data = 0.39%\n",
            "Coreset =  [4232, 39, 1253, 2496, 315, 417, 2848, 4767, 3110, 2693, 4378, 162, 915, 179, 1212, 3775, 4426, 4122, 3534]\n",
            "[0 1 2 3 4 0 0 4 4 4 0 4 0 4 0 0 4 4 2]\n",
            "uc local_max\n",
            "Running half of the iterations takes 8.227254015000653\n",
            "Accuracy for half of the iterations is 76.64783427495291\n",
            "Running all the iterations takes 13.435899431999133\n",
            "Final accuracy is 89.78224455611391\n",
            "89.78224455611391\n",
            "This is experiment 24\n",
            "169\n",
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.6035 Acc: 0.2189\n",
            "val Loss: 1.5979 Acc: 0.3611\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.6016 Acc: 0.2130\n",
            "val Loss: 1.5967 Acc: 0.2778\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.5987 Acc: 0.2663\n",
            "val Loss: 1.5949 Acc: 0.3611\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.5964 Acc: 0.2249\n",
            "val Loss: 1.5904 Acc: 0.3333\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.5913 Acc: 0.3077\n",
            "val Loss: 1.5854 Acc: 0.4028\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.5877 Acc: 0.2781\n",
            "val Loss: 1.5813 Acc: 0.3472\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.5833 Acc: 0.3077\n",
            "val Loss: 1.5774 Acc: 0.3056\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.5806 Acc: 0.3136\n",
            "val Loss: 1.5745 Acc: 0.3750\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 1.5791 Acc: 0.3550\n",
            "val Loss: 1.5750 Acc: 0.3611\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 1.5788 Acc: 0.3373\n",
            "val Loss: 1.5748 Acc: 0.3611\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 1.5775 Acc: 0.4024\n",
            "val Loss: 1.5757 Acc: 0.2778\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 1.5786 Acc: 0.3491\n",
            "val Loss: 1.5752 Acc: 0.3472\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 1.5776 Acc: 0.3491\n",
            "val Loss: 1.5734 Acc: 0.3333\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 1.5748 Acc: 0.4142\n",
            "val Loss: 1.5737 Acc: 0.3194\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 1.5770 Acc: 0.3254\n",
            "val Loss: 1.5730 Acc: 0.3472\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 1.5750 Acc: 0.3314\n",
            "val Loss: 1.5735 Acc: 0.3889\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 1.5765 Acc: 0.3018\n",
            "val Loss: 1.5739 Acc: 0.3333\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 1.5763 Acc: 0.3254\n",
            "val Loss: 1.5734 Acc: 0.3611\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 1.5756 Acc: 0.3195\n",
            "val Loss: 1.5749 Acc: 0.3194\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 1.5759 Acc: 0.3550\n",
            "val Loss: 1.5738 Acc: 0.3889\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 1.5755 Acc: 0.3373\n",
            "val Loss: 1.5740 Acc: 0.3750\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 1.5763 Acc: 0.3077\n",
            "val Loss: 1.5751 Acc: 0.3056\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 1.5766 Acc: 0.3254\n",
            "val Loss: 1.5749 Acc: 0.3333\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 1.5761 Acc: 0.3314\n",
            "val Loss: 1.5747 Acc: 0.3333\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 1.5763 Acc: 0.2722\n",
            "val Loss: 1.5743 Acc: 0.3333\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 1.5761 Acc: 0.3254\n",
            "val Loss: 1.5754 Acc: 0.4444\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 1.5749 Acc: 0.3314\n",
            "val Loss: 1.5759 Acc: 0.4028\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 1.5766 Acc: 0.3373\n",
            "val Loss: 1.5773 Acc: 0.3472\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 1.5756 Acc: 0.3787\n",
            "val Loss: 1.5740 Acc: 0.3611\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 1.5751 Acc: 0.3491\n",
            "val Loss: 1.5757 Acc: 0.3889\n",
            "\n",
            "Training complete in 1m 39s\n",
            "Best val Acc: 0.444444\n",
            "Constructing Graph Learning Objects\n",
            "(4856, 1024)\n",
            "Complete\n",
            "Time taken = 111.58835901400016\n",
            "Coreset Size = 17\t Percent of data = 0.35%\n",
            "Coreset =  [3360, 4580, 4478, 314, 1807, 3459, 98, 742, 3489, 3448, 908, 3523, 3158, 3286, 4818, 4800, 2275]\n",
            "[0 1 2 3 4 4 4 0 0 0 4 0 4 0 0 2 4]\n",
            "uc local_max\n",
            "Running half of the iterations takes 8.600099682000291\n",
            "Accuracy for half of the iterations is 77.22710163111668\n",
            "Running all the iterations takes 13.479405928999768\n",
            "Final accuracy is 90.29559397657557\n",
            "90.29559397657557\n",
            "This is experiment 25\n",
            "169\n",
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.6204 Acc: 0.0118\n",
            "val Loss: 1.6182 Acc: 0.0278\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.6196 Acc: 0.0118\n",
            "val Loss: 1.6182 Acc: 0.0139\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.6153 Acc: 0.0296\n",
            "val Loss: 1.6170 Acc: 0.0417\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.6120 Acc: 0.0888\n",
            "val Loss: 1.6129 Acc: 0.0417\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.6067 Acc: 0.1657\n",
            "val Loss: 1.6098 Acc: 0.1389\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.6008 Acc: 0.3905\n",
            "val Loss: 1.6043 Acc: 0.2917\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.5983 Acc: 0.4201\n",
            "val Loss: 1.5980 Acc: 0.3750\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.5947 Acc: 0.4556\n",
            "val Loss: 1.5986 Acc: 0.3611\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 1.5925 Acc: 0.4675\n",
            "val Loss: 1.5970 Acc: 0.3750\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 1.5911 Acc: 0.4675\n",
            "val Loss: 1.5966 Acc: 0.3750\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 1.5926 Acc: 0.4615\n",
            "val Loss: 1.5962 Acc: 0.3750\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 1.5904 Acc: 0.4615\n",
            "val Loss: 1.5950 Acc: 0.3750\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 1.5903 Acc: 0.4615\n",
            "val Loss: 1.5930 Acc: 0.3750\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 1.5886 Acc: 0.4615\n",
            "val Loss: 1.5941 Acc: 0.3750\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 1.5888 Acc: 0.4615\n",
            "val Loss: 1.5938 Acc: 0.3750\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 1.5897 Acc: 0.4615\n",
            "val Loss: 1.5920 Acc: 0.3750\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 1.5882 Acc: 0.4615\n",
            "val Loss: 1.5949 Acc: 0.3750\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 1.5906 Acc: 0.4615\n",
            "val Loss: 1.5930 Acc: 0.3750\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 1.5900 Acc: 0.4615\n",
            "val Loss: 1.5927 Acc: 0.3750\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 1.5885 Acc: 0.4615\n",
            "val Loss: 1.5925 Acc: 0.3750\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 1.5906 Acc: 0.4615\n",
            "val Loss: 1.5936 Acc: 0.3750\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 1.5887 Acc: 0.4615\n",
            "val Loss: 1.5911 Acc: 0.3750\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 1.5901 Acc: 0.4615\n",
            "val Loss: 1.5898 Acc: 0.3750\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 1.5892 Acc: 0.4615\n",
            "val Loss: 1.5940 Acc: 0.3750\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 1.5878 Acc: 0.4615\n",
            "val Loss: 1.5935 Acc: 0.3750\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 1.5897 Acc: 0.4615\n",
            "val Loss: 1.5922 Acc: 0.3611\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 1.5884 Acc: 0.4615\n",
            "val Loss: 1.5944 Acc: 0.3750\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 1.5895 Acc: 0.4615\n",
            "val Loss: 1.5945 Acc: 0.3750\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 1.5898 Acc: 0.4615\n",
            "val Loss: 1.5910 Acc: 0.3750\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 1.5894 Acc: 0.4556\n",
            "val Loss: 1.5941 Acc: 0.3750\n",
            "\n",
            "Training complete in 1m 37s\n",
            "Best val Acc: 0.375000\n",
            "Constructing Graph Learning Objects\n",
            "(4856, 1024)\n",
            "Complete\n",
            "Time taken = 109.89920425400123\n",
            "Coreset Size = 17\t Percent of data = 0.35%\n",
            "Coreset =  [1485, 4281, 2901, 3431, 3229, 3072, 2492, 3357, 546, 1994, 1083, 984, 1711, 829, 1008, 4668, 3457]\n",
            "[0 1 2 3 4 2 0 0 0 4 0 0 0 0 0 0 4]\n",
            "uc local_max\n",
            "Running half of the iterations takes 8.280792456997006\n",
            "Accuracy for half of the iterations is 75.78419071518194\n",
            "Running all the iterations takes 13.263684057998034\n",
            "Final accuracy is 87.78583379810374\n",
            "87.78583379810374\n",
            "This is experiment 26\n",
            "169\n",
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.6143 Acc: 0.0533\n",
            "val Loss: 1.6082 Acc: 0.1111\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.6113 Acc: 0.1006\n",
            "val Loss: 1.6056 Acc: 0.1250\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.6104 Acc: 0.1006\n",
            "val Loss: 1.6019 Acc: 0.2361\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.6059 Acc: 0.1657\n",
            "val Loss: 1.5964 Acc: 0.3194\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.6024 Acc: 0.2781\n",
            "val Loss: 1.5958 Acc: 0.2778\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.5975 Acc: 0.3609\n",
            "val Loss: 1.5913 Acc: 0.3056\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.5941 Acc: 0.3787\n",
            "val Loss: 1.5871 Acc: 0.3611\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.5893 Acc: 0.4260\n",
            "val Loss: 1.5880 Acc: 0.2361\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 1.5874 Acc: 0.4142\n",
            "val Loss: 1.5879 Acc: 0.2222\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 1.5900 Acc: 0.3964\n",
            "val Loss: 1.5894 Acc: 0.2361\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 1.5892 Acc: 0.4201\n",
            "val Loss: 1.5870 Acc: 0.4028\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 1.5886 Acc: 0.4024\n",
            "val Loss: 1.5859 Acc: 0.4306\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 1.5871 Acc: 0.4083\n",
            "val Loss: 1.5878 Acc: 0.3750\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 1.5883 Acc: 0.4024\n",
            "val Loss: 1.5882 Acc: 0.2639\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 1.5874 Acc: 0.3846\n",
            "val Loss: 1.5849 Acc: 0.4306\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 1.5870 Acc: 0.3964\n",
            "val Loss: 1.5865 Acc: 0.3194\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 1.5858 Acc: 0.4379\n",
            "val Loss: 1.5874 Acc: 0.3611\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 1.5864 Acc: 0.4734\n",
            "val Loss: 1.5848 Acc: 0.4306\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 1.5855 Acc: 0.3964\n",
            "val Loss: 1.5862 Acc: 0.4167\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 1.5840 Acc: 0.4497\n",
            "val Loss: 1.5859 Acc: 0.4722\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 1.5863 Acc: 0.4379\n",
            "val Loss: 1.5857 Acc: 0.4306\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 1.5863 Acc: 0.3846\n",
            "val Loss: 1.5879 Acc: 0.2917\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 1.5863 Acc: 0.4379\n",
            "val Loss: 1.5860 Acc: 0.3750\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 1.5874 Acc: 0.3669\n",
            "val Loss: 1.5853 Acc: 0.3889\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 1.5865 Acc: 0.4083\n",
            "val Loss: 1.5869 Acc: 0.3750\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 1.5852 Acc: 0.4852\n",
            "val Loss: 1.5856 Acc: 0.5000\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 1.5862 Acc: 0.4260\n",
            "val Loss: 1.5860 Acc: 0.4028\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 1.5867 Acc: 0.4379\n",
            "val Loss: 1.5862 Acc: 0.4306\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 1.5854 Acc: 0.4260\n",
            "val Loss: 1.5864 Acc: 0.3611\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 1.5861 Acc: 0.3905\n",
            "val Loss: 1.5865 Acc: 0.3750\n",
            "\n",
            "Training complete in 1m 37s\n",
            "Best val Acc: 0.500000\n",
            "Constructing Graph Learning Objects\n",
            "(4856, 1024)\n",
            "Complete\n",
            "Time taken = 110.43527068399999\n",
            "Coreset Size = 20\t Percent of data = 0.41%\n",
            "Coreset =  [4369, 2803, 3490, 3347, 4565, 4374, 4327, 488, 1183, 1236, 3811, 956, 4286, 92, 1750, 97, 3296, 3548, 1115, 3092]\n",
            "[0 1 2 3 4 0 4 0 0 0 0 0 0 4 2 0 4 3 4 4]\n",
            "uc local_max\n",
            "Running half of the iterations takes 8.326564475999476\n",
            "Accuracy for half of the iterations is 76.45211930926217\n",
            "Running all the iterations takes 13.266284983998048\n",
            "Final accuracy is 89.94413407821229\n",
            "89.94413407821229\n",
            "This is experiment 27\n",
            "169\n",
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.6145 Acc: 0.1124\n",
            "val Loss: 1.6136 Acc: 0.0556\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.6135 Acc: 0.0828\n",
            "val Loss: 1.6105 Acc: 0.0972\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.6099 Acc: 0.2012\n",
            "val Loss: 1.6068 Acc: 0.2917\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.6059 Acc: 0.2663\n",
            "val Loss: 1.6028 Acc: 0.3333\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.6010 Acc: 0.3787\n",
            "val Loss: 1.6001 Acc: 0.4028\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.5966 Acc: 0.4556\n",
            "val Loss: 1.5962 Acc: 0.4167\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.5918 Acc: 0.4320\n",
            "val Loss: 1.5921 Acc: 0.3472\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.5873 Acc: 0.4497\n",
            "val Loss: 1.5923 Acc: 0.3472\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 1.5870 Acc: 0.4379\n",
            "val Loss: 1.5931 Acc: 0.3750\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 1.5868 Acc: 0.3669\n",
            "val Loss: 1.5928 Acc: 0.3472\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 1.5861 Acc: 0.4260\n",
            "val Loss: 1.5910 Acc: 0.3194\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 1.5856 Acc: 0.3964\n",
            "val Loss: 1.5902 Acc: 0.3194\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 1.5850 Acc: 0.4083\n",
            "val Loss: 1.5898 Acc: 0.2917\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 1.5837 Acc: 0.4320\n",
            "val Loss: 1.5910 Acc: 0.3194\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 1.5844 Acc: 0.3905\n",
            "val Loss: 1.5916 Acc: 0.3056\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 1.5835 Acc: 0.4438\n",
            "val Loss: 1.5916 Acc: 0.3472\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 1.5835 Acc: 0.4438\n",
            "val Loss: 1.5905 Acc: 0.3194\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 1.5838 Acc: 0.4734\n",
            "val Loss: 1.5908 Acc: 0.3333\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 1.5829 Acc: 0.4497\n",
            "val Loss: 1.5918 Acc: 0.2917\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 1.5838 Acc: 0.4142\n",
            "val Loss: 1.5899 Acc: 0.3472\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 1.5841 Acc: 0.4675\n",
            "val Loss: 1.5914 Acc: 0.2917\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 1.5840 Acc: 0.4201\n",
            "val Loss: 1.5917 Acc: 0.3611\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 1.5838 Acc: 0.4497\n",
            "val Loss: 1.5909 Acc: 0.3750\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 1.5826 Acc: 0.4083\n",
            "val Loss: 1.5903 Acc: 0.3194\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 1.5834 Acc: 0.4201\n",
            "val Loss: 1.5907 Acc: 0.3750\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 1.5832 Acc: 0.4556\n",
            "val Loss: 1.5926 Acc: 0.2500\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 1.5825 Acc: 0.4201\n",
            "val Loss: 1.5932 Acc: 0.3611\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 1.5841 Acc: 0.3728\n",
            "val Loss: 1.5926 Acc: 0.2639\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 1.5838 Acc: 0.4201\n",
            "val Loss: 1.5926 Acc: 0.3056\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 1.5827 Acc: 0.4320\n",
            "val Loss: 1.5909 Acc: 0.3750\n",
            "\n",
            "Training complete in 1m 39s\n",
            "Best val Acc: 0.416667\n",
            "Constructing Graph Learning Objects\n",
            "(4856, 1024)\n",
            "Complete\n",
            "Time taken = 112.36546033999912\n",
            "Coreset Size = 19\t Percent of data = 0.39%\n",
            "Coreset =  [3360, 4580, 4478, 314, 1807, 3513, 4785, 253, 2052, 4172, 4551, 1653, 2684, 498, 357, 2929, 1551, 657, 4533]\n",
            "[0 1 2 3 4 2 4 4 0 0 0 0 4 0 0 4 4 4 4]\n",
            "uc local_max\n",
            "Running half of the iterations takes 8.093576707000466\n",
            "Accuracy for half of the iterations is 75.26679221594476\n",
            "Running all the iterations takes 13.061406890999933\n",
            "Final accuracy is 87.66052484645449\n",
            "87.66052484645449\n",
            "This is experiment 28\n",
            "169\n",
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.6202 Acc: 0.0651\n",
            "val Loss: 1.6230 Acc: 0.0972\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.6189 Acc: 0.0414\n",
            "val Loss: 1.6233 Acc: 0.0833\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.6159 Acc: 0.1243\n",
            "val Loss: 1.6184 Acc: 0.1111\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.6145 Acc: 0.1006\n",
            "val Loss: 1.6175 Acc: 0.1111\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.6100 Acc: 0.1834\n",
            "val Loss: 1.6122 Acc: 0.0972\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.6053 Acc: 0.2308\n",
            "val Loss: 1.6075 Acc: 0.1111\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.6017 Acc: 0.2367\n",
            "val Loss: 1.6015 Acc: 0.1667\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.5980 Acc: 0.3254\n",
            "val Loss: 1.5991 Acc: 0.2083\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 1.5983 Acc: 0.2959\n",
            "val Loss: 1.6009 Acc: 0.2222\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 1.5973 Acc: 0.3491\n",
            "val Loss: 1.5982 Acc: 0.1389\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 1.5976 Acc: 0.3077\n",
            "val Loss: 1.5949 Acc: 0.2083\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 1.5969 Acc: 0.3136\n",
            "val Loss: 1.5964 Acc: 0.2222\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 1.5955 Acc: 0.3314\n",
            "val Loss: 1.5943 Acc: 0.2222\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 1.5959 Acc: 0.3018\n",
            "val Loss: 1.5951 Acc: 0.2361\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 1.5954 Acc: 0.3018\n",
            "val Loss: 1.5947 Acc: 0.2222\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 1.5956 Acc: 0.3254\n",
            "val Loss: 1.5909 Acc: 0.2500\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 1.5943 Acc: 0.3491\n",
            "val Loss: 1.5919 Acc: 0.2361\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 1.5954 Acc: 0.3077\n",
            "val Loss: 1.5924 Acc: 0.2361\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 1.5946 Acc: 0.3077\n",
            "val Loss: 1.5929 Acc: 0.2361\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 1.5950 Acc: 0.3018\n",
            "val Loss: 1.5930 Acc: 0.2917\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 1.5945 Acc: 0.3254\n",
            "val Loss: 1.5941 Acc: 0.2361\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 1.5944 Acc: 0.3373\n",
            "val Loss: 1.5936 Acc: 0.2222\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 1.5938 Acc: 0.3314\n",
            "val Loss: 1.5927 Acc: 0.2222\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 1.5957 Acc: 0.2722\n",
            "val Loss: 1.5937 Acc: 0.2639\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 1.5940 Acc: 0.3314\n",
            "val Loss: 1.5941 Acc: 0.2917\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 1.5941 Acc: 0.3254\n",
            "val Loss: 1.5934 Acc: 0.3194\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 1.5944 Acc: 0.3136\n",
            "val Loss: 1.5939 Acc: 0.2500\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 1.5943 Acc: 0.3018\n",
            "val Loss: 1.5984 Acc: 0.2222\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 1.5953 Acc: 0.3373\n",
            "val Loss: 1.5932 Acc: 0.3056\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 1.5958 Acc: 0.2840\n",
            "val Loss: 1.5943 Acc: 0.2917\n",
            "\n",
            "Training complete in 1m 38s\n",
            "Best val Acc: 0.319444\n",
            "Constructing Graph Learning Objects\n",
            "(4856, 1024)\n",
            "Complete\n",
            "Time taken = 110.89984289700078\n",
            "Coreset Size = 18\t Percent of data = 0.37%\n",
            "Coreset =  [109, 1520, 2539, 364, 4823, 1525, 4414, 1409, 2200, 3546, 3576, 94, 1248, 1151, 1393, 3965, 3333, 2384]\n",
            "[0 1 2 3 4 0 4 0 0 0 3 0 4 0 4 4 4 0]\n",
            "uc local_max\n",
            "Running half of the iterations takes 8.292636400001356\n",
            "Accuracy for half of the iterations is 76.8748038908064\n",
            "Running all the iterations takes 13.383822427000268\n",
            "Final accuracy is 90.01116071428571\n",
            "90.01116071428571\n",
            "This is experiment 29\n",
            "169\n",
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.5900 Acc: 0.4556\n",
            "val Loss: 1.5967 Acc: 0.4167\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.5879 Acc: 0.4438\n",
            "val Loss: 1.5958 Acc: 0.4167\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.5854 Acc: 0.4379\n",
            "val Loss: 1.5944 Acc: 0.4028\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.5840 Acc: 0.4379\n",
            "val Loss: 1.5912 Acc: 0.4167\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.5779 Acc: 0.4438\n",
            "val Loss: 1.5875 Acc: 0.4167\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.5742 Acc: 0.4438\n",
            "val Loss: 1.5824 Acc: 0.4167\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.5708 Acc: 0.4497\n",
            "val Loss: 1.5778 Acc: 0.4167\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.5666 Acc: 0.4438\n",
            "val Loss: 1.5780 Acc: 0.4167\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 1.5660 Acc: 0.4438\n",
            "val Loss: 1.5741 Acc: 0.4167\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 1.5656 Acc: 0.4438\n",
            "val Loss: 1.5724 Acc: 0.4306\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 1.5659 Acc: 0.4438\n",
            "val Loss: 1.5721 Acc: 0.4167\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 1.5648 Acc: 0.4379\n",
            "val Loss: 1.5717 Acc: 0.4167\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 1.5639 Acc: 0.4438\n",
            "val Loss: 1.5675 Acc: 0.4167\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 1.5640 Acc: 0.4438\n",
            "val Loss: 1.5679 Acc: 0.4167\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 1.5644 Acc: 0.4438\n",
            "val Loss: 1.5676 Acc: 0.4167\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 1.5635 Acc: 0.4438\n",
            "val Loss: 1.5685 Acc: 0.4167\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 1.5626 Acc: 0.4438\n",
            "val Loss: 1.5696 Acc: 0.4167\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 1.5632 Acc: 0.4438\n",
            "val Loss: 1.5676 Acc: 0.4167\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 1.5627 Acc: 0.4438\n",
            "val Loss: 1.5660 Acc: 0.4167\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 1.5636 Acc: 0.4438\n",
            "val Loss: 1.5692 Acc: 0.4167\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 1.5642 Acc: 0.4438\n",
            "val Loss: 1.5661 Acc: 0.4167\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 1.5632 Acc: 0.4438\n",
            "val Loss: 1.5681 Acc: 0.4167\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 1.5640 Acc: 0.4438\n",
            "val Loss: 1.5658 Acc: 0.4167\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 1.5637 Acc: 0.4438\n",
            "val Loss: 1.5686 Acc: 0.4167\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 1.5631 Acc: 0.4438\n",
            "val Loss: 1.5680 Acc: 0.4167\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 1.5638 Acc: 0.4438\n",
            "val Loss: 1.5675 Acc: 0.4167\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 1.5625 Acc: 0.4438\n",
            "val Loss: 1.5669 Acc: 0.4167\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 1.5643 Acc: 0.4438\n",
            "val Loss: 1.5664 Acc: 0.4167\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 1.5639 Acc: 0.4438\n",
            "val Loss: 1.5666 Acc: 0.4306\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 1.5639 Acc: 0.4438\n",
            "val Loss: 1.5670 Acc: 0.4167\n",
            "\n",
            "Training complete in 1m 38s\n",
            "Best val Acc: 0.430556\n",
            "Constructing Graph Learning Objects\n",
            "(4856, 1024)\n",
            "Complete\n",
            "Time taken = 111.08402600800036\n",
            "Coreset Size = 16\t Percent of data = 0.33%\n",
            "Coreset =  [4607, 4342, 306, 2043, 2645, 3808, 1861, 538, 1300, 4568, 2278, 325, 580, 219, 1961, 2204]\n",
            "[0 1 2 3 4 0 0 4 4 2 4 0 0 4 0 0]\n",
            "uc local_max\n",
            "Running half of the iterations takes 8.43570714699672\n",
            "Accuracy for half of the iterations is 76.04264659767952\n",
            "Running all the iterations takes 13.224871605998487\n",
            "Final accuracy is 89.35340022296543\n",
            "89.35340022296543\n",
            "This is experiment 30\n",
            "169\n",
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.5993 Acc: 0.3254\n",
            "val Loss: 1.5923 Acc: 0.5278\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.5988 Acc: 0.3787\n",
            "val Loss: 1.5902 Acc: 0.5417\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.5985 Acc: 0.3373\n",
            "val Loss: 1.5872 Acc: 0.5417\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.5965 Acc: 0.3491\n",
            "val Loss: 1.5844 Acc: 0.5278\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.5920 Acc: 0.3905\n",
            "val Loss: 1.5772 Acc: 0.5417\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.5890 Acc: 0.3964\n",
            "val Loss: 1.5733 Acc: 0.5556\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.5826 Acc: 0.3964\n",
            "val Loss: 1.5680 Acc: 0.5417\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.5826 Acc: 0.3905\n",
            "val Loss: 1.5664 Acc: 0.5278\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 1.5816 Acc: 0.3964\n",
            "val Loss: 1.5666 Acc: 0.5139\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 1.5802 Acc: 0.3905\n",
            "val Loss: 1.5671 Acc: 0.5278\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 1.5793 Acc: 0.3964\n",
            "val Loss: 1.5688 Acc: 0.5278\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 1.5806 Acc: 0.3964\n",
            "val Loss: 1.5672 Acc: 0.5139\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 1.5803 Acc: 0.3905\n",
            "val Loss: 1.5658 Acc: 0.5417\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 1.5785 Acc: 0.3964\n",
            "val Loss: 1.5646 Acc: 0.5278\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 1.5790 Acc: 0.3964\n",
            "val Loss: 1.5659 Acc: 0.5278\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 1.5799 Acc: 0.3964\n",
            "val Loss: 1.5656 Acc: 0.5278\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 1.5776 Acc: 0.3964\n",
            "val Loss: 1.5639 Acc: 0.5278\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 1.5778 Acc: 0.3964\n",
            "val Loss: 1.5643 Acc: 0.5278\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 1.5780 Acc: 0.3964\n",
            "val Loss: 1.5660 Acc: 0.5278\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 1.5782 Acc: 0.3964\n",
            "val Loss: 1.5660 Acc: 0.5278\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 1.5781 Acc: 0.3964\n",
            "val Loss: 1.5653 Acc: 0.5278\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 1.5793 Acc: 0.3905\n",
            "val Loss: 1.5653 Acc: 0.5417\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 1.5784 Acc: 0.3964\n",
            "val Loss: 1.5682 Acc: 0.5278\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 1.5775 Acc: 0.3964\n",
            "val Loss: 1.5691 Acc: 0.5278\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 1.5783 Acc: 0.3964\n",
            "val Loss: 1.5680 Acc: 0.5278\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 1.5780 Acc: 0.3964\n",
            "val Loss: 1.5684 Acc: 0.5278\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 1.5789 Acc: 0.3964\n",
            "val Loss: 1.5668 Acc: 0.5278\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 1.5782 Acc: 0.3964\n",
            "val Loss: 1.5685 Acc: 0.5278\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 1.5782 Acc: 0.3964\n",
            "val Loss: 1.5676 Acc: 0.5278\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 1.5788 Acc: 0.3964\n",
            "val Loss: 1.5682 Acc: 0.5278\n",
            "\n",
            "Training complete in 1m 38s\n",
            "Best val Acc: 0.555556\n",
            "Constructing Graph Learning Objects\n",
            "(4856, 1024)\n",
            "Complete\n",
            "Time taken = 110.98047428500286\n",
            "Coreset Size = 19\t Percent of data = 0.39%\n",
            "Coreset =  [4369, 2803, 3490, 3347, 4565, 2562, 2518, 3258, 267, 2567, 1035, 2119, 3127, 494, 768, 3229, 1605, 2187, 1861]\n",
            "[0 1 2 3 4 2 4 0 3 4 0 4 0 4 4 4 4 0 0]\n",
            "uc local_max\n",
            "Running half of the iterations takes 8.34806888499952\n",
            "Accuracy for half of the iterations is 75.58066541117388\n",
            "Running all the iterations takes 13.356141800999467\n",
            "Final accuracy is 88.21887213847013\n",
            "88.21887213847013\n",
            "This is experiment 31\n",
            "169\n",
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.6025 Acc: 0.4201\n",
            "val Loss: 1.6032 Acc: 0.4306\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.6030 Acc: 0.4201\n",
            "val Loss: 1.5999 Acc: 0.4444\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.5986 Acc: 0.4260\n",
            "val Loss: 1.5983 Acc: 0.4583\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.5956 Acc: 0.4260\n",
            "val Loss: 1.5939 Acc: 0.4583\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.5929 Acc: 0.4260\n",
            "val Loss: 1.5892 Acc: 0.4583\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.5879 Acc: 0.4260\n",
            "val Loss: 1.5851 Acc: 0.4583\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.5839 Acc: 0.4260\n",
            "val Loss: 1.5780 Acc: 0.4583\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.5806 Acc: 0.4260\n",
            "val Loss: 1.5786 Acc: 0.4583\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 1.5808 Acc: 0.4260\n",
            "val Loss: 1.5784 Acc: 0.4583\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 1.5802 Acc: 0.4260\n",
            "val Loss: 1.5775 Acc: 0.4583\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 1.5813 Acc: 0.4260\n",
            "val Loss: 1.5756 Acc: 0.4583\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 1.5813 Acc: 0.4260\n",
            "val Loss: 1.5748 Acc: 0.4583\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 1.5788 Acc: 0.4260\n",
            "val Loss: 1.5739 Acc: 0.4583\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 1.5798 Acc: 0.4260\n",
            "val Loss: 1.5742 Acc: 0.4583\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 1.5785 Acc: 0.4260\n",
            "val Loss: 1.5755 Acc: 0.4583\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 1.5786 Acc: 0.4260\n",
            "val Loss: 1.5741 Acc: 0.4583\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 1.5786 Acc: 0.4260\n",
            "val Loss: 1.5748 Acc: 0.4583\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 1.5796 Acc: 0.4260\n",
            "val Loss: 1.5731 Acc: 0.4583\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 1.5795 Acc: 0.4260\n",
            "val Loss: 1.5753 Acc: 0.4583\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 1.5795 Acc: 0.4260\n",
            "val Loss: 1.5743 Acc: 0.4583\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 1.5783 Acc: 0.4260\n",
            "val Loss: 1.5748 Acc: 0.4583\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 1.5782 Acc: 0.4260\n",
            "val Loss: 1.5755 Acc: 0.4583\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 1.5783 Acc: 0.4260\n",
            "val Loss: 1.5730 Acc: 0.4583\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 1.5786 Acc: 0.4260\n",
            "val Loss: 1.5736 Acc: 0.4583\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 1.5794 Acc: 0.4260\n",
            "val Loss: 1.5754 Acc: 0.4583\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 1.5787 Acc: 0.4260\n",
            "val Loss: 1.5732 Acc: 0.4583\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 1.5799 Acc: 0.4260\n",
            "val Loss: 1.5740 Acc: 0.4583\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 1.5792 Acc: 0.4260\n",
            "val Loss: 1.5733 Acc: 0.4583\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 1.5794 Acc: 0.4260\n",
            "val Loss: 1.5744 Acc: 0.4583\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 1.5766 Acc: 0.4260\n",
            "val Loss: 1.5739 Acc: 0.4583\n",
            "\n",
            "Training complete in 1m 39s\n",
            "Best val Acc: 0.458333\n",
            "Constructing Graph Learning Objects\n",
            "(4856, 1024)\n",
            "Complete\n",
            "Time taken = 112.02820141499978\n",
            "Coreset Size = 21\t Percent of data = 0.43%\n",
            "Coreset =  [4607, 4342, 306, 2043, 2645, 2195, 4466, 3009, 3657, 1155, 4032, 2788, 4755, 2896, 2187, 2736, 37, 4171, 1474, 1287, 2738]\n",
            "[0 1 2 3 4 4 0 4 0 4 0 1 0 4 0 2 0 0 0 0 0]\n",
            "uc local_max\n",
            "Running half of the iterations takes 8.59480570300002\n",
            "Accuracy for half of the iterations is 75.18844221105527\n",
            "Running all the iterations takes 13.565611718000582\n",
            "Final accuracy is 89.10005589714925\n",
            "89.10005589714925\n",
            "This is experiment 32\n",
            "169\n",
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.6124 Acc: 0.1420\n",
            "val Loss: 1.6210 Acc: 0.0833\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.6118 Acc: 0.1716\n",
            "val Loss: 1.6178 Acc: 0.0556\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.6090 Acc: 0.1716\n",
            "val Loss: 1.6130 Acc: 0.1111\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.6053 Acc: 0.2189\n",
            "val Loss: 1.6070 Acc: 0.1806\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.6033 Acc: 0.2485\n",
            "val Loss: 1.6026 Acc: 0.2222\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.5997 Acc: 0.3077\n",
            "val Loss: 1.5987 Acc: 0.3472\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.5965 Acc: 0.3373\n",
            "val Loss: 1.5928 Acc: 0.4722\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.5934 Acc: 0.3432\n",
            "val Loss: 1.5898 Acc: 0.4722\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 1.5934 Acc: 0.3432\n",
            "val Loss: 1.5887 Acc: 0.5278\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 1.5928 Acc: 0.3373\n",
            "val Loss: 1.5894 Acc: 0.5694\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 1.5927 Acc: 0.3491\n",
            "val Loss: 1.5900 Acc: 0.4306\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 1.5933 Acc: 0.3373\n",
            "val Loss: 1.5866 Acc: 0.5417\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 1.5907 Acc: 0.4024\n",
            "val Loss: 1.5882 Acc: 0.4722\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 1.5910 Acc: 0.3550\n",
            "val Loss: 1.5871 Acc: 0.4722\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 1.5901 Acc: 0.3669\n",
            "val Loss: 1.5868 Acc: 0.4583\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 1.5892 Acc: 0.3905\n",
            "val Loss: 1.5862 Acc: 0.5000\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 1.5911 Acc: 0.3373\n",
            "val Loss: 1.5871 Acc: 0.4583\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 1.5902 Acc: 0.3728\n",
            "val Loss: 1.5860 Acc: 0.5000\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 1.5900 Acc: 0.3846\n",
            "val Loss: 1.5843 Acc: 0.4861\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 1.5905 Acc: 0.3728\n",
            "val Loss: 1.5854 Acc: 0.4861\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 1.5918 Acc: 0.3136\n",
            "val Loss: 1.5847 Acc: 0.5139\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 1.5899 Acc: 0.3609\n",
            "val Loss: 1.5877 Acc: 0.5000\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 1.5912 Acc: 0.3846\n",
            "val Loss: 1.5865 Acc: 0.5000\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 1.5917 Acc: 0.3432\n",
            "val Loss: 1.5844 Acc: 0.5000\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 1.5898 Acc: 0.3787\n",
            "val Loss: 1.5845 Acc: 0.4861\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 1.5913 Acc: 0.3432\n",
            "val Loss: 1.5838 Acc: 0.5556\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 1.5898 Acc: 0.3787\n",
            "val Loss: 1.5836 Acc: 0.4583\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 1.5890 Acc: 0.4201\n",
            "val Loss: 1.5846 Acc: 0.4583\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 1.5913 Acc: 0.3373\n",
            "val Loss: 1.5855 Acc: 0.4167\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 1.5909 Acc: 0.3669\n",
            "val Loss: 1.5835 Acc: 0.5694\n",
            "\n",
            "Training complete in 1m 38s\n",
            "Best val Acc: 0.569444\n",
            "Constructing Graph Learning Objects\n",
            "(4856, 1024)\n",
            "Complete\n",
            "Time taken = 111.03125527899829\n",
            "Coreset Size = 16\t Percent of data = 0.33%\n",
            "Coreset =  [4431, 169, 1854, 2887, 589, 3905, 4289, 452, 2235, 2786, 1571, 977, 3102, 949, 665, 3525]\n",
            "[0 1 2 3 4 0 2 0 2 0 2 4 4 0 0 4]\n",
            "uc local_max\n",
            "Running half of the iterations takes 8.42761698600225\n",
            "Accuracy for half of the iterations is 76.32486672938225\n",
            "Running all the iterations takes 13.229143487002148\n",
            "Final accuracy is 88.96321070234114\n",
            "88.96321070234114\n",
            "This is experiment 33\n",
            "169\n",
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.6088 Acc: 0.0947\n",
            "val Loss: 1.5944 Acc: 0.4306\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.6063 Acc: 0.1124\n",
            "val Loss: 1.5899 Acc: 0.4861\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.6054 Acc: 0.1538\n",
            "val Loss: 1.5850 Acc: 0.4583\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.6033 Acc: 0.2249\n",
            "val Loss: 1.5833 Acc: 0.4028\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.5994 Acc: 0.2899\n",
            "val Loss: 1.5771 Acc: 0.4167\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.5950 Acc: 0.3373\n",
            "val Loss: 1.5744 Acc: 0.4722\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.5920 Acc: 0.3609\n",
            "val Loss: 1.5742 Acc: 0.4444\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.5882 Acc: 0.3905\n",
            "val Loss: 1.5739 Acc: 0.5000\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 1.5889 Acc: 0.3254\n",
            "val Loss: 1.5745 Acc: 0.5000\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 1.5894 Acc: 0.3373\n",
            "val Loss: 1.5734 Acc: 0.4444\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 1.5885 Acc: 0.3373\n",
            "val Loss: 1.5775 Acc: 0.3750\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 1.5873 Acc: 0.4142\n",
            "val Loss: 1.5778 Acc: 0.3333\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 1.5875 Acc: 0.3964\n",
            "val Loss: 1.5759 Acc: 0.3889\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 1.5877 Acc: 0.3491\n",
            "val Loss: 1.5752 Acc: 0.5000\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 1.5859 Acc: 0.3787\n",
            "val Loss: 1.5756 Acc: 0.4583\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 1.5847 Acc: 0.4024\n",
            "val Loss: 1.5784 Acc: 0.3750\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 1.5858 Acc: 0.3728\n",
            "val Loss: 1.5761 Acc: 0.4028\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 1.5853 Acc: 0.3846\n",
            "val Loss: 1.5746 Acc: 0.5139\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 1.5857 Acc: 0.3728\n",
            "val Loss: 1.5747 Acc: 0.4583\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 1.5865 Acc: 0.3787\n",
            "val Loss: 1.5757 Acc: 0.4444\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 1.5857 Acc: 0.3787\n",
            "val Loss: 1.5723 Acc: 0.5833\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 1.5863 Acc: 0.3669\n",
            "val Loss: 1.5749 Acc: 0.4583\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 1.5852 Acc: 0.3905\n",
            "val Loss: 1.5750 Acc: 0.4861\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 1.5855 Acc: 0.3787\n",
            "val Loss: 1.5747 Acc: 0.4861\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 1.5858 Acc: 0.4260\n",
            "val Loss: 1.5758 Acc: 0.4306\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 1.5866 Acc: 0.3195\n",
            "val Loss: 1.5765 Acc: 0.4861\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 1.5868 Acc: 0.3669\n",
            "val Loss: 1.5763 Acc: 0.5000\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 1.5854 Acc: 0.3787\n",
            "val Loss: 1.5724 Acc: 0.5556\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 1.5855 Acc: 0.3905\n",
            "val Loss: 1.5753 Acc: 0.5417\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 1.5863 Acc: 0.3669\n",
            "val Loss: 1.5766 Acc: 0.4861\n",
            "\n",
            "Training complete in 1m 39s\n",
            "Best val Acc: 0.583333\n",
            "Constructing Graph Learning Objects\n",
            "(4856, 1024)\n",
            "Complete\n",
            "Time taken = 111.8220546099983\n",
            "Coreset Size = 15\t Percent of data = 0.31%\n",
            "Coreset =  [4705, 3030, 4242, 234, 1249, 4321, 2480, 3232, 4102, 2355, 1335, 2271, 1523, 3755, 4669]\n",
            "[0 1 2 3 4 0 0 4 4 0 0 0 4 4 2]\n",
            "uc local_max\n",
            "Running half of the iterations takes 8.4444777839999\n",
            "Accuracy for half of the iterations is 76.42633228840126\n",
            "Running all the iterations takes 13.425933780999912\n",
            "Final accuracy is 90.08356545961003\n",
            "90.08356545961003\n",
            "This is experiment 34\n",
            "169\n",
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.6136 Acc: 0.2071\n",
            "val Loss: 1.6092 Acc: 0.3611\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.6112 Acc: 0.2722\n",
            "val Loss: 1.6061 Acc: 0.4028\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.6085 Acc: 0.3432\n",
            "val Loss: 1.6038 Acc: 0.3889\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.6050 Acc: 0.4142\n",
            "val Loss: 1.6006 Acc: 0.4028\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.6008 Acc: 0.4556\n",
            "val Loss: 1.5973 Acc: 0.4028\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.5966 Acc: 0.4497\n",
            "val Loss: 1.5967 Acc: 0.4028\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.5904 Acc: 0.4556\n",
            "val Loss: 1.5917 Acc: 0.4028\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.5882 Acc: 0.4497\n",
            "val Loss: 1.5902 Acc: 0.4028\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 1.5860 Acc: 0.4497\n",
            "val Loss: 1.5884 Acc: 0.4028\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 1.5854 Acc: 0.4497\n",
            "val Loss: 1.5909 Acc: 0.4028\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 1.5856 Acc: 0.4497\n",
            "val Loss: 1.5903 Acc: 0.4028\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 1.5857 Acc: 0.4497\n",
            "val Loss: 1.5898 Acc: 0.4028\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 1.5851 Acc: 0.4497\n",
            "val Loss: 1.5920 Acc: 0.4028\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 1.5825 Acc: 0.4497\n",
            "val Loss: 1.5915 Acc: 0.4028\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 1.5831 Acc: 0.4497\n",
            "val Loss: 1.5925 Acc: 0.4028\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 1.5831 Acc: 0.4497\n",
            "val Loss: 1.5892 Acc: 0.4028\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 1.5836 Acc: 0.4497\n",
            "val Loss: 1.5915 Acc: 0.4028\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 1.5836 Acc: 0.4497\n",
            "val Loss: 1.5910 Acc: 0.4028\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 1.5831 Acc: 0.4497\n",
            "val Loss: 1.5913 Acc: 0.4028\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 1.5835 Acc: 0.4497\n",
            "val Loss: 1.5928 Acc: 0.4028\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 1.5818 Acc: 0.4497\n",
            "val Loss: 1.5896 Acc: 0.4028\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 1.5841 Acc: 0.4497\n",
            "val Loss: 1.5918 Acc: 0.4028\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 1.5840 Acc: 0.4497\n",
            "val Loss: 1.5902 Acc: 0.3889\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 1.5824 Acc: 0.4497\n",
            "val Loss: 1.5913 Acc: 0.4028\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 1.5831 Acc: 0.4497\n",
            "val Loss: 1.5917 Acc: 0.4028\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 1.5828 Acc: 0.4497\n",
            "val Loss: 1.5891 Acc: 0.4028\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 1.5824 Acc: 0.4497\n",
            "val Loss: 1.5883 Acc: 0.4028\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 1.5835 Acc: 0.4497\n",
            "val Loss: 1.5902 Acc: 0.4028\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 1.5834 Acc: 0.4497\n",
            "val Loss: 1.5892 Acc: 0.4028\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 1.5833 Acc: 0.4497\n",
            "val Loss: 1.5873 Acc: 0.4028\n",
            "\n",
            "Training complete in 1m 39s\n",
            "Best val Acc: 0.402778\n",
            "Constructing Graph Learning Objects\n",
            "(4856, 1024)\n",
            "Complete\n",
            "Time taken = 112.28435545699904\n",
            "Coreset Size = 21\t Percent of data = 0.43%\n",
            "Coreset =  [2952, 1630, 4394, 2968, 3370, 2126, 4440, 403, 3540, 3339, 4097, 4494, 2599, 3542, 3055, 3101, 3131, 746, 3883, 2633, 4716]\n",
            "[0 1 2 3 4 4 2 4 0 4 0 0 0 0 0 0 4 2 0 4 2]\n",
            "uc local_max\n",
            "Running half of the iterations takes 8.333263952998095\n",
            "Accuracy for half of the iterations is 74.90577889447236\n",
            "Running all the iterations takes 13.322822337999241\n",
            "Final accuracy is 89.15595304639463\n",
            "89.15595304639463\n",
            "This is experiment 35\n",
            "169\n",
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.6127 Acc: 0.1716\n",
            "val Loss: 1.6119 Acc: 0.1944\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.6101 Acc: 0.1834\n",
            "val Loss: 1.6088 Acc: 0.2917\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.6088 Acc: 0.2130\n",
            "val Loss: 1.6060 Acc: 0.2778\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.6051 Acc: 0.2840\n",
            "val Loss: 1.6031 Acc: 0.3611\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.6011 Acc: 0.2722\n",
            "val Loss: 1.5992 Acc: 0.2917\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.5970 Acc: 0.4083\n",
            "val Loss: 1.5946 Acc: 0.3611\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.5933 Acc: 0.3491\n",
            "val Loss: 1.5889 Acc: 0.3889\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.5891 Acc: 0.4024\n",
            "val Loss: 1.5890 Acc: 0.3889\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 1.5890 Acc: 0.4260\n",
            "val Loss: 1.5886 Acc: 0.4583\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 1.5882 Acc: 0.3728\n",
            "val Loss: 1.5869 Acc: 0.3611\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 1.5882 Acc: 0.4083\n",
            "val Loss: 1.5856 Acc: 0.4583\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 1.5889 Acc: 0.3609\n",
            "val Loss: 1.5869 Acc: 0.3889\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 1.5874 Acc: 0.4142\n",
            "val Loss: 1.5858 Acc: 0.4167\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 1.5857 Acc: 0.4379\n",
            "val Loss: 1.5862 Acc: 0.3889\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 1.5864 Acc: 0.3728\n",
            "val Loss: 1.5851 Acc: 0.4444\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 1.5872 Acc: 0.3846\n",
            "val Loss: 1.5852 Acc: 0.4167\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 1.5855 Acc: 0.4497\n",
            "val Loss: 1.5849 Acc: 0.4167\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 1.5858 Acc: 0.4260\n",
            "val Loss: 1.5859 Acc: 0.3611\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 1.5866 Acc: 0.4201\n",
            "val Loss: 1.5854 Acc: 0.4444\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 1.5860 Acc: 0.4260\n",
            "val Loss: 1.5852 Acc: 0.4583\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 1.5862 Acc: 0.3905\n",
            "val Loss: 1.5854 Acc: 0.4444\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 1.5865 Acc: 0.3432\n",
            "val Loss: 1.5861 Acc: 0.3611\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 1.5856 Acc: 0.3728\n",
            "val Loss: 1.5854 Acc: 0.4028\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 1.5867 Acc: 0.4497\n",
            "val Loss: 1.5854 Acc: 0.3611\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 1.5869 Acc: 0.3314\n",
            "val Loss: 1.5859 Acc: 0.4028\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 1.5865 Acc: 0.3964\n",
            "val Loss: 1.5851 Acc: 0.4028\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 1.5861 Acc: 0.3905\n",
            "val Loss: 1.5844 Acc: 0.5000\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 1.5856 Acc: 0.3846\n",
            "val Loss: 1.5871 Acc: 0.3056\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 1.5855 Acc: 0.3846\n",
            "val Loss: 1.5860 Acc: 0.4028\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 1.5850 Acc: 0.3728\n",
            "val Loss: 1.5843 Acc: 0.4167\n",
            "\n",
            "Training complete in 1m 40s\n",
            "Best val Acc: 0.500000\n",
            "Constructing Graph Learning Objects\n",
            "(4856, 1024)\n",
            "Complete\n",
            "Time taken = 112.64357143400048\n",
            "Coreset Size = 17\t Percent of data = 0.35%\n",
            "Coreset =  [2426, 191, 4840, 1295, 1772, 2702, 462, 1840, 4103, 3955, 2268, 184, 1035, 4435, 1144, 1957, 2007]\n",
            "[0 1 2 3 4 2 0 0 0 4 4 4 0 0 0 0 0]\n",
            "uc local_max\n",
            "Running half of the iterations takes 8.37095635100195\n",
            "Accuracy for half of the iterations is 76.53701380175659\n",
            "Running all the iterations takes 13.501958008000656\n",
            "Final accuracy is 89.96095928611265\n",
            "89.96095928611265\n",
            "This is experiment 36\n",
            "169\n",
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.6184 Acc: 0.0414\n",
            "val Loss: 1.6170 Acc: 0.0278\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.6165 Acc: 0.0592\n",
            "val Loss: 1.6145 Acc: 0.0833\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.6134 Acc: 0.1183\n",
            "val Loss: 1.6121 Acc: 0.1389\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.6105 Acc: 0.2189\n",
            "val Loss: 1.6086 Acc: 0.2917\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.6069 Acc: 0.2663\n",
            "val Loss: 1.6034 Acc: 0.4583\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.6046 Acc: 0.3077\n",
            "val Loss: 1.5982 Acc: 0.5278\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.5999 Acc: 0.4024\n",
            "val Loss: 1.5954 Acc: 0.5000\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.5974 Acc: 0.3669\n",
            "val Loss: 1.5953 Acc: 0.4722\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 1.5968 Acc: 0.4142\n",
            "val Loss: 1.5953 Acc: 0.4861\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 1.5959 Acc: 0.3669\n",
            "val Loss: 1.5958 Acc: 0.4444\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 1.5953 Acc: 0.3609\n",
            "val Loss: 1.5955 Acc: 0.4722\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 1.5956 Acc: 0.4201\n",
            "val Loss: 1.5955 Acc: 0.5000\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 1.5962 Acc: 0.3787\n",
            "val Loss: 1.5969 Acc: 0.4722\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 1.5947 Acc: 0.3905\n",
            "val Loss: 1.5962 Acc: 0.4861\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 1.5953 Acc: 0.3787\n",
            "val Loss: 1.5951 Acc: 0.5000\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 1.5935 Acc: 0.4142\n",
            "val Loss: 1.5966 Acc: 0.4861\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 1.5937 Acc: 0.3905\n",
            "val Loss: 1.5950 Acc: 0.4861\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 1.5933 Acc: 0.3964\n",
            "val Loss: 1.5956 Acc: 0.4306\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 1.5953 Acc: 0.4201\n",
            "val Loss: 1.5933 Acc: 0.5278\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 1.5951 Acc: 0.4024\n",
            "val Loss: 1.5928 Acc: 0.4583\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 1.5950 Acc: 0.4083\n",
            "val Loss: 1.5925 Acc: 0.5000\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 1.5933 Acc: 0.3905\n",
            "val Loss: 1.5914 Acc: 0.4722\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 1.5945 Acc: 0.3609\n",
            "val Loss: 1.5938 Acc: 0.4722\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 1.5936 Acc: 0.4083\n",
            "val Loss: 1.5902 Acc: 0.4861\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 1.5936 Acc: 0.3964\n",
            "val Loss: 1.5900 Acc: 0.4861\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 1.5945 Acc: 0.4142\n",
            "val Loss: 1.5907 Acc: 0.5000\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 1.5944 Acc: 0.3846\n",
            "val Loss: 1.5915 Acc: 0.4861\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 1.5944 Acc: 0.4142\n",
            "val Loss: 1.5922 Acc: 0.4306\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 1.5939 Acc: 0.4142\n",
            "val Loss: 1.5901 Acc: 0.4444\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 1.5936 Acc: 0.4024\n",
            "val Loss: 1.5918 Acc: 0.4167\n",
            "\n",
            "Training complete in 1m 40s\n",
            "Best val Acc: 0.527778\n",
            "Constructing Graph Learning Objects\n",
            "(4856, 1024)\n",
            "Complete\n",
            "Time taken = 112.75521019900043\n",
            "Coreset Size = 17\t Percent of data = 0.35%\n",
            "Coreset =  [1485, 4281, 2901, 3431, 3229, 4736, 1017, 3957, 178, 1474, 2058, 8, 2727, 1960, 618, 1541, 2929]\n",
            "[0 1 2 3 4 4 2 4 0 0 0 0 0 2 4 4 4]\n",
            "uc local_max\n",
            "Running half of the iterations takes 8.274466136001138\n",
            "Accuracy for half of the iterations is 76.2547051442911\n",
            "Running all the iterations takes 13.293452817000798\n",
            "Final accuracy is 88.62242052426102\n",
            "88.62242052426102\n",
            "This is experiment 37\n",
            "169\n",
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.6076 Acc: 0.1361\n",
            "val Loss: 1.6094 Acc: 0.2222\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.6057 Acc: 0.1893\n",
            "val Loss: 1.6048 Acc: 0.1944\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.6035 Acc: 0.1716\n",
            "val Loss: 1.6010 Acc: 0.2222\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.6011 Acc: 0.1775\n",
            "val Loss: 1.5967 Acc: 0.2361\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.5986 Acc: 0.1953\n",
            "val Loss: 1.5929 Acc: 0.2222\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.5925 Acc: 0.3018\n",
            "val Loss: 1.5870 Acc: 0.2500\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.5894 Acc: 0.3136\n",
            "val Loss: 1.5847 Acc: 0.2361\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.5857 Acc: 0.3254\n",
            "val Loss: 1.5834 Acc: 0.3472\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 1.5859 Acc: 0.3254\n",
            "val Loss: 1.5825 Acc: 0.2500\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 1.5852 Acc: 0.3373\n",
            "val Loss: 1.5805 Acc: 0.3611\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 1.5841 Acc: 0.3905\n",
            "val Loss: 1.5814 Acc: 0.3472\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 1.5850 Acc: 0.2899\n",
            "val Loss: 1.5810 Acc: 0.4167\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 1.5851 Acc: 0.3077\n",
            "val Loss: 1.5812 Acc: 0.3472\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 1.5832 Acc: 0.3905\n",
            "val Loss: 1.5798 Acc: 0.3333\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 1.5825 Acc: 0.3550\n",
            "val Loss: 1.5789 Acc: 0.4583\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 1.5834 Acc: 0.3432\n",
            "val Loss: 1.5805 Acc: 0.3750\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 1.5828 Acc: 0.3609\n",
            "val Loss: 1.5794 Acc: 0.3889\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 1.5820 Acc: 0.3787\n",
            "val Loss: 1.5814 Acc: 0.3333\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 1.5825 Acc: 0.3728\n",
            "val Loss: 1.5813 Acc: 0.4028\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 1.5825 Acc: 0.3254\n",
            "val Loss: 1.5802 Acc: 0.4028\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 1.5821 Acc: 0.3550\n",
            "val Loss: 1.5796 Acc: 0.4306\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 1.5825 Acc: 0.3550\n",
            "val Loss: 1.5820 Acc: 0.4028\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 1.5830 Acc: 0.3491\n",
            "val Loss: 1.5793 Acc: 0.3889\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 1.5812 Acc: 0.3787\n",
            "val Loss: 1.5816 Acc: 0.3889\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 1.5821 Acc: 0.4024\n",
            "val Loss: 1.5823 Acc: 0.3056\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 1.5830 Acc: 0.3314\n",
            "val Loss: 1.5806 Acc: 0.3333\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 1.5837 Acc: 0.3550\n",
            "val Loss: 1.5812 Acc: 0.3750\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 1.5831 Acc: 0.3432\n",
            "val Loss: 1.5849 Acc: 0.3472\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 1.5829 Acc: 0.3609\n",
            "val Loss: 1.5831 Acc: 0.3333\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 1.5831 Acc: 0.3669\n",
            "val Loss: 1.5843 Acc: 0.3333\n",
            "\n",
            "Training complete in 1m 39s\n",
            "Best val Acc: 0.458333\n",
            "Constructing Graph Learning Objects\n",
            "(4856, 1024)\n",
            "Complete\n",
            "Time taken = 112.14477959099895\n",
            "Coreset Size = 17\t Percent of data = 0.35%\n",
            "Coreset =  [4705, 3030, 4242, 234, 1249, 682, 3385, 1011, 1081, 2782, 3938, 3761, 94, 2945, 4435, 3106, 135]\n",
            "[0 1 2 3 4 2 0 4 0 4 0 4 0 0 0 3 4]\n",
            "uc local_max\n",
            "Running half of the iterations takes 8.654020673002378\n",
            "Accuracy for half of the iterations is 75.56461731493098\n",
            "Running all the iterations takes 13.947500988000684\n",
            "Final accuracy is 90.23982152816508\n",
            "90.23982152816508\n",
            "This is experiment 38\n",
            "169\n",
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.6061 Acc: 0.1479\n",
            "val Loss: 1.6061 Acc: 0.1806\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.6058 Acc: 0.1893\n",
            "val Loss: 1.6049 Acc: 0.1111\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.6018 Acc: 0.2130\n",
            "val Loss: 1.6007 Acc: 0.1667\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.6008 Acc: 0.2426\n",
            "val Loss: 1.5989 Acc: 0.2083\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.5968 Acc: 0.2485\n",
            "val Loss: 1.5942 Acc: 0.3472\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.5930 Acc: 0.2899\n",
            "val Loss: 1.5917 Acc: 0.4306\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.5895 Acc: 0.3136\n",
            "val Loss: 1.5850 Acc: 0.4028\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.5859 Acc: 0.3077\n",
            "val Loss: 1.5834 Acc: 0.4306\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 1.5862 Acc: 0.3314\n",
            "val Loss: 1.5850 Acc: 0.4028\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 1.5846 Acc: 0.3018\n",
            "val Loss: 1.5844 Acc: 0.3333\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 1.5847 Acc: 0.3136\n",
            "val Loss: 1.5820 Acc: 0.4167\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 1.5842 Acc: 0.3373\n",
            "val Loss: 1.5830 Acc: 0.3333\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 1.5827 Acc: 0.3669\n",
            "val Loss: 1.5820 Acc: 0.3194\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 1.5839 Acc: 0.3550\n",
            "val Loss: 1.5818 Acc: 0.2778\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 1.5815 Acc: 0.3787\n",
            "val Loss: 1.5811 Acc: 0.4167\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 1.5835 Acc: 0.3787\n",
            "val Loss: 1.5787 Acc: 0.4167\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 1.5810 Acc: 0.4083\n",
            "val Loss: 1.5805 Acc: 0.2639\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 1.5829 Acc: 0.3195\n",
            "val Loss: 1.5802 Acc: 0.3750\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 1.5818 Acc: 0.3846\n",
            "val Loss: 1.5814 Acc: 0.3889\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 1.5839 Acc: 0.3018\n",
            "val Loss: 1.5805 Acc: 0.3750\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 1.5826 Acc: 0.4260\n",
            "val Loss: 1.5819 Acc: 0.2917\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 1.5815 Acc: 0.3728\n",
            "val Loss: 1.5806 Acc: 0.3472\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 1.5834 Acc: 0.3314\n",
            "val Loss: 1.5804 Acc: 0.2917\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 1.5826 Acc: 0.3609\n",
            "val Loss: 1.5814 Acc: 0.3333\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 1.5824 Acc: 0.3609\n",
            "val Loss: 1.5792 Acc: 0.3611\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 1.5827 Acc: 0.3254\n",
            "val Loss: 1.5805 Acc: 0.3889\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 1.5817 Acc: 0.3491\n",
            "val Loss: 1.5811 Acc: 0.3333\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 1.5826 Acc: 0.3491\n",
            "val Loss: 1.5790 Acc: 0.4444\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 1.5830 Acc: 0.3254\n",
            "val Loss: 1.5817 Acc: 0.3750\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 1.5834 Acc: 0.3609\n",
            "val Loss: 1.5795 Acc: 0.3750\n",
            "\n",
            "Training complete in 1m 39s\n",
            "Best val Acc: 0.444444\n",
            "Constructing Graph Learning Objects\n",
            "(4856, 1024)\n",
            "Complete\n",
            "Time taken = 111.9046258060007\n",
            "Coreset Size = 18\t Percent of data = 0.37%\n",
            "Coreset =  [3360, 4580, 4478, 314, 1807, 2495, 3268, 417, 2949, 1198, 581, 4418, 2922, 8, 2622, 665, 3795, 3746]\n",
            "[0 1 2 3 4 0 4 0 4 3 2 2 3 0 2 0 0 4]\n",
            "uc local_max\n",
            "Running half of the iterations takes 8.34866672300268\n",
            "Accuracy for half of the iterations is 76.78067147787888\n",
            "Running all the iterations takes 13.38066752099985\n",
            "Final accuracy is 89.56473214285714\n",
            "89.56473214285714\n",
            "This is experiment 39\n",
            "169\n",
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.6185 Acc: 0.0533\n",
            "val Loss: 1.6126 Acc: 0.2361\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.6157 Acc: 0.1243\n",
            "val Loss: 1.6103 Acc: 0.3056\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.6145 Acc: 0.1538\n",
            "val Loss: 1.6068 Acc: 0.3611\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.6081 Acc: 0.2959\n",
            "val Loss: 1.6033 Acc: 0.4028\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.6045 Acc: 0.3964\n",
            "val Loss: 1.5979 Acc: 0.4028\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.5995 Acc: 0.4379\n",
            "val Loss: 1.5948 Acc: 0.4028\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.5939 Acc: 0.4438\n",
            "val Loss: 1.5941 Acc: 0.4028\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.5906 Acc: 0.4497\n",
            "val Loss: 1.5963 Acc: 0.3889\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 1.5888 Acc: 0.4497\n",
            "val Loss: 1.5918 Acc: 0.4028\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 1.5903 Acc: 0.4497\n",
            "val Loss: 1.5939 Acc: 0.4028\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 1.5901 Acc: 0.4497\n",
            "val Loss: 1.5928 Acc: 0.4028\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 1.5884 Acc: 0.4497\n",
            "val Loss: 1.5956 Acc: 0.4028\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 1.5878 Acc: 0.4438\n",
            "val Loss: 1.5932 Acc: 0.4028\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 1.5868 Acc: 0.4497\n",
            "val Loss: 1.5926 Acc: 0.4028\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 1.5857 Acc: 0.4497\n",
            "val Loss: 1.5956 Acc: 0.4028\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 1.5857 Acc: 0.4497\n",
            "val Loss: 1.5920 Acc: 0.4028\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 1.5857 Acc: 0.4497\n",
            "val Loss: 1.5945 Acc: 0.4028\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 1.5864 Acc: 0.4497\n",
            "val Loss: 1.5940 Acc: 0.4028\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 1.5872 Acc: 0.4497\n",
            "val Loss: 1.5938 Acc: 0.4028\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 1.5859 Acc: 0.4497\n",
            "val Loss: 1.5924 Acc: 0.4028\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 1.5860 Acc: 0.4497\n",
            "val Loss: 1.5929 Acc: 0.4028\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 1.5869 Acc: 0.4497\n",
            "val Loss: 1.5932 Acc: 0.4028\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 1.5860 Acc: 0.4497\n",
            "val Loss: 1.5966 Acc: 0.4028\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 1.5854 Acc: 0.4438\n",
            "val Loss: 1.5926 Acc: 0.4028\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 1.5862 Acc: 0.4497\n",
            "val Loss: 1.5948 Acc: 0.4028\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 1.5867 Acc: 0.4497\n",
            "val Loss: 1.5921 Acc: 0.4028\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 1.5843 Acc: 0.4497\n",
            "val Loss: 1.5939 Acc: 0.4028\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 1.5866 Acc: 0.4497\n",
            "val Loss: 1.5940 Acc: 0.4028\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 1.5838 Acc: 0.4497\n",
            "val Loss: 1.5930 Acc: 0.4028\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 1.5854 Acc: 0.4497\n",
            "val Loss: 1.5925 Acc: 0.4028\n",
            "\n",
            "Training complete in 1m 38s\n",
            "Best val Acc: 0.402778\n",
            "Constructing Graph Learning Objects\n",
            "(4856, 1024)\n",
            "Complete\n",
            "Time taken = 112.00418646500111\n",
            "Coreset Size = 21\t Percent of data = 0.43%\n",
            "Coreset =  [4369, 2803, 3490, 3347, 4565, 4060, 3945, 466, 2202, 3137, 1769, 2816, 3603, 1861, 3927, 3881, 1488, 3828, 2930, 1780, 3899]\n",
            "[0 1 2 3 4 0 2 4 3 2 2 0 0 0 2 0 0 4 0 4 2]\n",
            "uc local_max\n",
            "Running half of the iterations takes 8.228798042000562\n",
            "Accuracy for half of the iterations is 75.84798994974874\n",
            "Running all the iterations takes 13.266822762998345\n",
            "Final accuracy is 88.82057015092231\n",
            "88.82057015092231\n",
            "This is experiment 40\n",
            "169\n",
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.6099 Acc: 0.3314\n",
            "val Loss: 1.6111 Acc: 0.1250\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.6085 Acc: 0.3491\n",
            "val Loss: 1.6098 Acc: 0.1667\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.6057 Acc: 0.3373\n",
            "val Loss: 1.6094 Acc: 0.1806\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.6032 Acc: 0.3609\n",
            "val Loss: 1.6078 Acc: 0.1250\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.6006 Acc: 0.3728\n",
            "val Loss: 1.6043 Acc: 0.1389\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.5955 Acc: 0.3728\n",
            "val Loss: 1.6013 Acc: 0.1667\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.5918 Acc: 0.3728\n",
            "val Loss: 1.5967 Acc: 0.1667\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.5870 Acc: 0.3728\n",
            "val Loss: 1.5966 Acc: 0.1667\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 1.5876 Acc: 0.3787\n",
            "val Loss: 1.5968 Acc: 0.1806\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 1.5859 Acc: 0.3728\n",
            "val Loss: 1.5967 Acc: 0.1806\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 1.5856 Acc: 0.3787\n",
            "val Loss: 1.5963 Acc: 0.1944\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 1.5853 Acc: 0.3669\n",
            "val Loss: 1.5972 Acc: 0.2083\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 1.5852 Acc: 0.3787\n",
            "val Loss: 1.5946 Acc: 0.2639\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 1.5851 Acc: 0.3728\n",
            "val Loss: 1.5932 Acc: 0.2500\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 1.5850 Acc: 0.3728\n",
            "val Loss: 1.5911 Acc: 0.2500\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 1.5848 Acc: 0.3728\n",
            "val Loss: 1.5931 Acc: 0.2500\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 1.5844 Acc: 0.3728\n",
            "val Loss: 1.5910 Acc: 0.2917\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 1.5847 Acc: 0.3728\n",
            "val Loss: 1.5933 Acc: 0.2639\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 1.5836 Acc: 0.3728\n",
            "val Loss: 1.5929 Acc: 0.2639\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 1.5843 Acc: 0.3728\n",
            "val Loss: 1.5929 Acc: 0.2639\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 1.5835 Acc: 0.3787\n",
            "val Loss: 1.5917 Acc: 0.2639\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 1.5846 Acc: 0.3787\n",
            "val Loss: 1.5922 Acc: 0.2917\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 1.5848 Acc: 0.3728\n",
            "val Loss: 1.5926 Acc: 0.2917\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 1.5838 Acc: 0.3728\n",
            "val Loss: 1.5904 Acc: 0.2778\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 1.5838 Acc: 0.3787\n",
            "val Loss: 1.5919 Acc: 0.2639\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 1.5824 Acc: 0.3728\n",
            "val Loss: 1.5918 Acc: 0.2500\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 1.5855 Acc: 0.3787\n",
            "val Loss: 1.5906 Acc: 0.2917\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 1.5835 Acc: 0.3728\n",
            "val Loss: 1.5930 Acc: 0.2500\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 1.5833 Acc: 0.3787\n",
            "val Loss: 1.5900 Acc: 0.2639\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 1.5842 Acc: 0.3728\n",
            "val Loss: 1.5888 Acc: 0.2639\n",
            "\n",
            "Training complete in 1m 38s\n",
            "Best val Acc: 0.291667\n",
            "Constructing Graph Learning Objects\n",
            "(4856, 1024)\n",
            "Complete\n",
            "Time taken = 110.83386891699774\n",
            "Coreset Size = 16\t Percent of data = 0.33%\n",
            "Coreset =  [320, 4817, 1094, 2035, 1001, 102, 498, 404, 73, 1112, 1699, 2660, 983, 1928, 3965, 3926]\n",
            "[0 1 2 3 4 4 0 0 4 4 2 0 2 2 4 0]\n",
            "uc local_max\n",
            "Running half of the iterations takes 8.551664923001226\n",
            "Accuracy for half of the iterations is 76.16807776732519\n",
            "Running all the iterations takes 13.695350151003368\n",
            "Final accuracy is 90.41248606465997\n",
            "90.41248606465997\n",
            "This is experiment 41\n",
            "169\n",
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.6063 Acc: 0.2663\n",
            "val Loss: 1.5980 Acc: 0.4306\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.6037 Acc: 0.2899\n",
            "val Loss: 1.5962 Acc: 0.4306\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.6011 Acc: 0.3254\n",
            "val Loss: 1.5937 Acc: 0.4306\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.5989 Acc: 0.3373\n",
            "val Loss: 1.5903 Acc: 0.4306\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.5962 Acc: 0.4083\n",
            "val Loss: 1.5880 Acc: 0.4306\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.5920 Acc: 0.4201\n",
            "val Loss: 1.5816 Acc: 0.4306\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.5862 Acc: 0.4260\n",
            "val Loss: 1.5768 Acc: 0.4306\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.5843 Acc: 0.4260\n",
            "val Loss: 1.5790 Acc: 0.4306\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 1.5843 Acc: 0.4320\n",
            "val Loss: 1.5785 Acc: 0.4306\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 1.5830 Acc: 0.4320\n",
            "val Loss: 1.5783 Acc: 0.4306\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 1.5827 Acc: 0.4320\n",
            "val Loss: 1.5793 Acc: 0.4306\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 1.5828 Acc: 0.4379\n",
            "val Loss: 1.5792 Acc: 0.4444\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 1.5820 Acc: 0.4438\n",
            "val Loss: 1.5800 Acc: 0.4444\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 1.5817 Acc: 0.4320\n",
            "val Loss: 1.5815 Acc: 0.4028\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 1.5811 Acc: 0.4320\n",
            "val Loss: 1.5816 Acc: 0.4306\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 1.5817 Acc: 0.4320\n",
            "val Loss: 1.5812 Acc: 0.4167\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 1.5813 Acc: 0.4438\n",
            "val Loss: 1.5807 Acc: 0.4306\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 1.5809 Acc: 0.4379\n",
            "val Loss: 1.5798 Acc: 0.4306\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 1.5801 Acc: 0.4438\n",
            "val Loss: 1.5817 Acc: 0.4306\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 1.5802 Acc: 0.4379\n",
            "val Loss: 1.5824 Acc: 0.4306\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 1.5809 Acc: 0.4379\n",
            "val Loss: 1.5801 Acc: 0.4306\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 1.5800 Acc: 0.4379\n",
            "val Loss: 1.5802 Acc: 0.4306\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 1.5796 Acc: 0.4438\n",
            "val Loss: 1.5808 Acc: 0.4306\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 1.5799 Acc: 0.4320\n",
            "val Loss: 1.5813 Acc: 0.4306\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 1.5803 Acc: 0.4260\n",
            "val Loss: 1.5799 Acc: 0.4306\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 1.5806 Acc: 0.4320\n",
            "val Loss: 1.5813 Acc: 0.4028\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 1.5810 Acc: 0.4379\n",
            "val Loss: 1.5789 Acc: 0.4306\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 1.5815 Acc: 0.4320\n",
            "val Loss: 1.5810 Acc: 0.4306\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 1.5807 Acc: 0.4379\n",
            "val Loss: 1.5791 Acc: 0.4306\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 1.5812 Acc: 0.4379\n",
            "val Loss: 1.5814 Acc: 0.4167\n",
            "\n",
            "Training complete in 1m 37s\n",
            "Best val Acc: 0.444444\n",
            "Constructing Graph Learning Objects\n",
            "(4856, 1024)\n",
            "Complete\n",
            "Time taken = 110.23375354100062\n",
            "Coreset Size = 16\t Percent of data = 0.33%\n",
            "Coreset =  [2952, 1630, 4394, 2968, 3370, 335, 2221, 336, 3196, 2403, 3632, 4718, 4700, 445, 13, 4621]\n",
            "[0 1 2 3 4 4 0 4 4 0 4 4 2 4 2 4]\n",
            "uc local_max\n",
            "Running half of the iterations takes 8.377502764997189\n",
            "Accuracy for half of the iterations is 76.57572906867357\n",
            "Running all the iterations takes 13.371969433999766\n",
            "Final accuracy is 89.74358974358974\n",
            "89.74358974358974\n",
            "This is experiment 42\n",
            "169\n",
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.5988 Acc: 0.4024\n",
            "val Loss: 1.6019 Acc: 0.4444\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.5961 Acc: 0.4260\n",
            "val Loss: 1.6005 Acc: 0.4306\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.5951 Acc: 0.4260\n",
            "val Loss: 1.5997 Acc: 0.4444\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.5911 Acc: 0.4260\n",
            "val Loss: 1.5966 Acc: 0.4444\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.5875 Acc: 0.4379\n",
            "val Loss: 1.5930 Acc: 0.4444\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.5832 Acc: 0.4438\n",
            "val Loss: 1.5877 Acc: 0.4444\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.5790 Acc: 0.4320\n",
            "val Loss: 1.5839 Acc: 0.4444\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.5757 Acc: 0.4320\n",
            "val Loss: 1.5820 Acc: 0.4444\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 1.5736 Acc: 0.4320\n",
            "val Loss: 1.5807 Acc: 0.4444\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 1.5744 Acc: 0.4320\n",
            "val Loss: 1.5773 Acc: 0.4444\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 1.5728 Acc: 0.4320\n",
            "val Loss: 1.5776 Acc: 0.4444\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 1.5728 Acc: 0.4320\n",
            "val Loss: 1.5778 Acc: 0.4444\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 1.5734 Acc: 0.4260\n",
            "val Loss: 1.5756 Acc: 0.4444\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 1.5716 Acc: 0.4320\n",
            "val Loss: 1.5758 Acc: 0.4444\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 1.5710 Acc: 0.4260\n",
            "val Loss: 1.5746 Acc: 0.4444\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 1.5715 Acc: 0.4320\n",
            "val Loss: 1.5717 Acc: 0.4444\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 1.5724 Acc: 0.4260\n",
            "val Loss: 1.5723 Acc: 0.4444\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 1.5702 Acc: 0.4320\n",
            "val Loss: 1.5740 Acc: 0.4444\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 1.5722 Acc: 0.4320\n",
            "val Loss: 1.5722 Acc: 0.4444\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 1.5709 Acc: 0.4320\n",
            "val Loss: 1.5727 Acc: 0.4444\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 1.5719 Acc: 0.4320\n",
            "val Loss: 1.5711 Acc: 0.4444\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 1.5705 Acc: 0.4320\n",
            "val Loss: 1.5696 Acc: 0.4444\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 1.5712 Acc: 0.4320\n",
            "val Loss: 1.5714 Acc: 0.4444\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 1.5715 Acc: 0.4320\n",
            "val Loss: 1.5716 Acc: 0.4444\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 1.5711 Acc: 0.4260\n",
            "val Loss: 1.5720 Acc: 0.4444\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 1.5716 Acc: 0.4320\n",
            "val Loss: 1.5691 Acc: 0.4444\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 1.5713 Acc: 0.4379\n",
            "val Loss: 1.5703 Acc: 0.4444\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 1.5712 Acc: 0.4320\n",
            "val Loss: 1.5711 Acc: 0.4444\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 1.5712 Acc: 0.4320\n",
            "val Loss: 1.5700 Acc: 0.4444\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 1.5713 Acc: 0.4320\n",
            "val Loss: 1.5707 Acc: 0.4444\n",
            "\n",
            "Training complete in 1m 39s\n",
            "Best val Acc: 0.444444\n",
            "Constructing Graph Learning Objects\n",
            "(4856, 1024)\n",
            "Complete\n",
            "Time taken = 112.39989918300125\n",
            "Coreset Size = 17\t Percent of data = 0.35%\n",
            "Coreset =  [4705, 3030, 4242, 234, 1249, 4024, 1087, 2654, 4338, 487, 3513, 1003, 3654, 2867, 3592, 1346, 4747]\n",
            "[0 1 2 3 4 0 4 0 0 4 2 2 0 0 4 1 0]\n",
            "uc local_max\n",
            "Running half of the iterations takes 8.823328061000211\n",
            "Accuracy for half of the iterations is 76.12923462986198\n",
            "Running all the iterations takes 14.330896081999526\n",
            "Final accuracy is 89.4590072504183\n",
            "89.4590072504183\n",
            "This is experiment 43\n",
            "169\n",
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.6075 Acc: 0.1657\n",
            "val Loss: 1.6128 Acc: 0.0972\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.6054 Acc: 0.2544\n",
            "val Loss: 1.6102 Acc: 0.1111\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.6017 Acc: 0.3136\n",
            "val Loss: 1.6068 Acc: 0.1389\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.6001 Acc: 0.3018\n",
            "val Loss: 1.6055 Acc: 0.1528\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.5945 Acc: 0.3905\n",
            "val Loss: 1.6005 Acc: 0.2361\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.5913 Acc: 0.3787\n",
            "val Loss: 1.5961 Acc: 0.2917\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.5844 Acc: 0.4734\n",
            "val Loss: 1.5918 Acc: 0.3056\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.5808 Acc: 0.4497\n",
            "val Loss: 1.5904 Acc: 0.3333\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 1.5810 Acc: 0.4083\n",
            "val Loss: 1.5906 Acc: 0.2778\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 1.5804 Acc: 0.4556\n",
            "val Loss: 1.5909 Acc: 0.2778\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 1.5802 Acc: 0.4083\n",
            "val Loss: 1.5871 Acc: 0.3333\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 1.5785 Acc: 0.4438\n",
            "val Loss: 1.5871 Acc: 0.4028\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 1.5794 Acc: 0.4260\n",
            "val Loss: 1.5842 Acc: 0.4167\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 1.5779 Acc: 0.4556\n",
            "val Loss: 1.5858 Acc: 0.4167\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 1.5775 Acc: 0.4438\n",
            "val Loss: 1.5870 Acc: 0.3472\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 1.5778 Acc: 0.4201\n",
            "val Loss: 1.5846 Acc: 0.3889\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 1.5776 Acc: 0.4260\n",
            "val Loss: 1.5842 Acc: 0.3056\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 1.5771 Acc: 0.4615\n",
            "val Loss: 1.5860 Acc: 0.3611\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 1.5780 Acc: 0.4320\n",
            "val Loss: 1.5832 Acc: 0.4444\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 1.5787 Acc: 0.4024\n",
            "val Loss: 1.5835 Acc: 0.4028\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 1.5779 Acc: 0.4497\n",
            "val Loss: 1.5844 Acc: 0.3611\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 1.5767 Acc: 0.4615\n",
            "val Loss: 1.5853 Acc: 0.3472\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 1.5770 Acc: 0.4201\n",
            "val Loss: 1.5832 Acc: 0.3611\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 1.5770 Acc: 0.4320\n",
            "val Loss: 1.5863 Acc: 0.3333\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 1.5777 Acc: 0.4615\n",
            "val Loss: 1.5844 Acc: 0.3056\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 1.5773 Acc: 0.4497\n",
            "val Loss: 1.5842 Acc: 0.3472\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 1.5769 Acc: 0.4852\n",
            "val Loss: 1.5860 Acc: 0.3472\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 1.5776 Acc: 0.4379\n",
            "val Loss: 1.5824 Acc: 0.3611\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 1.5786 Acc: 0.4201\n",
            "val Loss: 1.5831 Acc: 0.3611\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 1.5773 Acc: 0.4142\n",
            "val Loss: 1.5837 Acc: 0.3611\n",
            "\n",
            "Training complete in 1m 40s\n",
            "Best val Acc: 0.444444\n",
            "Constructing Graph Learning Objects\n",
            "(4856, 1024)\n",
            "Complete\n",
            "Time taken = 112.88528870799928\n",
            "Coreset Size = 20\t Percent of data = 0.41%\n",
            "Coreset =  [924, 4806, 3218, 4161, 117, 1442, 2235, 224, 3101, 2342, 2356, 4512, 1676, 2428, 1252, 1652, 2582, 3033, 1861, 2911]\n",
            "[0 1 2 3 4 2 2 4 0 4 4 4 0 4 4 0 4 4 0 0]\n",
            "uc local_max\n",
            "Running half of the iterations takes 8.438779064999835\n",
            "Accuracy for half of the iterations is 75.25902668759812\n",
            "Running all the iterations takes 13.628996575000201\n",
            "Final accuracy is 89.55307262569832\n",
            "89.55307262569832\n",
            "This is experiment 44\n",
            "169\n",
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.6096 Acc: 0.2722\n",
            "val Loss: 1.5997 Acc: 0.3472\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.6091 Acc: 0.2959\n",
            "val Loss: 1.5998 Acc: 0.3333\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.6056 Acc: 0.3136\n",
            "val Loss: 1.5963 Acc: 0.3472\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.6004 Acc: 0.3432\n",
            "val Loss: 1.5937 Acc: 0.3889\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.5954 Acc: 0.3550\n",
            "val Loss: 1.5899 Acc: 0.3750\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.5929 Acc: 0.3491\n",
            "val Loss: 1.5878 Acc: 0.3333\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.5858 Acc: 0.3550\n",
            "val Loss: 1.5834 Acc: 0.3750\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.5821 Acc: 0.3964\n",
            "val Loss: 1.5843 Acc: 0.3056\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 1.5816 Acc: 0.4320\n",
            "val Loss: 1.5826 Acc: 0.3611\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 1.5816 Acc: 0.3905\n",
            "val Loss: 1.5848 Acc: 0.3333\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 1.5810 Acc: 0.4142\n",
            "val Loss: 1.5857 Acc: 0.2778\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 1.5801 Acc: 0.4675\n",
            "val Loss: 1.5835 Acc: 0.3333\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 1.5797 Acc: 0.3964\n",
            "val Loss: 1.5842 Acc: 0.3056\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 1.5785 Acc: 0.4320\n",
            "val Loss: 1.5869 Acc: 0.2500\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 1.5783 Acc: 0.4142\n",
            "val Loss: 1.5837 Acc: 0.3472\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 1.5784 Acc: 0.3846\n",
            "val Loss: 1.5834 Acc: 0.4167\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 1.5786 Acc: 0.3846\n",
            "val Loss: 1.5858 Acc: 0.3194\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 1.5788 Acc: 0.3964\n",
            "val Loss: 1.5833 Acc: 0.4028\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 1.5781 Acc: 0.3728\n",
            "val Loss: 1.5835 Acc: 0.4167\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 1.5782 Acc: 0.4320\n",
            "val Loss: 1.5852 Acc: 0.3611\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 1.5787 Acc: 0.3491\n",
            "val Loss: 1.5856 Acc: 0.2917\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 1.5778 Acc: 0.4142\n",
            "val Loss: 1.5847 Acc: 0.3611\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 1.5792 Acc: 0.4083\n",
            "val Loss: 1.5862 Acc: 0.3472\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 1.5783 Acc: 0.3964\n",
            "val Loss: 1.5870 Acc: 0.2500\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 1.5783 Acc: 0.3905\n",
            "val Loss: 1.5854 Acc: 0.3056\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 1.5786 Acc: 0.4024\n",
            "val Loss: 1.5853 Acc: 0.4306\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 1.5774 Acc: 0.4497\n",
            "val Loss: 1.5860 Acc: 0.2917\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 1.5774 Acc: 0.3905\n",
            "val Loss: 1.5838 Acc: 0.4028\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 1.5784 Acc: 0.4497\n",
            "val Loss: 1.5846 Acc: 0.3333\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 1.5780 Acc: 0.4379\n",
            "val Loss: 1.5831 Acc: 0.4028\n",
            "\n",
            "Training complete in 1m 38s\n",
            "Best val Acc: 0.430556\n",
            "Constructing Graph Learning Objects\n",
            "(4856, 1024)\n",
            "Complete\n",
            "Time taken = 111.62012366600175\n",
            "Coreset Size = 18\t Percent of data = 0.37%\n",
            "Coreset =  [2426, 191, 4840, 1295, 1772, 2276, 4236, 734, 1854, 4168, 177, 1407, 3269, 1564, 2659, 494, 2615, 3303]\n",
            "[0 1 2 3 4 0 0 2 2 4 0 2 0 1 0 4 4 2]\n",
            "uc local_max\n",
            "Running half of the iterations takes 8.309569502001978\n",
            "Accuracy for half of the iterations is 76.52965171007217\n",
            "Running all the iterations takes 13.252539315999456\n",
            "Final accuracy is 89.28571428571429\n",
            "89.28571428571429\n",
            "This is experiment 45\n",
            "169\n",
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.6080 Acc: 0.1183\n",
            "val Loss: 1.6020 Acc: 0.2361\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.6076 Acc: 0.1716\n",
            "val Loss: 1.5990 Acc: 0.2361\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.6032 Acc: 0.2071\n",
            "val Loss: 1.5961 Acc: 0.3750\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.6010 Acc: 0.2722\n",
            "val Loss: 1.5913 Acc: 0.4583\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.5963 Acc: 0.3609\n",
            "val Loss: 1.5882 Acc: 0.4167\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.5932 Acc: 0.3787\n",
            "val Loss: 1.5847 Acc: 0.4444\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.5874 Acc: 0.4142\n",
            "val Loss: 1.5838 Acc: 0.4444\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.5834 Acc: 0.4320\n",
            "val Loss: 1.5836 Acc: 0.4306\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 1.5819 Acc: 0.4379\n",
            "val Loss: 1.5822 Acc: 0.4861\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 1.5838 Acc: 0.4320\n",
            "val Loss: 1.5828 Acc: 0.4861\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 1.5831 Acc: 0.4320\n",
            "val Loss: 1.5824 Acc: 0.4306\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 1.5811 Acc: 0.4260\n",
            "val Loss: 1.5822 Acc: 0.4306\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 1.5808 Acc: 0.4320\n",
            "val Loss: 1.5820 Acc: 0.4722\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 1.5806 Acc: 0.4438\n",
            "val Loss: 1.5817 Acc: 0.4444\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 1.5801 Acc: 0.4201\n",
            "val Loss: 1.5796 Acc: 0.4306\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 1.5805 Acc: 0.4260\n",
            "val Loss: 1.5795 Acc: 0.4028\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 1.5808 Acc: 0.4142\n",
            "val Loss: 1.5783 Acc: 0.4444\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 1.5787 Acc: 0.4497\n",
            "val Loss: 1.5788 Acc: 0.4444\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 1.5805 Acc: 0.4260\n",
            "val Loss: 1.5795 Acc: 0.4444\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 1.5800 Acc: 0.4497\n",
            "val Loss: 1.5789 Acc: 0.4722\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 1.5813 Acc: 0.4260\n",
            "val Loss: 1.5794 Acc: 0.4444\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 1.5791 Acc: 0.4142\n",
            "val Loss: 1.5796 Acc: 0.4583\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 1.5794 Acc: 0.4379\n",
            "val Loss: 1.5777 Acc: 0.4444\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 1.5789 Acc: 0.4438\n",
            "val Loss: 1.5793 Acc: 0.4167\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 1.5806 Acc: 0.4320\n",
            "val Loss: 1.5784 Acc: 0.4444\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 1.5790 Acc: 0.4260\n",
            "val Loss: 1.5799 Acc: 0.4306\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 1.5787 Acc: 0.4438\n",
            "val Loss: 1.5805 Acc: 0.3889\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 1.5791 Acc: 0.4615\n",
            "val Loss: 1.5778 Acc: 0.4583\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 1.5803 Acc: 0.4379\n",
            "val Loss: 1.5790 Acc: 0.4444\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 1.5783 Acc: 0.4438\n",
            "val Loss: 1.5783 Acc: 0.4444\n",
            "\n",
            "Training complete in 1m 40s\n",
            "Best val Acc: 0.486111\n",
            "Constructing Graph Learning Objects\n",
            "(4856, 1024)\n",
            "Complete\n",
            "Time taken = 113.16064221899796\n",
            "Coreset Size = 18\t Percent of data = 0.37%\n",
            "Coreset =  [924, 4806, 3218, 4161, 117, 2334, 3917, 4442, 326, 220, 3266, 2810, 2284, 888, 2857, 3808, 4356, 2382]\n",
            "[0 1 2 3 4 0 0 4 0 2 0 0 0 2 2 0 4 0]\n",
            "uc local_max\n",
            "Running half of the iterations takes 8.218447944000218\n",
            "Accuracy for half of the iterations is 75.55695010982114\n",
            "Running all the iterations takes 13.380644503999065\n",
            "Final accuracy is 88.44866071428571\n",
            "88.44866071428571\n",
            "This is experiment 46\n",
            "169\n",
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.6247 Acc: 0.0473\n",
            "val Loss: 1.6229 Acc: 0.0000\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.6241 Acc: 0.0355\n",
            "val Loss: 1.6206 Acc: 0.0000\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.6220 Acc: 0.0355\n",
            "val Loss: 1.6163 Acc: 0.0417\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.6192 Acc: 0.0473\n",
            "val Loss: 1.6133 Acc: 0.0556\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.6149 Acc: 0.0651\n",
            "val Loss: 1.6085 Acc: 0.1528\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.6093 Acc: 0.2012\n",
            "val Loss: 1.6022 Acc: 0.2917\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.6050 Acc: 0.3195\n",
            "val Loss: 1.6014 Acc: 0.3194\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.6002 Acc: 0.4320\n",
            "val Loss: 1.5982 Acc: 0.3889\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 1.5994 Acc: 0.4260\n",
            "val Loss: 1.5969 Acc: 0.3333\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 1.5994 Acc: 0.4556\n",
            "val Loss: 1.5979 Acc: 0.3194\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 1.6001 Acc: 0.4556\n",
            "val Loss: 1.5984 Acc: 0.3056\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 1.5992 Acc: 0.4320\n",
            "val Loss: 1.5968 Acc: 0.3611\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 1.5984 Acc: 0.4438\n",
            "val Loss: 1.5985 Acc: 0.3889\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 1.5968 Acc: 0.4497\n",
            "val Loss: 1.5964 Acc: 0.3333\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 1.5961 Acc: 0.4734\n",
            "val Loss: 1.5965 Acc: 0.3333\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 1.5967 Acc: 0.4793\n",
            "val Loss: 1.5960 Acc: 0.4167\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 1.5976 Acc: 0.4201\n",
            "val Loss: 1.5959 Acc: 0.4167\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 1.5965 Acc: 0.4675\n",
            "val Loss: 1.5971 Acc: 0.3611\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 1.5964 Acc: 0.4734\n",
            "val Loss: 1.5985 Acc: 0.3472\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 1.5953 Acc: 0.4675\n",
            "val Loss: 1.5995 Acc: 0.3333\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 1.5974 Acc: 0.4497\n",
            "val Loss: 1.5988 Acc: 0.3333\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 1.5956 Acc: 0.4556\n",
            "val Loss: 1.5950 Acc: 0.3472\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 1.5961 Acc: 0.4201\n",
            "val Loss: 1.5974 Acc: 0.3611\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 1.5968 Acc: 0.4675\n",
            "val Loss: 1.5993 Acc: 0.3333\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 1.5972 Acc: 0.4497\n",
            "val Loss: 1.5988 Acc: 0.3611\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 1.5972 Acc: 0.4556\n",
            "val Loss: 1.5986 Acc: 0.3472\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 1.5961 Acc: 0.4675\n",
            "val Loss: 1.5989 Acc: 0.3472\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 1.5968 Acc: 0.4675\n",
            "val Loss: 1.5976 Acc: 0.3472\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 1.5956 Acc: 0.4615\n",
            "val Loss: 1.5981 Acc: 0.3472\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 1.5960 Acc: 0.4675\n",
            "val Loss: 1.5982 Acc: 0.3472\n",
            "\n",
            "Training complete in 1m 40s\n",
            "Best val Acc: 0.416667\n",
            "Constructing Graph Learning Objects\n",
            "(4856, 1024)\n",
            "Complete\n",
            "Time taken = 113.39934446999905\n",
            "Coreset Size = 17\t Percent of data = 0.35%\n",
            "Coreset =  [924, 4806, 3218, 4161, 117, 1791, 1628, 2716, 1909, 94, 3184, 4640, 4512, 2752, 1151, 3933, 3692]\n",
            "[0 1 2 3 4 0 3 0 4 0 3 4 4 3 0 3 0]\n",
            "uc local_max\n",
            "Running half of the iterations takes 8.570408812000096\n",
            "Accuracy for half of the iterations is 75.65872020075282\n",
            "Running all the iterations takes 13.689074662001076\n",
            "Final accuracy is 90.01673173452315\n",
            "90.01673173452315\n",
            "This is experiment 47\n",
            "169\n",
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.6145 Acc: 0.0888\n",
            "val Loss: 1.6159 Acc: 0.0556\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.6139 Acc: 0.0888\n",
            "val Loss: 1.6151 Acc: 0.0417\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.6111 Acc: 0.1479\n",
            "val Loss: 1.6131 Acc: 0.0417\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.6081 Acc: 0.2012\n",
            "val Loss: 1.6084 Acc: 0.1944\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.6047 Acc: 0.2604\n",
            "val Loss: 1.6048 Acc: 0.2639\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.6017 Acc: 0.3550\n",
            "val Loss: 1.5999 Acc: 0.4444\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.5968 Acc: 0.3728\n",
            "val Loss: 1.5975 Acc: 0.4306\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.5933 Acc: 0.4675\n",
            "val Loss: 1.5968 Acc: 0.4722\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 1.5914 Acc: 0.4615\n",
            "val Loss: 1.5968 Acc: 0.4167\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 1.5922 Acc: 0.4497\n",
            "val Loss: 1.5959 Acc: 0.4861\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 1.5916 Acc: 0.4615\n",
            "val Loss: 1.5945 Acc: 0.4861\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 1.5913 Acc: 0.4260\n",
            "val Loss: 1.5937 Acc: 0.4722\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 1.5913 Acc: 0.4260\n",
            "val Loss: 1.5914 Acc: 0.5278\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 1.5913 Acc: 0.4142\n",
            "val Loss: 1.5917 Acc: 0.4583\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 1.5900 Acc: 0.4320\n",
            "val Loss: 1.5903 Acc: 0.4722\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 1.5898 Acc: 0.4556\n",
            "val Loss: 1.5931 Acc: 0.4861\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 1.5902 Acc: 0.4320\n",
            "val Loss: 1.5927 Acc: 0.4444\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 1.5893 Acc: 0.4260\n",
            "val Loss: 1.5914 Acc: 0.4583\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 1.5886 Acc: 0.4260\n",
            "val Loss: 1.5923 Acc: 0.4861\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 1.5898 Acc: 0.3964\n",
            "val Loss: 1.5910 Acc: 0.4167\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 1.5895 Acc: 0.4438\n",
            "val Loss: 1.5908 Acc: 0.4444\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 1.5899 Acc: 0.4320\n",
            "val Loss: 1.5938 Acc: 0.4306\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 1.5889 Acc: 0.4497\n",
            "val Loss: 1.5933 Acc: 0.4306\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 1.5886 Acc: 0.4260\n",
            "val Loss: 1.5902 Acc: 0.4861\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 1.5903 Acc: 0.4083\n",
            "val Loss: 1.5920 Acc: 0.4861\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 1.5906 Acc: 0.4024\n",
            "val Loss: 1.5922 Acc: 0.4722\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 1.5892 Acc: 0.4675\n",
            "val Loss: 1.5904 Acc: 0.4861\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 1.5898 Acc: 0.4142\n",
            "val Loss: 1.5911 Acc: 0.4306\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 1.5908 Acc: 0.4024\n",
            "val Loss: 1.5922 Acc: 0.4861\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 1.5899 Acc: 0.4675\n",
            "val Loss: 1.5901 Acc: 0.4722\n",
            "\n",
            "Training complete in 1m 40s\n",
            "Best val Acc: 0.527778\n",
            "Constructing Graph Learning Objects\n",
            "(4856, 1024)\n",
            "Complete\n",
            "Time taken = 114.20370986600028\n",
            "Coreset Size = 16\t Percent of data = 0.33%\n",
            "Coreset =  [4705, 3030, 4242, 234, 1249, 793, 3698, 1787, 1996, 4184, 609, 3381, 4089, 145, 2817, 4027]\n",
            "[0 1 2 3 4 2 4 4 4 0 0 2 0 4 0 3]\n",
            "uc local_max\n",
            "Running half of the iterations takes 8.330279759000405\n",
            "Accuracy for half of the iterations is 77.01473816243336\n",
            "Running all the iterations takes 13.508257123001385\n",
            "Final accuracy is 89.57636566332218\n",
            "89.57636566332218\n",
            "This is experiment 48\n",
            "169\n",
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.6217 Acc: 0.3136\n",
            "val Loss: 1.6187 Acc: 0.2361\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.6196 Acc: 0.2959\n",
            "val Loss: 1.6175 Acc: 0.2778\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.6161 Acc: 0.3254\n",
            "val Loss: 1.6152 Acc: 0.2917\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.6109 Acc: 0.3373\n",
            "val Loss: 1.6134 Acc: 0.3194\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.6079 Acc: 0.3432\n",
            "val Loss: 1.6087 Acc: 0.3194\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.6019 Acc: 0.3432\n",
            "val Loss: 1.6053 Acc: 0.3194\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.5978 Acc: 0.3491\n",
            "val Loss: 1.5995 Acc: 0.3194\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.5946 Acc: 0.3491\n",
            "val Loss: 1.5985 Acc: 0.3194\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 1.5923 Acc: 0.3491\n",
            "val Loss: 1.5989 Acc: 0.3194\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 1.5931 Acc: 0.3491\n",
            "val Loss: 1.5959 Acc: 0.3194\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 1.5918 Acc: 0.3491\n",
            "val Loss: 1.5964 Acc: 0.3194\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 1.5913 Acc: 0.3550\n",
            "val Loss: 1.5947 Acc: 0.3194\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 1.5893 Acc: 0.3491\n",
            "val Loss: 1.5947 Acc: 0.3194\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 1.5907 Acc: 0.3491\n",
            "val Loss: 1.5941 Acc: 0.3194\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 1.5885 Acc: 0.3491\n",
            "val Loss: 1.5944 Acc: 0.3194\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 1.5887 Acc: 0.3491\n",
            "val Loss: 1.5944 Acc: 0.3194\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 1.5912 Acc: 0.3491\n",
            "val Loss: 1.5941 Acc: 0.3194\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 1.5893 Acc: 0.3491\n",
            "val Loss: 1.5922 Acc: 0.3194\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 1.5897 Acc: 0.3491\n",
            "val Loss: 1.5934 Acc: 0.3194\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 1.5888 Acc: 0.3491\n",
            "val Loss: 1.5929 Acc: 0.3194\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 1.5875 Acc: 0.3491\n",
            "val Loss: 1.5923 Acc: 0.3194\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 1.5887 Acc: 0.3491\n",
            "val Loss: 1.5931 Acc: 0.3194\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 1.5891 Acc: 0.3491\n",
            "val Loss: 1.5931 Acc: 0.3194\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 1.5900 Acc: 0.3491\n",
            "val Loss: 1.5912 Acc: 0.3194\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 1.5880 Acc: 0.3491\n",
            "val Loss: 1.5928 Acc: 0.3194\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 1.5905 Acc: 0.3491\n",
            "val Loss: 1.5920 Acc: 0.3194\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 1.5900 Acc: 0.3491\n",
            "val Loss: 1.5933 Acc: 0.3194\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 1.5897 Acc: 0.3491\n",
            "val Loss: 1.5920 Acc: 0.3194\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 1.5889 Acc: 0.3491\n",
            "val Loss: 1.5921 Acc: 0.3194\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 1.5904 Acc: 0.3491\n",
            "val Loss: 1.5928 Acc: 0.3194\n",
            "\n",
            "Training complete in 1m 43s\n",
            "Best val Acc: 0.319444\n",
            "Constructing Graph Learning Objects\n",
            "(4856, 1024)\n",
            "Complete\n",
            "Time taken = 116.98179179400177\n",
            "Coreset Size = 19\t Percent of data = 0.39%\n",
            "Coreset =  [3504, 2329, 937, 4692, 3066, 4366, 2788, 931, 3826, 1096, 1531, 3517, 3638, 4019, 4428, 1883, 37, 3114, 3549]\n",
            "[0 1 2 3 4 4 1 0 4 2 3 4 0 4 2 0 0 0 2]\n",
            "uc local_max\n",
            "Running half of the iterations takes 9.022283620000962\n",
            "Accuracy for half of the iterations is 75.23540489642184\n",
            "Running all the iterations takes 14.539454777001083\n",
            "Final accuracy is 88.38637632607482\n",
            "88.38637632607482\n",
            "This is experiment 49\n",
            "169\n",
            "72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 1.6124 Acc: 0.1775\n",
            "val Loss: 1.6133 Acc: 0.2917\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 1.6094 Acc: 0.2249\n",
            "val Loss: 1.6067 Acc: 0.3472\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 1.6089 Acc: 0.2604\n",
            "val Loss: 1.6065 Acc: 0.3472\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 1.6057 Acc: 0.3018\n",
            "val Loss: 1.6026 Acc: 0.3472\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 1.6010 Acc: 0.2959\n",
            "val Loss: 1.5954 Acc: 0.3611\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 1.5963 Acc: 0.3373\n",
            "val Loss: 1.5923 Acc: 0.3333\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 1.5920 Acc: 0.3432\n",
            "val Loss: 1.5867 Acc: 0.4167\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 1.5883 Acc: 0.3491\n",
            "val Loss: 1.5869 Acc: 0.4167\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 1.5884 Acc: 0.3787\n",
            "val Loss: 1.5859 Acc: 0.4861\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 1.5880 Acc: 0.3550\n",
            "val Loss: 1.5867 Acc: 0.4444\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 1.5879 Acc: 0.3609\n",
            "val Loss: 1.5856 Acc: 0.4444\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 1.5869 Acc: 0.3728\n",
            "val Loss: 1.5851 Acc: 0.4583\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 1.5850 Acc: 0.3550\n",
            "val Loss: 1.5858 Acc: 0.3889\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 1.5852 Acc: 0.3728\n",
            "val Loss: 1.5848 Acc: 0.3889\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 1.5853 Acc: 0.3846\n",
            "val Loss: 1.5861 Acc: 0.4028\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 1.5847 Acc: 0.3846\n",
            "val Loss: 1.5825 Acc: 0.4028\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 1.5841 Acc: 0.4260\n",
            "val Loss: 1.5850 Acc: 0.3889\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 1.5860 Acc: 0.3669\n",
            "val Loss: 1.5849 Acc: 0.3333\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 1.5860 Acc: 0.3491\n",
            "val Loss: 1.5848 Acc: 0.3750\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 1.5850 Acc: 0.3669\n",
            "val Loss: 1.5844 Acc: 0.3750\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 1.5848 Acc: 0.3609\n",
            "val Loss: 1.5842 Acc: 0.3750\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 1.5848 Acc: 0.3669\n",
            "val Loss: 1.5836 Acc: 0.3889\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 1.5846 Acc: 0.3609\n",
            "val Loss: 1.5819 Acc: 0.3333\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 1.5855 Acc: 0.3609\n",
            "val Loss: 1.5842 Acc: 0.3611\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 1.5846 Acc: 0.3964\n",
            "val Loss: 1.5853 Acc: 0.3472\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 1.5854 Acc: 0.3669\n",
            "val Loss: 1.5840 Acc: 0.3611\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 1.5844 Acc: 0.3432\n",
            "val Loss: 1.5826 Acc: 0.3889\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 1.5846 Acc: 0.4024\n",
            "val Loss: 1.5845 Acc: 0.4028\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 1.5852 Acc: 0.3669\n",
            "val Loss: 1.5845 Acc: 0.3472\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 1.5849 Acc: 0.3728\n",
            "val Loss: 1.5814 Acc: 0.4306\n",
            "\n",
            "Training complete in 1m 40s\n",
            "Best val Acc: 0.486111\n",
            "Constructing Graph Learning Objects\n",
            "(4856, 1024)\n",
            "Complete\n",
            "Time taken = 113.82534217400098\n",
            "Coreset Size = 18\t Percent of data = 0.37%\n",
            "Coreset =  [1312, 2707, 395, 4846, 1126, 660, 3794, 4444, 4547, 4623, 4248, 982, 41, 4111, 579, 547, 3906, 2731]\n",
            "[0 1 2 3 4 3 0 3 0 0 0 4 0 4 2 4 4 4]\n",
            "uc local_max\n",
            "Running half of the iterations takes 8.322981378001714\n",
            "Accuracy for half of the iterations is 75.83934734860371\n",
            "Running all the iterations takes 13.449226068001735\n",
            "Final accuracy is 88.50446428571429\n",
            "88.50446428571429\n",
            "[88.38637632607482, 86.42458100558659, 89.18014500836587, 90.1840490797546, 88.65287870318613, 87.60469011725293, 90.35136642498605, 87.9041248606466, 90.73143495254048, 88.95705521472392, 88.29431438127091, 89.50892857142857, 88.38637632607482, 90.41248606465997, 90.45226130653266, 89.52062430323299, 89.95535714285714, 90.01673173452315, 89.57055214723927, 88.85172798216277, 89.453125, 89.43543879262158, 89.4032348020078, 89.78224455611391, 90.29559397657557, 87.78583379810374, 89.94413407821229, 87.66052484645449, 90.01116071428571, 89.35340022296543, 88.21887213847013, 89.10005589714925, 88.96321070234114, 90.08356545961003, 89.15595304639463, 89.96095928611265, 88.62242052426102, 90.23982152816508, 89.56473214285714, 88.82057015092231, 90.41248606465997, 89.74358974358974, 89.4590072504183, 89.55307262569832, 89.28571428571429, 88.44866071428571, 90.01673173452315, 89.57636566332218, 88.38637632607482, 88.50446428571429]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "OpenSARShip Results with Transformation"
      ],
      "metadata": {
        "id": "_FB5BnHLxfFa"
      },
      "id": "_FB5BnHLxfFa"
    },
    {
      "cell_type": "code",
      "source": [
        "print(final_acc_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHR-hTskwXc4",
        "outputId": "be336418-2b07-4d8d-8a74-94bd82fef2ed"
      },
      "id": "gHR-hTskwXc4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[82.05771643663739, 79.41176470588235, 81.36335209505941, 80.86574654956085, 80.26315789473684, 77.5062656641604, 80.3125, 80.05018820577165, 78.38345864661655, 80.0125313283208, 71.61654135338345, 79.24764890282131, 80.75235109717869, 79.73651191969887, 76.9712140175219, 81.14035087719299, 76.77338355304457, 71.5090795241077, 80.51378446115288, 79.64824120603015, 81.08954289292423, 81.34422110552764, 80.42659974905897, 78.87147335423198, 73.6842105263158, 58.203368683718026, 79.56112852664577, 77.69423558897243, 77.14464621164684, 81.21477770820287, 74.1692789968652, 79.43573667711598, 80.0125313283208, 78.50408548082967, 74.70256731371322, 81.15216030056355, 81.0625, 75.9119496855346, 82.1831869510665, 80.32581453634086, 79.76190476190476, 80.55207026348808, 76.41154328732748, 79.89981214777708, 78.98368883312422, 79.4486215538847, 79.96231155778895, 78.5982478097622, 80.0, 79.57393483709274]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(max(final_acc_list))\n",
        "print(np.mean(final_acc_list))\n",
        "print(np.std(final_acc_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-rc1LPrw1MG",
        "outputId": "74af75e2-1d3b-4ec0-8b64-022f3159bda2"
      },
      "id": "t-rc1LPrw1MG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "82.1831869510665\n",
            "78.56043878217248\n",
            "3.7878383432666864\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fusar Resuls with Transformation"
      ],
      "metadata": {
        "id": "hiFdmEsfxkNt"
      },
      "id": "hiFdmEsfxkNt"
    },
    {
      "cell_type": "code",
      "source": [
        "print(final_acc_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FtBHh5mxj_R",
        "outputId": "86bfe896-6cff-482e-df86-6d61e3fa691c"
      },
      "id": "_FtBHh5mxj_R",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[93.5340022296544, 95.37088678192973, 82.64508928571429, 93.69771332961517, 85.39576365663322, 91.80145008365868, 86.94924707194646, 92.80133928571429, 92.98050139275766, 92.45810055865921, 93.26280623608018, 91.02063580591188, 88.6908077994429, 94.03234802007808, 90.39106145251397, 93.03232998885173, 91.40625, 85.51532033426184, 66.62958843159066, 94.46927374301676, 92.07589285714286, 81.91430161380077, 91.63413273842721, 91.56895589056393, 91.03064066852367, 89.79933110367892, 91.28004471771939, 89.64941569282136, 90.01673173452315, 94.15041782729806, 92.37193763919822, 90.85841694537346, 90.06696428571429, 91.97324414715719, 90.46822742474916, 92.68973214285714, 89.63210702341136, 92.92479108635098, 94.30803571428571, 94.31438127090301, 85.57103064066852, 88.85172798216277, 85.85746102449889, 91.796875, 87.52783964365256, 92.58226436140546, 94.08151870463428, 93.0400890868597, 90.42316258351893, 83.93753485778025]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(max(final_acc_list))\n",
        "print(np.mean(final_acc_list))\n",
        "print(np.std(final_acc_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsTk1zvaQLi_",
        "outputId": "6aab41c8-a075-42f1-b5ba-c36959dcf435"
      },
      "id": "CsTk1zvaQLi_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "95.37088678192973\n",
            "90.24963443795427\n",
            "4.61559637693679\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "OpenSARShip Results without Transformation"
      ],
      "metadata": {
        "id": "vDt4KYtvgj4I"
      },
      "id": "vDt4KYtvgj4I"
    },
    {
      "cell_type": "code",
      "source": [
        "print(final_acc_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KD4UnyNugnq4",
        "outputId": "ca85fcf1-0be1-4e38-cba4-3da07ff27d80"
      },
      "id": "KD4UnyNugnq4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[78.54454203262233, 78.62068965517241, 79.40991839296925, 79.58412098298676, 78.37837837837837, 79.91211550533585, 78.80503144654088, 78.7515762925599, 78.55345911949685, 78.39195979899498, 78.59384808537351, 78.79548306148055, 79.00691389063482, 79.14812460267005, 78.83165829145729, 78.46829880728185, 79.19547454431175, 78.93081761006289, 78.71939736346516, 79.29736511919698, 79.5483061480552, 78.58040201005025, 78.9572864321608, 79.63544940289127, 80.34134007585335, 78.06411062225015, 79.71105527638191, 79.43396226415095, 78.64321608040201, 79.23462986198244, 79.44688874921432, 78.26633165829146, 79.00691389063482, 78.67924528301887, 79.02010050251256, 79.08291457286433, 79.33417085427136, 77.97356828193833, 77.78477029578352, 78.45477386934674, 78.8546255506608, 78.74213836477988, 78.51758793969849, 78.732747804266, 79.14572864321607, 78.45477386934674, 78.56693903205532, 78.79548306148055, 79.14303717706365, 78.71939736346516]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(max(final_acc_list))\n",
        "print(np.mean(final_acc_list))\n",
        "print(np.std(final_acc_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhEq3rQjgpCK",
        "outputId": "d48ea51c-4133-491a-b70a-1707b578e621"
      },
      "id": "HhEq3rQjgpCK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80.34134007585335\n",
            "78.8962213583816\n",
            "0.4943527425054134\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fusar Results without Transformation"
      ],
      "metadata": {
        "id": "UpKkdGRe9po1"
      },
      "id": "UpKkdGRe9po1"
    },
    {
      "cell_type": "code",
      "source": [
        "print(final_acc_list)"
      ],
      "metadata": {
        "id": "tFuSZ3cN9txs",
        "outputId": "aa7ae169-7092-4049-8262-1073dbb2e085",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "tFuSZ3cN9txs",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[88.38637632607482, 86.42458100558659, 89.18014500836587, 90.1840490797546, 88.65287870318613, 87.60469011725293, 90.35136642498605, 87.9041248606466, 90.73143495254048, 88.95705521472392, 88.29431438127091, 89.50892857142857, 88.38637632607482, 90.41248606465997, 90.45226130653266, 89.52062430323299, 89.95535714285714, 90.01673173452315, 89.57055214723927, 88.85172798216277, 89.453125, 89.43543879262158, 89.4032348020078, 89.78224455611391, 90.29559397657557, 87.78583379810374, 89.94413407821229, 87.66052484645449, 90.01116071428571, 89.35340022296543, 88.21887213847013, 89.10005589714925, 88.96321070234114, 90.08356545961003, 89.15595304639463, 89.96095928611265, 88.62242052426102, 90.23982152816508, 89.56473214285714, 88.82057015092231, 90.41248606465997, 89.74358974358974, 89.4590072504183, 89.55307262569832, 89.28571428571429, 88.44866071428571, 90.01673173452315, 89.57636566332218, 88.38637632607482, 88.50446428571429]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(max(final_acc_list))\n",
        "print(np.mean(final_acc_list))\n",
        "print(np.std(final_acc_list))"
      ],
      "metadata": {
        "id": "OjhGKMG29vnZ",
        "outputId": "36326544-3e72-415a-88b8-7daa4975ebfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "OjhGKMG29vnZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90.73143495254048\n",
            "89.25174764021453\n",
            "0.8892634560634238\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "collapsed_sections": [
        "J5zkzrxiw_bS",
        "FEPyIbxlxB19"
      ]
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}