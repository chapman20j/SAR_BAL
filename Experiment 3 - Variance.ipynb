{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "613f1e2a",
   "metadata": {},
   "source": [
    "# Experiment 3: Variance\n",
    "This notebook tests the impact of data augmentation and fine tuning on the final results. We notice that data augmentation and fine tuning inject noise into the process. \n",
    "\n",
    "Tests:\n",
    "- Zero-shot Transfer Learning\n",
    "- Fine tuned Transfer Learning without data augmentation\n",
    "- Fine Tuned Transfer Learning with data augmentation\n",
    "\n",
    "Datasets:\n",
    "- OpenSARShip\n",
    "- FUSAR-Ship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9444edf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stuff for google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "171419dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import utils\n",
    "from experiments import experiment_3, EXPERIMENT_3_SAVE_PATH, EXPERIMENT_3_NUM_EXPERIMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27220391",
   "metadata": {},
   "source": [
    "## Parameters and Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ca02ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Default Parameters\n",
    "\n",
    "#(data augmentation, embedding)\n",
    "test_list = [(False, 'zero_shot_tl'), (False, 'fine_tuned_tl'), (True, 'fine_tuned_tl')]\n",
    "\n",
    "HARDWARE_ACCELERATION = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729f46ab",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "This is running 8 experiments each num_experiments times. This comes out to 400 runs for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59d81240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False_open_sar_ship_zero_shot_tl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/jameschapman/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Using cache found in /Users/jameschapman/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m key \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(data_augmentation) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m dataset \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m embedding\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(key)\n\u001b[0;32m----> 7\u001b[0m experiment_result \u001b[39m=\u001b[39m experiment_3(\n\u001b[1;32m      8\u001b[0m     dataset,\n\u001b[1;32m      9\u001b[0m     embedding,\n\u001b[1;32m     10\u001b[0m     data_augmentation,\n\u001b[1;32m     11\u001b[0m     hardware_acceleration\u001b[39m=\u001b[39;49mHARDWARE_ACCELERATION,\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     13\u001b[0m all_results[key] \u001b[39m=\u001b[39m experiment_result\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m     14\u001b[0m \u001b[39mprint\u001b[39m(experiment_result)\n",
      "File \u001b[0;32m~/Documents/GitHub/SAR_BAL/experiments.py:255\u001b[0m, in \u001b[0;36mexperiment_3\u001b[0;34m(dataset, embedding, data_augmentation, num_experiments, hardware_acceleration)\u001b[0m\n\u001b[1;32m    251\u001b[0m     X, labels, knn_data, initial \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mcnnvae(\n\u001b[1;32m    252\u001b[0m         dataset, hardware_acceleration\u001b[39m=\u001b[39mhardware_acceleration\n\u001b[1;32m    253\u001b[0m     )\n\u001b[1;32m    254\u001b[0m \u001b[39melif\u001b[39;00m embedding \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mzero_shot_tl\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 255\u001b[0m     X, labels, knn_data, initial \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39;49mzero_shot_tl(\n\u001b[1;32m    256\u001b[0m         dataset,\n\u001b[1;32m    257\u001b[0m         hardware_acceleration\u001b[39m=\u001b[39;49mhardware_acceleration,\n\u001b[1;32m    258\u001b[0m     )\n\u001b[1;32m    259\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    260\u001b[0m     X, labels, knn_data, initial \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mfine_tuned_tl(\n\u001b[1;32m    261\u001b[0m         dataset,\n\u001b[1;32m    262\u001b[0m         data_augmentation\u001b[39m=\u001b[39mdata_augmentation,\n\u001b[1;32m    263\u001b[0m         hardware_acceleration\u001b[39m=\u001b[39mhardware_acceleration,\n\u001b[1;32m    264\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/GitHub/SAR_BAL/utils.py:178\u001b[0m, in \u001b[0;36mzero_shot_tl\u001b[0;34m(dataset, knn_num, hardware_acceleration)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(labels, torch\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m    176\u001b[0m     labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m--> 178\u001b[0m knn_data \u001b[39m=\u001b[39m gl\u001b[39m.\u001b[39;49mweightmatrix\u001b[39m.\u001b[39;49mknnsearch(\n\u001b[1;32m    179\u001b[0m     data, knn_num, method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mannoy\u001b[39;49m\u001b[39m\"\u001b[39;49m, similarity\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mangular\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m    180\u001b[0m )\n\u001b[1;32m    182\u001b[0m train_ind \u001b[39m=\u001b[39m gl\u001b[39m.\u001b[39mtrainsets\u001b[39m.\u001b[39mgenerate(labels, rate\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    184\u001b[0m \u001b[39mreturn\u001b[39;00m data, labels, knn_data, train_ind\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/graphlearning/weightmatrix.py:289\u001b[0m, in \u001b[0;36mknnsearch\u001b[0;34m(X, k, method, similarity, dataset, metric)\u001b[0m\n\u001b[1;32m    287\u001b[0m knn_ind \u001b[39m=\u001b[39m []\n\u001b[1;32m    288\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n):\n\u001b[0;32m--> 289\u001b[0m     A \u001b[39m=\u001b[39m u\u001b[39m.\u001b[39;49mget_nns_by_item(i, k, include_distances\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, search_k\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m    290\u001b[0m     knn_ind\u001b[39m.\u001b[39mappend(A[\u001b[39m0\u001b[39m])\n\u001b[1;32m    291\u001b[0m     knn_dist\u001b[39m.\u001b[39mappend(A[\u001b[39m1\u001b[39m])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_results = {}\n",
    "\n",
    "for (data_augmentation, embedding) in test_list:\n",
    "    for dataset in utils.AVAILABLE_SAR_DATASETS[1:]:\n",
    "        key = str(data_augmentation) + \"_\" + dataset + \"_\" + embedding\n",
    "        print(key)\n",
    "        experiment_result = experiment_3(\n",
    "            dataset,\n",
    "            embedding,\n",
    "            data_augmentation,\n",
    "            hardware_acceleration=HARDWARE_ACCELERATION,\n",
    "        )\n",
    "        all_results[key] = experiment_result.copy()\n",
    "        print(experiment_result)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56ccd50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'False_open_sar_ship_zero_shot_tl': {'num_points': 772,\n",
       "  'experiments': 1,\n",
       "  'mean': 80.97112860892389,\n",
       "  'std_dev': 0.0},\n",
       " 'False_fusar_zero_shot_tl': {'num_points': 3127,\n",
       "  'experiments': 1,\n",
       "  'mean': 87.56506651243494,\n",
       "  'std_dev': 0.0},\n",
       " 'False_open_sar_ship_fine_tuned_tl': {'num_points': 776,\n",
       "  'experiments': 1,\n",
       "  'mean': 79.73684210526316,\n",
       "  'std_dev': 0.0},\n",
       " 'False_fusar_fine_tuned_tl': {'num_points': 3151,\n",
       "  'experiments': 1,\n",
       "  'mean': 86.56891495601172,\n",
       "  'std_dev': 0.0},\n",
       " 'True_open_sar_ship_fine_tuned_tl': {'num_points': 757,\n",
       "  'experiments': 1,\n",
       "  'mean': 79.53216374269006,\n",
       "  'std_dev': 0.0},\n",
       " 'True_fusar_fine_tuned_tl': {'num_points': 3141,\n",
       "  'experiments': 1,\n",
       "  'mean': 86.29737609329446,\n",
       "  'std_dev': 0.0}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d50b9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_save_path = EXPERIMENT_3_SAVE_PATH + 'all_results_' + str(EXPERIMENT_3_NUM_EXPERIMENTS) \n",
    "\n",
    "df = pd.DataFrame.from_dict(all_results, orient='index')\n",
    "df.to_pickle(new_save_path + '.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
