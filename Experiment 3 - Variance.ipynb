{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "613f1e2a",
   "metadata": {},
   "source": [
    "# Experiment 3: Variance\n",
    "\n",
    "# TODO: \n",
    "1. Code this\n",
    "2. Make it so we can optionally use data augmentation in the functions at the bottom of utils.py. I added it to the signature, but this is not yet implemented. \n",
    "3. Other than the stuff in BAL, this should be good for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9444edf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stuff for google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "171419dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as th\n",
    "import pandas as pd\n",
    "\n",
    "import graphlearning as gl\n",
    "\n",
    "import batch_active_learning as bal\n",
    "import utils\n",
    "\n",
    "#TODO: CHECK THE PARAMETERS IN bal.coreset_run_experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27220391",
   "metadata": {},
   "source": [
    "## Parameters and Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ca02ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Default Parameters\n",
    "\n",
    "num_experiments = 2\n",
    "num_epochs=1\n",
    "\n",
    "save_path = \"Experiment Results/Experiment 3/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d7930b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment3(dataset, embedding, data_augmentation, num_experiments=num_experiments):\n",
    "    assert dataset in utils.AVAILABLE_SAR_DATASETS, \"Invalid dataset\"\n",
    "    assert dataset != \"mstar\", \"Invalid dataset: not testing MSTAR\"\n",
    "    assert embedding in utils.AVAILABLE_EMBEDDINGS, \"Invalid embedding\"\n",
    "\n",
    "    if embedding == \"fine_tuned_tl\":\n",
    "        max_new_samples = bal.FINE_TUNED_MAX_NEW_SAMPLES_DICT[dataset]\n",
    "    else:\n",
    "        max_new_samples = bal.MAX_NEW_SAMPLES_DICT[dataset]\n",
    "\n",
    "    acc_results = np.zeros(num_experiments)\n",
    "\n",
    "    for i in range(num_experiments):\n",
    "        # Do inside each experiment because we want to understand the impact of this kind of noise\n",
    "        # Perform embedding\n",
    "        if embedding == \"cnnvae\":\n",
    "            X, labels, knn_data = utils.CNNVAE(dataset)\n",
    "        elif embedding == \"zero_shot_tl\":\n",
    "            X, labels, knn_data = utils.zero_shot_TL(\n",
    "                dataset, data_augmentation=data_augmentation\n",
    "            )\n",
    "        else:\n",
    "            X, labels, knn_data = utils.fine_tuned_TL(\n",
    "                dataset, data_augmentation=data_augmentation, num_epochs=num_epochs\n",
    "            )\n",
    "\n",
    "        if isinstance(X, th.Tensor):\n",
    "            X = X.numpy()\n",
    "        if isinstance(labels, th.Tensor):\n",
    "            labels = labels.numpy()\n",
    "\n",
    "        # Create graph objects\n",
    "        try:\n",
    "            W = gl.weightmatrix.knn(\n",
    "                X, utils.KNN_NUM, kernel=\"gaussian\", knn_data=knn_data\n",
    "            )\n",
    "        except FileNotFoundError:\n",
    "            return knn_data\n",
    "        G = gl.graph(W)\n",
    "\n",
    "        num_iter = max_new_samples // bal.BATCH_SIZE\n",
    "\n",
    "        # Ensure each label is represented in core set\n",
    "        initial = gl.trainsets.generate(labels, rate=1).tolist()\n",
    "\n",
    "        coreset = bal.coreset_dijkstras(\n",
    "            G,\n",
    "            rad=bal.DENSITY_RADIUS,\n",
    "            data=X,\n",
    "            initial=initial,\n",
    "            density_info=(True, bal.DENSITY_RADIUS, 1),\n",
    "            knn_data=knn_data,\n",
    "        )\n",
    "\n",
    "        _, num_labels, acc_vals, _ = bal.coreset_run_experiment(\n",
    "            X,\n",
    "            labels,\n",
    "            W,\n",
    "            coreset,\n",
    "            num_iter=num_iter,\n",
    "            method=\"Laplace\",\n",
    "            display=False,\n",
    "            use_prior=False,\n",
    "            al_mtd=\"local_max\",\n",
    "            acq_fun=\"uc\",\n",
    "            knn_data=knn_data,\n",
    "            mtd_para=None,\n",
    "            savefig=False,\n",
    "            batchsize=bal.BATCH_SIZE,\n",
    "            dist_metric=\"angular\",\n",
    "            knn_size=utils.KNN_NUM,\n",
    "            q=1,\n",
    "            thresholding=0,\n",
    "        )\n",
    "\n",
    "        acc_results[i] = acc_vals[-1]\n",
    "    end_labels = num_labels[-1]\n",
    "\n",
    "    return {\n",
    "        \"num_points\": end_labels,\n",
    "        \"experiments\": num_experiments,\n",
    "        \"mean\": np.mean(acc_results),\n",
    "        \"std_dev\": np.std(acc_results),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729f46ab",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "This is running 8 experiments each num_experiments times. This comes out to 400 runs for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d81240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True_open_sar_ship_zero_shot_tl\n",
      "torch.Size([2296, 1, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/jameschapman/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2296, 1, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/jameschapman/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_points': 748, 'experiments': 2, 'mean': 76.43847002090226, 'std_dev': 1.597705689692063}\n",
      "\n",
      "True_open_sar_ship_fine_tuned_tl\n",
      "Epoch 1/1\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jameschapman/Documents/GitHub/SAR_BAL/utils.py:328: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs = nn.functional.log_softmax(outputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.2121 Acc: 0.1686\n",
      "val Loss: 1.0495 Acc: 0.2629\n",
      "\n",
      "Training complete in 0m 18s\n",
      "Best val Acc: 0.262871\n",
      "torch.Size([2296, 1, 128, 128])\n",
      "Epoch 1/1\n",
      "----------\n",
      "train Loss: 1.2126 Acc: 0.1578\n",
      "val Loss: 1.0618 Acc: 0.2559\n",
      "\n",
      "Training complete in 0m 18s\n",
      "Best val Acc: 0.255850\n",
      "torch.Size([2296, 1, 128, 128])\n",
      "{'num_points': 618, 'experiments': 2, 'mean': 76.41483863655084, 'std_dev': 0.37193041247455483}\n",
      "\n",
      "True_fusar_zero_shot_tl\n",
      "torch.Size([4856, 1, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/jameschapman/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ShuffleNet_V2_X0_5_Weights.IMAGENET1K_V1`. You can also use `weights=ShuffleNet_V2_X0_5_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4856, 1, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/jameschapman/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_points': 3121, 'experiments': 2, 'mean': 84.94637031199389, 'std_dev': 0.06803890990813244}\n",
      "\n",
      "True_fusar_fine_tuned_tl\n",
      "Epoch 1/1\n",
      "----------\n",
      "train Loss: 1.5596 Acc: 0.4239\n",
      "val Loss: 1.5259 Acc: 0.4482\n",
      "\n",
      "Training complete in 0m 56s\n",
      "Best val Acc: 0.448181\n",
      "torch.Size([4856, 1, 128, 128])\n",
      "Epoch 1/1\n",
      "----------\n",
      "train Loss: 1.5797 Acc: 0.3695\n",
      "val Loss: 1.5371 Acc: 0.4571\n",
      "\n",
      "Training complete in 0m 54s\n",
      "Best val Acc: 0.457104\n",
      "torch.Size([4856, 1, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/graphlearning/weightmatrix.py:90: RuntimeWarning: invalid value encountered in divide\n",
      "  weights = np.exp(-4*D/eps[:,None])\n"
     ]
    }
   ],
   "source": [
    "all_results = {}\n",
    "\n",
    "for data_augmentation in [True, False]:\n",
    "    for dataset in utils.AVAILABLE_SAR_DATASETS[1:]:\n",
    "        for embedding in utils.AVAILABLE_EMBEDDINGS[1:]:\n",
    "            key = str(data_augmentation) + '_' + dataset + '_' + embedding\n",
    "            print(key)\n",
    "            experiment_result = experiment3(dataset, embedding, data_augmentation)\n",
    "            all_results[key] = experiment_result.copy()\n",
    "            if not isinstance(experiment_result, dict):\n",
    "                assert False, \"Error in the knn_data. Look at experiment_result. It contains knn_data now. \"\n",
    "            print(experiment_result)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56ccd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d50b9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_save_path = save_path + 'all_results_' + str(num_experiments) \n",
    "if num_epochs < 10:\n",
    "    new_save_path += '_testing'\n",
    "df = pd.DataFrame.from_dict(all_results, orient='index')\n",
    "df.to_pickle(new_save_path + '.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1127eaad",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d8760ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import numpy as np\n",
    "import torch as th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd5943c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tester(num_tests=10):\n",
    "    out = []\n",
    "    for i in range(10):\n",
    "        print(f\"Iteration {i+1}\")\n",
    "        X, labels, knn_data = utils.fine_tuned_TL('fusar', data_augmentation=False, num_epochs=1)\n",
    "        num_zeros = len(np.where(knn_data[1][:, -1] == 0)[0])\n",
    "        print(num_zeros)\n",
    "        out.append(num_zeros)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10764a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "Epoch 1/1\n",
      "----------\n",
      "train Loss: 1.6151 Acc: 0.1030\n",
      "val Loss: 1.6166 Acc: 0.0528\n",
      "\n",
      "Training complete in 0m 15s\n",
      "Best val Acc: 0.052848\n",
      "4801\n",
      "Iteration 2\n",
      "Epoch 1/1\n",
      "----------\n",
      "train Loss: 1.6119 Acc: 0.1786\n",
      "val Loss: 1.6079 Acc: 0.2107\n",
      "\n",
      "Training complete in 0m 11s\n",
      "Best val Acc: 0.210707\n",
      "4825\n",
      "Iteration 3\n",
      "Epoch 1/1\n",
      "----------\n",
      "train Loss: 1.6110 Acc: 0.2142\n",
      "val Loss: 1.6119 Acc: 0.1915\n",
      "\n",
      "Training complete in 0m 11s\n",
      "Best val Acc: 0.191489\n",
      "4740\n",
      "Iteration 4\n",
      "Epoch 1/1\n",
      "----------\n",
      "train Loss: 1.6080 Acc: 0.2012\n",
      "val Loss: 1.6055 Acc: 0.1682\n",
      "\n",
      "Training complete in 0m 11s\n",
      "Best val Acc: 0.168154\n",
      "4714\n",
      "Iteration 5\n",
      "Epoch 1/1\n",
      "----------\n",
      "train Loss: 1.6136 Acc: 0.3054\n",
      "val Loss: 1.6101 Acc: 0.3054\n",
      "\n",
      "Training complete in 0m 11s\n",
      "Best val Acc: 0.305422\n",
      "4788\n",
      "Iteration 6\n",
      "Epoch 1/1\n",
      "----------\n",
      "train Loss: 1.6039 Acc: 0.3313\n",
      "val Loss: 1.6054 Acc: 0.2841\n",
      "\n",
      "Training complete in 0m 11s\n",
      "Best val Acc: 0.284146\n",
      "4720\n",
      "Iteration 7\n",
      "Epoch 1/1\n",
      "----------\n",
      "train Loss: 1.6061 Acc: 0.2145\n",
      "val Loss: 1.6114 Acc: 0.0995\n",
      "\n",
      "Training complete in 0m 11s\n",
      "Best val Acc: 0.099520\n",
      "4743\n",
      "Iteration 8\n",
      "Epoch 1/1\n",
      "----------\n",
      "train Loss: 1.6184 Acc: 0.1548\n",
      "val Loss: 1.6188 Acc: 0.1510\n",
      "\n",
      "Training complete in 0m 11s\n",
      "Best val Acc: 0.150995\n",
      "4673\n",
      "Iteration 9\n",
      "Epoch 1/1\n",
      "----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mtester\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [5], line 5\u001b[0m, in \u001b[0;36mtester\u001b[0;34m(num_tests)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIteration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m     X, labels, knn_data \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfine_tuned_TL\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfusar\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_augmentation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     num_zeros \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39mwhere(knn_data[\u001b[38;5;241m1\u001b[39m][:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(num_zeros)\n",
      "File \u001b[0;32m~/Documents/GitHub/SAR_BAL/utils.py:806\u001b[0m, in \u001b[0;36mfine_tuned_TL\u001b[0;34m(dataset, knn_num, num_epochs, network, data_augmentation, include_knn_data)\u001b[0m\n\u001b[1;32m    804\u001b[0m     X \u001b[38;5;241m=\u001b[39m encode_transfer_learning(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopen_sar_ship\u001b[39m\u001b[38;5;124m'\u001b[39m, model_type\u001b[38;5;241m=\u001b[39mnetwork, transfer_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, epochs\u001b[38;5;241m=\u001b[39mnum_epochs, data_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, transformed\u001b[38;5;241m=\u001b[39mdata_augmentation)\n\u001b[1;32m    805\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 806\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mencode_transfer_learning\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfusar\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransfer_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_augmentation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_knn_data:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;66;03m#Takes a long time\u001b[39;00m\n\u001b[1;32m    810\u001b[0m     knn_data \u001b[38;5;241m=\u001b[39m gl\u001b[38;5;241m.\u001b[39mweightmatrix\u001b[38;5;241m.\u001b[39mknnsearch(X, knn_num, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mannoy\u001b[39m\u001b[38;5;124m'\u001b[39m, similarity\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mangular\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/GitHub/SAR_BAL/utils.py:518\u001b[0m, in \u001b[0;36mencode_transfer_learning\u001b[0;34m(dataset, model_type, epochs, transfer_batch_size, batch_size, data_info, transformed)\u001b[0m\n\u001b[1;32m    515\u001b[0m exp_lr_scheduler \u001b[38;5;241m=\u001b[39m lr_scheduler\u001b[38;5;241m.\u001b[39mStepLR(optimizer_ft, step_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m    517\u001b[0m \u001b[38;5;66;03m#Train the model with cross entropy loss\u001b[39;00m\n\u001b[0;32m--> 518\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m    519\u001b[0m model_ft \u001b[38;5;241m=\u001b[39m train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, device, dataloaders, dataset_sizes, num_epochs\u001b[38;5;241m=\u001b[39mepochs)\n\u001b[1;32m    521\u001b[0m data, _ \u001b[38;5;241m=\u001b[39m load_dataset(dataset, return_torch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, shuffle_train_set\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, concatenate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/GitHub/SAR_BAL/utils.py:358\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, device, dataloaders, dataset_sizes, num_epochs)\u001b[0m\n\u001b[1;32m    355\u001b[0m         loss.backward()\n\u001b[1;32m    356\u001b[0m         optimizer.step()\n\u001b[0;32m--> 358\u001b[0m # statistics\n\u001b[1;32m    359\u001b[0m running_loss += loss.item() * inputs.size(0)\n\u001b[1;32m    360\u001b[0m running_corrects += torch.sum(preds == labels.data)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "out = tester()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bf041d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out)\n",
    "#[0, 0, 0, 0, 0, 4712, 4677, 4669, 4680, 4672] with mps\n",
    "#[0, 0, 0, 0, 0, 0, 0, 0, 0, 0] with cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc016918",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ShuffleNet_V2_X0_5_Weights.IMAGENET1K_V1`. You can also use `weights=ShuffleNet_V2_X0_5_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jameschapman/Documents/GitHub/SAR_BAL/utils.py:349: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs = nn.functional.log_softmax(outputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.6270 Acc: 0.0559\n",
      "val Loss: 1.6237 Acc: 0.0494\n",
      "\n",
      "Training complete in 0m 10s\n",
      "Best val Acc: 0.049417\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "X, labels, knn_data = utils.fine_tuned_TL('fusar', data_augmentation=False, num_epochs=1)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8464910f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4650"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.where(knn_data[1][:, -1] == 0)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a89faacb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00590989, 0.        , 0.10457867, ..., 0.01400539, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.00333806, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.04948823, 0.01027269, 0.05872394, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.09199033, 0.        , ..., 0.00718634, 0.        ,\n",
       "        0.        ],\n",
       "       [0.02563937, 0.00534612, 0.11887628, ..., 0.03139264, 0.        ,\n",
       "        0.        ],\n",
       "       [0.00980122, 0.05995636, 0.10911434, ..., 0.00628325, 0.        ,\n",
       "        0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f219603",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_da, labels_da, knn_data_da = utils.fine_tuned_TL('fusar', data_augmentation=True, num_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4926af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/jameschapman/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ShuffleNet_V2_X0_5_Weights.IMAGENET1K_V1`. You can also use `weights=ShuffleNet_V2_X0_5_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "X_zs, labels_zs, knn_data_zs = utils.zero_shot_TL('fusar', data_augmentation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f6a3e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3475616 , 0.2934168 , 0.52518052, ..., 0.31965578, 0.45735806,\n",
       "       0.63850933])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_data_zs[1][:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afed3eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5 (v3.9.5:0a7dcbdb13, May  3 2021, 13:05:53) \n[Clang 12.0.5 (clang-1205.0.22.9)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
